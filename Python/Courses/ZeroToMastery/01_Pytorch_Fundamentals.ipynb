{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), 0, torch.Size([]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining a scalar - a 0 dim tensor\n",
    "scalar = torch.tensor(2)\n",
    "scalar, scalar.ndim, scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting tensor to python integer\n",
    "scalar_val = scalar.item()\n",
    "scalar_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), 1, torch.Size([4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vector -> is a single dim tensor\n",
    "vector = torch.tensor([1,2,3,4])\n",
    "vector, vector.ndim, vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " 2,\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix -> is 2 dimentional vector\n",
    "matrix = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "matrix, matrix.ndim, matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6]]]),\n",
       " 3,\n",
       " torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor -> beyond 2 dim\n",
    "tensor = torch.tensor([[[1,2,3], [4,5,6]]])\n",
    "tensor, tensor.ndim, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0665, 0.9831, 0.6270, 0.8774],\n",
       "         [0.6561, 0.7547, 0.6187, 0.3135],\n",
       "         [0.4055, 0.1984, 0.2459, 0.8826]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a random tensor\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "random_tensor,random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " torch.Size([3, 3]),\n",
       " 2,\n",
       " torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors filled with zeros and ones\n",
    "zeros = torch.zeros(size=(3,3))\n",
    "zeros, zeros.shape, zeros.ndim, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]]),\n",
       " torch.Size([3, 3]),\n",
       " 2,\n",
       " torch.bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeros with custom type\n",
    "# creating tensors filled with zeros and ones\n",
    "zeros = torch.zeros(size=(3,3), dtype=torch.bool)\n",
    "zeros, zeros.shape, zeros.ndim, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]),\n",
       " torch.Size([3, 4]),\n",
       " torch.int64,\n",
       " 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly for ones\n",
    "ones = torch.ones(size=(3,4), dtype=torch.int64)\n",
    "ones, ones.shape, ones.dtype, ones.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 4, 6, 8]), torch.Size([5]), 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor using range\n",
    "tensor_range = torch.arange(start=0, end=10, step=2)\n",
    "tensor_range, tensor_range.shape, tensor_range.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0]) torch.Size([5])\n",
      "tensor([1, 1, 1, 1, 1]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# creating tensors based on shape\n",
    "zero_like = torch.zeros_like(tensor_range)\n",
    "print(zero_like, zero_like.shape)\n",
    "\n",
    "one_like = torch.ones_like(tensor_range)\n",
    "print(one_like, one_like.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13, 14])\n",
      "tensor([-2, -1,  0,  1])\n",
      "tensor([10, 20, 30, 40])\n"
     ]
    }
   ],
   "source": [
    "# tensor operations\n",
    "og = torch.tensor([1,2,3,4])\n",
    "\n",
    "# add\n",
    "sample  = og + 10\n",
    "print(sample)\n",
    "\n",
    "# sub\n",
    "sample = og - 3\n",
    "print(sample)\n",
    "\n",
    "# mul\n",
    "sample = og * 10\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26052/4246429935.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  matmul = torch.matmul(og, og.T) # 1*4 * 4* 1 => 1*1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multiplication\n",
    "\n",
    "matmul = torch.matmul(og, og.T) # 1*4 * 4* 1 => 1*1\n",
    "matmul.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative\n",
    "matmul = og @ og.T # 1*4 * 4* 1 => 1* -> this is slow (not recommended)\n",
    "matmul.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0304,  0.2328,  2.1020,  0.7054,  1.5950,  0.9444, -0.2944,  0.2701,\n",
       "         -1.8215, -2.2932,  1.3970,  0.9839,  1.7678, -0.8180,  1.7025,  0.2724,\n",
       "         -2.5135,  0.5463,  1.3991,  0.1427],\n",
       "        [ 3.3865,  1.7939,  3.8028,  1.2644,  3.9444,  2.2910, -1.4595,  0.5125,\n",
       "         -4.4763, -4.8819,  2.8271,  1.7800,  3.6266, -1.3686,  4.9791,  0.8249,\n",
       "         -4.4042, -0.0302,  3.1632,  0.2375],\n",
       "        [ 4.1718,  2.3143,  4.3697,  1.4507,  4.7276,  2.7399, -1.8479,  0.5933,\n",
       "         -5.3612, -5.7448,  3.3038,  2.0454,  4.2461, -1.5521,  6.0713,  1.0091,\n",
       "         -5.0344, -0.2224,  3.7512,  0.2690]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "#y = x * A(T) + b\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X = torch.tensor([[1,2,3], [4,5,6],[5,6,7]], dtype=torch.float32)\n",
    "\n",
    "linear = torch.nn.Linear(in_features=3, out_features=20)\n",
    "\n",
    "y = linear(X)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  3.,  6.,  9., 12., 15., 18.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregation\n",
    "\n",
    "sample_tensor = torch.arange(0,20,3, dtype=torch.float32)\n",
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min tensor(0.)\n",
      "Max tensor(18.)\n",
      "Medium tensor(9.)\n",
      "Mean tensor(9.)\n",
      "Sum tensor(63.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Min\", sample_tensor.min())\n",
    "print(\"Max\",sample_tensor.max())\n",
    "print(\"Medium\", sample_tensor.median())\n",
    "print(\"Mean\", sample_tensor.mean())\n",
    "print(\"Sum\", sample_tensor.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4679, -0.2049, -0.7409,  0.3618],\n",
       "        [ 1.9199, -0.2254, -0.3417,  0.3040],\n",
       "        [-0.6890, -1.1267, -0.2858, -1.0935]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional min/max -> argmax, argmin\n",
    "\n",
    "sample_arr  = torch.randn(size=(3,4), dtype=torch.float32)\n",
    "\n",
    "sample_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(sample_arr) # looks like the data needs to be normalized for this code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(sample_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def arg_min_max(tensor: torch.tensor, max=True) -> list[int]:\n",
    "    shape = list(tensor.shape)\n",
    "    norm_tensor = tensor / tensor.max() # todo fix divide by zero\n",
    "    if max:\n",
    "        idx = norm_tensor.argmax()\n",
    "    else:\n",
    "        idx = norm_tensor.argmin()\n",
    "    idx = idx.item()\n",
    "    res = []\n",
    "    for dim in shape[len(shape)-1:0:-1]:\n",
    "        res.append((idx // dim))\n",
    "        idx = idx % dim\n",
    "    res.append(idx)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor([[1,2,11,4],[4,5,6,7], [8,9,10,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(arg_min_max(sample))\n",
    "print(arg_min_max(sample, max=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping \n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = sample.reshape(2,6) # or sample.view(2,6)\n",
    "new_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor[0][0] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9999,    2,   11,    4,    4,    5],\n",
       "         [   6,    7,    8,    9,   10,    3]]),\n",
       " tensor([[9999,    2,   11,    4],\n",
       "         [   4,    5,    6,    7],\n",
       "         [   8,    9,   10,    3]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor, sample # changing the view affects the original tensor (reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking tensors\n",
    "base_tensor = torch.tensor([1,2,3,4])\n",
    "\n",
    "hstack = torch.stack([base_tensor, base_tensor], dim=0) # stacking in x dim\n",
    "\n",
    "hstack, hstack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3],\n",
       "         [4, 4]]),\n",
       " torch.Size([4, 2]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vstack = torch.stack([base_tensor, base_tensor], dim=1) # stacking in x dim\n",
    "\n",
    "vstack, vstack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4]]),\n",
       " torch.Size([1, 4]),\n",
       " tensor([1, 2, 3, 4]),\n",
       " torch.Size([4]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze - reduce a dim\n",
    "not_sq = torch.tensor([[1,2,3,4]])\n",
    "sq = torch.squeeze(not_sq)\n",
    "not_sq, not_sq.shape, sq, sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3]) torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Re-ordering the axes of a tensor\n",
    "\n",
    "x_original = torch.rand(size=(224,224, 3))\n",
    "\n",
    "x_permuted = x_original.permute(2,0,1)\n",
    "\n",
    "print(x_original.shape, x_permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch and Numpy\n",
    "\n",
    "#torch.from_numpy() -> numpy -> torch\n",
    "#torch.tensor.numpy() -> torch -> numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np_arr = np.array([1,2,3])\n",
    "trch_arr = torch.tensor([1,2,3], dtype=torch.long)\n",
    "\n",
    "# checking for equality in numpy world\n",
    "assert np.allclose(np_arr, trch_arr)\n",
    "assert np.array_equal(np_arr, trch_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for equality in the torch world\n",
    "assert  torch.allclose(trch_arr, torch.from_numpy(np_arr)) \n",
    "assert  torch.equal(trch_arr, torch.from_numpy(np_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiddling with GPU\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='cuda:0'),\n",
       " torch.int64,\n",
       " tensor([1, 2, 3]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors to gpu\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "\n",
    "tensor_on_gpu, tensor_on_gpu.dtype, tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), numpy.ndarray)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving the tensor from gpu to cpu and converting to numpy\n",
    "np_arr = tensor_on_gpu.cpu().numpy()\n",
    "np_arr, type(np_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
