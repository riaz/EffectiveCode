{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example we make use of advanced RAG to answer users question on a specific knowlegde base -> using LangChain\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the knowledge base\n",
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2647/2647 [00:00<00:00, 17706.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]}) for doc in tqdm(ds)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval - Embeddings\n",
    "# The snippet size are called chunk size which is how the data is stored and retrieved.\n",
    "# We need to make sure that the top_k is tuned towards relavancy vs random documents to have a consistent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking notebook example - which describes many chunking strategies\n",
    "# https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Langchains recursive character splitter for chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# We use a hierarchical list of separators specifically tailored for splitting Markdown documents\n",
    "# This list is taken from LangChain's MarkdownTextSplitter class\n",
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "CHUNK_SIZE = 8000\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,  # The maximum number of characters in a chunk: we selected this value arbitrarily\n",
    "    chunk_overlap=int(0.1 * CHUNK_SIZE),  # The number of characters to overlap between chunks - 1/10 (chunk_size)\n",
    "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
    "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
    "    separators=MARKDOWN_SEPARATORS,\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "for doc in RAW_KNOWLEDGE_BASE:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "4888\n",
      "7263\n",
      "7768\n",
      "6263\n",
      "696\n",
      "2907\n",
      "2919\n",
      "1606\n",
      "3555\n"
     ]
    }
   ],
   "source": [
    "# Now we have processed the documents to arbitracy size but under chunk_size, lets verify this\n",
    "\n",
    "for chunked_doc in docs_processed[:10]:\n",
    "    print(len(chunked_doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will embed these into a vector database, since that would transform these aribitrary chunks into the embedding space which will make sense for the\n",
    "# retrievel in that space.\n",
    "\n",
    "# we set the max length of the embedding space to max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riaz/miniconda3/envs/cookbook/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# getting the maximum sentence length\n",
    "print(SentenceTransformer(\"jinaai/jina-embeddings-v2-base-en\").max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4647/4647 [00:35<00:00, 130.64it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAGzCAYAAAChApYOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIk0lEQVR4nO3dd3gU5d7G8TshyaZAEmpCqBGQXjQohCIKgYiAICCgKEWQQ1MQRUGlqyAqooiU4xFsiAKKHpQSukoV6U1QEASTIBgSWgjJ8/7Bu3NYksAEUlj4fq6L62Jnnp155jezM3dmZ2Y9jDFGAAAAwFV45nUHAAAA4B4IjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbcjw4jhw5Uh4eHjk9G0nSvffeq3vvvdd6vXLlSnl4eGju3Lm5Mv9u3bqpbNmyuTKva3Xq1Cn17NlToaGh8vDw0MCBA7M8DQ8PD40cOTLb+3YrKlu2rLp165bX3biqbt26KX/+/Dk6j9zarnJrv5Db+5/rdfDgQXl4eGjmzJnZNs2ZM2fKw8NDBw8ezLZp2lW2bFm1bNky1+d7vU6dOqVixYrps88+s4bl5nH0Zpcdx0C7nNv/zz//nGPzuFadOnVShw4drum9WQqOziI4//n6+iosLEzR0dF69913lZSUdE2duNzRo0c1cuRIbdmyJVuml51u5L7Z8dprr2nmzJnq06ePPvnkEz3++ON53aWbyqxZszRx4sS87sY1OXPmjEaOHKmVK1fmdVeyhTuvC9y63nnnHRUoUECdOnXK667kqddee03z58/PkenaPQbmVB9uBC+88ILmzZunrVu3Zvm913TGcfTo0frkk080ZcoUPfXUU5KkgQMHqnr16tq2bZtL25dffllnz57N0vSPHj2qUaNGZTmcLVmyREuWLMnSe7LqSn3797//rb179+bo/K/X8uXLVbduXY0YMUKPPfaYIiIi8rpLNxV3DitnzpzRqFGj8iw4nj17Vi+//HK2Tc+d1wVuTSkpKXrnnXfUs2dP5cuXzxp+LcdRd5dToS0rx8CbOTjecccdql27tt56660sv/eagmPz5s312GOPqXv37ho6dKgWL16spUuXKj4+Xg8++KDLBu7l5SVfX99rmY1tZ86ckST5+PjIx8cnR+d1Jd7e3nI4HHk2fzvi4+MVHByc190A0vH19ZWXl1dedwPIMwsWLNCxY8fSfYWYG8fRWwXHwP/p0KGDvvrqK506dSpL78u2axwbN26sYcOG6Y8//tCnn35qDc/o2oyYmBg1aNBAwcHByp8/vypWrKgXX3xR0sXrgu666y5JUvfu3a2vxZ3X3dx7772qVq2aNm3apHvuuUf+/v7Wey+/xtEpNTVVL774okJDQxUQEKAHH3xQhw8fdmmT2bVml07zan3L6BrH06dP69lnn1WpUqXkcDhUsWJFvfnmmzLGuLTz8PBQ//79NX/+fFWrVk0Oh0NVq1bVokWLMi74ZeLj49WjRw+FhITI19dXNWvW1EcffWSNd15vdeDAAX333XdW36907VFycrKeeeYZFS1aVAUKFNCDDz6oP//8M8O2mzdvVvPmzRUYGKj8+fOrSZMmWrduXbp2CQkJeuaZZ1S2bFk5HA6VLFlSXbp00d9//y0p82uinP2/9GyYc1vYtm2bGjVqJH9/f5UvX966pmzVqlWqU6eO/Pz8VLFiRS1dujRdf44cOaInnnhCISEhVs0//PDDDOf95Zdf6tVXX1XJkiXl6+urJk2aaP/+/S79+e677/THH39Y9b2Wa14TEhI0cOBAa5spX768Xn/9daWlpVltnNejvfnmm5o+fbrKlSsnh8Ohu+66Sxs3bkw3zTlz5qhKlSry9fVVtWrV9PXXX7tsrwcPHlTRokUlSaNGjbL6f/k1h0eOHFGbNm2UP39+FS1aVM8995xSU1Nd2syePVsREREqUKCAAgMDVb16db3zzjtXXe7L5+fcd+zfv1/dunVTcHCwgoKC1L17d+uPxczYWRdpaWlXXJ9O69ev1/3336+goCD5+/urUaNG+umnn666PBlJTk5Wy5YtFRQUpDVr1mR5OS9cuKAxY8ZY67ts2bJ68cUXlZycbLUZNGiQChcu7LKPeeqpp+Th4aF3333XGhYXFycPDw9NmTLlin3es2eP2rdvr0KFCsnX11e1a9fWt99+m67dzp071bhxY/n5+alkyZJ65ZVXXLZZp7S0NI0cOVJhYWHy9/fXfffdp127dmW4D7bzWbiaJUuWqFatWvL19VWVKlX01VdfuYw/ceKEnnvuOVWvXl358+dXYGCgmjdvnuFXeJMmTVLVqlXl7++vggULqnbt2po1a5ZLGzv7lMzMnz9fZcuWVbly5VyGZ3Qcvd5jxrlz5zRy5Ejdfvvt8vX1VfHixdW2bVv99ttvVhs7x68rXRt7rZ9pDw8PnT59Wh999JH1+b3ateDZfQy8Wh/sHvMu988//+juu+9WyZIlrW8ok5OTNWLECJUvX14Oh0OlSpXS888/7/K5dvbJzjpPSkrSwIEDreNssWLF1LRpU/3yyy8u7Zo2barTp08rJibmqv2+VLb+ef/444/rxRdf1JIlS/Tkk09m2Gbnzp1q2bKlatSoodGjR8vhcGj//v3Wjrhy5coaPXq0hg8frl69eqlhw4aSpHr16lnTOH78uJo3b65OnTrpscceU0hIyBX79eqrr8rDw0MvvPCC4uPjNXHiREVFRWnLli3y8/OzvXx2+nYpY4wefPBBrVixQj169FCtWrW0ePFiDR48WEeOHNHbb7/t0v7HH3/UV199pb59+6pAgQJ699131a5dOx06dEiFCxfOtF9nz57Vvffeq/3796t///4KDw/XnDlz1K1bNyUkJGjAgAGqXLmyPvnkEz3zzDMqWbKknn32WUmywkJGevbsqU8//VSPPvqo6tWrp+XLl6tFixbp2u3cuVMNGzZUYGCgnn/+eXl7e2vatGm69957rfAmXbwouWHDhtq9e7eeeOIJ3Xnnnfr777/17bff6s8//1SRIkWuvAIy8M8//6hly5bq1KmTHn74YU2ZMkWdOnXSZ599poEDB6p379569NFH9cYbb6h9+/Y6fPiwChQoIOnigbNu3brWh7Fo0aJauHChevToocTExHQXTY8bN06enp567rnndPLkSY0fP16dO3fW+vXrJUkvvfSSTp48qT///NNat1m9oeTMmTNq1KiRjhw5on/9618qXbq01qxZo6FDh+qvv/5K99XrrFmzlJSUpH/961/y8PDQ+PHj1bZtW/3+++/y9vaWJH333Xfq2LGjqlevrrFjx+qff/5Rjx49VKJECWs6RYsW1ZQpU9SnTx899NBDatu2rSSpRo0aVpvU1FRFR0erTp06evPNN7V06VK99dZbKleunPr06SPp4h+FjzzyiJo0aaLXX39dkrR792799NNPGjBgQJZq4dShQweFh4dr7Nix+uWXX/TBBx+oWLFi1vQzYmddXG19She/1mrevLkiIiI0YsQIeXp6asaMGWrcuLF++OEH3X333baX4+zZs2rdurV+/vlnLV261PojNCvL2bNnT3300Udq3769nn32Wa1fv15jx47V7t279fXXX0uSGjZsqLfffls7d+5UtWrVJEk//PCDPD099cMPP+jpp5+2hknSPffck2mfd+7cqfr166tEiRIaMmSIAgIC9OWXX6pNmzaaN2+eHnroIUlSbGys7rvvPl24cMFqN3369Az3r0OHDtX48ePVqlUrRUdHa+vWrYqOjta5c+dc2mX1s5CRffv2qWPHjurdu7e6du2qGTNm6OGHH9aiRYvUtGlTSdLvv/+u+fPn6+GHH1Z4eLji4uI0bdo0NWrUSLt27VJYWJiki5ciPf3002rfvr0GDBigc+fOadu2bVq/fr0effRRSVnfp1xuzZo1uvPOO6+6XE7XesxITU1Vy5YttWzZMnXq1EkDBgxQUlKSYmJitGPHDpUrVy7Lx6+suNq2/sknn6hnz566++671atXL0lKF6YvlRPHwCv1we4x73J///23mjZtqhMnTmjVqlUqV66c0tLS9OCDD+rHH39Ur169VLlyZW3fvl1vv/22fv3113RfldtZ571799bcuXPVv39/ValSRcePH9ePP/6o3bt3u2xfVapUkZ+fn3766Sfrs2yLyYIZM2YYSWbjxo2ZtgkKCjJ33HGH9XrEiBHm0tm8/fbbRpI5duxYptPYuHGjkWRmzJiRblyjRo2MJDN16tQMxzVq1Mh6vWLFCiPJlChRwiQmJlrDv/zySyPJvPPOO9awMmXKmK5du151mlfqW9euXU2ZMmWs1/PnzzeSzCuvvOLSrn379sbDw8Ps37/fGibJ+Pj4uAzbunWrkWQmTZqUbl6XmjhxopFkPv30U2vY+fPnTWRkpMmfP7/LspcpU8a0aNHiitMzxpgtW7YYSaZv374uwx999FEjyYwYMcIa1qZNG+Pj42N+++03a9jRo0dNgQIFzD333GMNGz58uJFkvvrqq3TzS0tLM8b8bxs7cOCAy3jnulyxYoU1zLktzJo1yxq2Z88eI8l4enqadevWWcMXL16cbr316NHDFC9e3Pz9998u8+rUqZMJCgoyZ86ccZl35cqVTXJystXunXfeMZLM9u3brWEtWrRw2Qau5vLtbsyYMSYgIMD8+uuvLu2GDBli8uXLZw4dOmSMMebAgQNGkilcuLA5ceKE1e6bb74xksx///tfa1j16tVNyZIlTVJSkjVs5cqVRpJLX48dO5Zu3Tp17drVSDKjR492GX7HHXeYiIgI6/WAAQNMYGCguXDhgu0aOF0+b+e+44knnnBp99BDD5nChQtfdXqZrQu76zMtLc1UqFDBREdHW9unMcacOXPGhIeHm6ZNm15x/s75zJkzxyQlJZlGjRqZIkWKmM2bN7u0s7uczs9kz549Xdo999xzRpJZvny5McaY+Ph4I8m8//77xhhjEhISjKenp3n44YdNSEiI9b6nn37aFCpUyFo25zZ16WekSZMmpnr16ubcuXPWsLS0NFOvXj1ToUIFa9jAgQONJLN+/XprWHx8vAkKCnL5PMfGxhovLy/Tpk0bl2UYOXKkkXRNn4XMlClTxkgy8+bNs4adPHnSFC9e3OUYde7cOZOamury3gMHDhiHw+Gyvbdu3dpUrVr1ivO0u0/JSEpKivHw8DDPPvtsunGXH0eNub5jxocffmgkmQkTJqQb59we7B6/MtpuLu3jtX6mAwICMjwmZyQnjoFX6oPdY96lmemvv/4yVatWNbfddps5ePCg1eaTTz4xnp6e5ocffnCZx9SpU40k89NPP1nD7K7zoKAg069fP1vLePvtt5vmzZvbauuU7Y/jyZ8//xXvrnZeW/DNN99k6euGSzkcDnXv3t12+y5dulhnmSSpffv2Kl68uL7//vtrmr9d33//vfLly2f9he/07LPPyhijhQsXugyPiopy+auqRo0aCgwM1O+//37V+YSGhuqRRx6xhnl7e+vpp5/WqVOntGrVqmvqu6R0fb/8L+bU1FQtWbJEbdq00W233WYNL168uB599FH9+OOPSkxMlCTNmzdPNWvWzPAvm2t91ET+/Pld7j6sWLGigoODVblyZZe/+pz/d9bSGKN58+apVatWMsbo77//tv5FR0fr5MmT6U7rd+/e3eUaWucZ56utn6yYM2eOGjZsqIIFC7r0KSoqSqmpqVq9erVL+44dO6pgwYKZ9uno0aPavn27unTp4nLGrVGjRqpevXqW+9e7d2+X1w0bNnRZ/uDg4Gv66iOr8zx+/Li1XV2rq63PLVu2aN++fXr00Ud1/Phxa12cPn1aTZo00erVq23tw06ePKlmzZppz549WrlypWrVqpVhu6stp/MzOWjQIJd2zjMn3333naSLZ1AqVapkbSs//fST8uXLp8GDBysuLk779u2TdPGMY4MGDTL97J04cULLly9Xhw4dlJSUZC3/8ePHFR0drX379unIkSNW3+rWretyBrZo0aLq3LmzyzSXLVumCxcuqG/fvi7DnTdZXiqrn4WMhIWFuexvAgMD1aVLF23evFmxsbGSLh5PPD0vHgpTU1N1/Phx6xKqS/cBwcHB+vPPPzO8FES6tn3KpU6cOCFjjMvn+Wqu9Zgxb948FSlSJMO6O7eHrB6/siK7P9M5cQzMTFaOeU5//vmnGjVqpJSUFK1evVplypSxxs2ZM0eVK1dWpUqVXLaZxo0bS5JWrFjhMi076zw4OFjr16/X0aNHr7o8zs9XVmT7lejOZ1BlpmPHjvrggw/Us2dPDRkyRE2aNFHbtm3Vvn1768N7NSVKlMjSTTAVKlRwee3h4aHy5cvn+LPF/vjjD4WFhbmEVuniV97O8ZcqXbp0umkULFhQ//zzz1XnU6FChXT1y2w+dvvu6emZ7uuBihUrurw+duyYzpw5k264c/5paWk6fPiwqlatqt9++03t2rXLcl+upGTJkukOfEFBQSpVqlS6YZKsWh47dkwJCQmaPn26pk+fnuG04+PjXV5fvn6cO/irrZ+s2Ldvn7Zt25bp1ydZ7ZNz3ZcvXz7dtMqXL3/FA9nlfH190/Xr8u2zb9+++vLLL9W8eXOVKFFCzZo1U4cOHXT//ffbns/lrrSMgYGBOTJdSVbA6tq1a6bTOHny5FUP9AMHDtS5c+e0efNmVa1a9Zr6ExgYaH0mL1+XoaGhCg4OdvmcN2zY0AqaP/zwg2rXrq3atWurUKFC+uGHHxQSEqKtW7daX7FmZP/+/TLGaNiwYRo2bFiGbeLj41WiRAn98ccfGX49d/l+IbPtsVChQunqmNXPQkbKly+fbv9w++23S7p4bV5oaKjS0tL0zjvv6P3339eBAwdcrtm99OveF154QUuXLtXdd9+t8uXLq1mzZnr00UdVv359Sde2T8mIuez69yu51mPGb7/9pooVK17xZrSsHr+yIrs/0zlxDMxMVo55To8//ri8vLy0e/duhYaGurxn37592r179zXv86X063z8+PHq2rWrSpUqpYiICD3wwAPq0qWLS9B1MsZk+cRNtgbHP//8UydPnszwIOXk5+en1atXa8WKFfruu++0aNEiffHFF2rcuLGWLFni8giCK00ju2VWuNTUVFt9yg6ZzScrOxJ3d6X1kJHMana1WjrPFD322GOZBoNLr++zM83skJaWpqZNm+r555/PcLzzoJebfbravC5VrFgxbdmyRYsXL9bChQu1cOFCzZgxQ126dHG5UD075nu9y2h3G3njjTcyPUto5xrW1q1ba/bs2Ro3bpw+/vjjTP9AtrucdnbyDRo00L///W/9/vvv+uGHH9SwYUN5eHioQYMG+uGHHxQWFqa0tDTrLGtGnMv/3HPPKTo6OsM2V9rXX6+sfhau1WuvvaZhw4bpiSee0JgxY1SoUCF5enpq4MCBLmeUK1eurL1792rBggVatGiR5s2bp/fff1/Dhw/XqFGjrmmfcqlChQrJw8MjS3+I3gjHjKzus6Ubo9+5qW3btvr444/1zjvvaOzYsS7j0tLSVL16dU2YMCHD915+EsRO7Tp06KCGDRvq66+/1pIlS/TGG2/o9ddf11dffaXmzZu7vO+ff/5Jd3LtarI1OH7yySeSlOlOxsnT01NNmjRRkyZNNGHCBL322mt66aWXtGLFCkVFRWX7E/KdZw6cjDHav3+/y4e4YMGCSkhISPfeP/74wyWlZ6VvZcqU0dKlS5WUlOTyV9uePXus8dmhTJky2rZtm9LS0lwOStcznzJlyigtLc36y9Tp8udUFi1aVP7+/hk+v3LPnj3y9PS0Nvxy5cppx44dV5yv8y/Py9dFdv7FKMm6Uzw1NVVRUVHZNt3r3XbLlSunU6dOZVufnOs+o7uFLx+WXZ87Hx8ftWrVSq1atVJaWpr69u2radOmadiwYTkaNC6XHetCuvj15vWsjzZt2qhZs2bq1q2bChQocNW7mDPj/Ezu27fPOpMiXbwhIyEhweVz7gyEMTEx2rhxo4YMGSLp4o0wU6ZMUVhYmAICAq74DDvnfs/b2/uqy1+mTJl0+1kp/f7i0u0xPDzcGn78+PF0gSk7PgvOs6aXbgu//vqrJFl32c+dO1f33Xef/vOf/7i8NyEhId0NewEBAerYsaM6duyo8+fPq23btnr11Vc1dOjQ696neHl5qVy5cjpw4ECW35tV5cqV0/r165WSkmLdRHc5u8evnNpnZ/VYm93HwMz6kJVjntNTTz2l8uXLa/jw4QoKCrI+j9LFdbF161Y1adIkW7NP8eLF1bdvX/Xt21fx8fG688479eqrr7oExwsXLujw4cN68MEHszTtbLvGcfny5RozZozCw8PTXddyqRMnTqQb5vxr3nnreUBAgKT0G+K1+vjjj12uu5w7d67++usvlwKWK1dO69at0/nz561hCxYsSPfYnqz07YEHHlBqaqree+89l+Fvv/22PDw80iX/a/XAAw8oNjZWX3zxhTXswoULmjRpkvLnz69GjRpleZrOvl36+A5J6e5kzJcvn5o1a6ZvvvnG5av/uLg4zZo1Sw0aNLC+emjXrp22bt1q3f15KedfS86D9aXXL6Wmpmb61c+1ypcvn9q1a6d58+ZlGGaPHTt2TdMNCAjQyZMnr7lfHTp00Nq1a7V48eJ04xISEnThwoUsTS8sLEzVqlXTxx9/7PKsrlWrVmn79u0ubf39/a35XKvjx4+7vPb09LT+QLv80RI57XrXRUREhMqVK6c333wzw+ecZWUb6dKli959911NnTpVL7zwwjX154EHHpCU/jPoPFNx6RMPwsPDVaJECb399ttKSUmxvk5t2LChfvvtN82dO1d169a94leVxYoV07333qtp06bpr7/+Sjf+0uV/4IEHtG7dOm3YsMFl/KU/mydJTZo0kZeXV7rwfPk+Usqez8LRo0dd9jeJiYn6+OOPVatWLesrw3z58qU70zVnzhzr+k2ny7dtHx8fValSRcYYpaSkZMs+JTIyMld+nq5du3b6+++/M6y7sxZ2j1+BgYEqUqRIumtO33///evqY0BAgO19UU4cAzPrQ1aOeZcaNmyYnnvuOQ0dOtRl++/QoYOOHDmif//73+nec/bsWZ0+fTpLfU5NTU233ytWrJjCwsLS7YN37dqlc+fOZfpkmMxc0xnHhQsXas+ePbpw4YLi4uK0fPlyxcTEqEyZMvr222+v+KDS0aNHa/Xq1WrRooXKlCmj+Ph4vf/++ypZsqQaNGgg6WJ4CA4O1tSpU1WgQAEFBASoTp06Ln+hZkWhQoXUoEEDde/eXXFxcZo4caLKly/v8signj17au7cubr//vvVoUMH/fbbb/r000/TXeOXlb61atVK9913n1566SUdPHhQNWvW1JIlS/TNN99o4MCBV3y8QFb06tVL06ZNU7du3bRp0yaVLVtWc+fO1U8//aSJEyemu0bFjlq1aumRRx7R+++/r5MnT6pevXpatmxZhmeuXnnlFevZnH379pWXl5emTZum5ORkjR8/3mo3ePBgzZ07Vw8//LCeeOIJRURE6MSJE/r22281depU1axZU1WrVlXdunU1dOhQnThxQoUKFdLs2bOzHJjsGDdunFasWKE6deroySefVJUqVXTixAn98ssvWrp0aYZ/5FxNRESEvvjiCw0aNEh33XWX8ufPr1atWtl+/+DBg/Xtt9+qZcuW6tatmyIiInT69Glt375dc+fO1cGDB7P82KLXXntNrVu3Vv369dW9e3f9888/eu+991StWjWXQOTn56cqVaroiy++0O23365ChQqpWrVq1iNd7OjZs6dOnDihxo0bq2TJkvrjjz80adIk1apVy+UsWW643nXh6empDz74QM2bN1fVqlXVvXt3lShRQkeOHNGKFSsUGBio//73v7an179/fyUmJuqll15SUFCQ9fxZu2rWrKmuXbtq+vTpSkhIUKNGjbRhwwZ99NFHatOmje677z6X9g0bNtTs2bNVvXp166zQnXfeqYCAAP36669XvL7RafLkyWrQoIGqV6+uJ598Urfddpvi4uK0du1a/fnnn9azDp9//nl98sknuv/++zVgwADrcTzOM0FOISEhGjBggN566y09+OCDuv/++7V161YtXLhQRYoUcTnjkh2fhdtvv109evTQxo0bFRISog8//FBxcXGaMWOG1aZly5YaPXq0unfvrnr16mn79u367LPP0l0P1qxZM4WGhqp+/foKCQnR7t279d5776lFixbWPvZ69ymtW7fWJ598ol9//TXbvorPSJcuXfTxxx9r0KBB2rBhgxo2bKjTp09r6dKl6tu3r1q3bp2l41fPnj01btw49ezZU7Vr19bq1autM7vXKiIiQkuXLtWECRMUFham8PDwTB9zkxPHwCv1we4x73JvvPGGTp48qX79+qlAgQJ67LHH9Pjjj+vLL79U7969tWLFCtWvX1+pqanas2ePvvzySy1evFi1a9e23eekpCSVLFlS7du3V82aNZU/f34tXbpUGzduTPcrMTExMfL397ceTWVbVm7Bdt5a7vzn4+NjQkNDTdOmTc0777zjcsu70+WPEVi2bJlp3bq1CQsLMz4+PiYsLMw88sgj6R658M0335gqVaoYLy8vl1v9GzVqlOkjETJ7HM/nn39uhg4daooVK2b8/PxMixYtzB9//JHu/W+99ZYpUaKEcTgcpn79+ubnn39ON80r9e3yx/EYY0xSUpJ55plnTFhYmPH29jYVKlQwb7zxhsvjPYy5eJt9RrfPZ/aYoMvFxcWZ7t27myJFihgfHx9TvXr1DB+PkJVHEZw9e9Y8/fTTpnDhwiYgIMC0atXKHD58OMNHtvzyyy8mOjra5M+f3/j7+5v77rvPrFmzJt00jx8/bvr3729KlChhfHx8TMmSJU3Xrl1dHl/x22+/maioKONwOExISIh58cUXTUxMTIaP48loW8hsGTOqcVxcnOnXr58pVaqU8fb2NqGhoaZJkyZm+vTpVptLH6tyqYweQ3Hq1Cnz6KOPmuDg4HSPu8lIRus3KSnJDB061JQvX974+PiYIkWKmHr16pk333zTnD9/3mXeb7zxRobLefn6mT17tqlUqZJxOBymWrVq5ttvvzXt2rUzlSpVcmm3Zs0aExERYXx8fFym07VrVxMQEJBuXpd/vufOnWuaNWtmihUrZnx8fEzp0qXNv/71L/PXX39dsQ4Z9ds57csf3ZXZI5sul9m6yMr6NMaYzZs3m7Zt25rChQsbh8NhypQpYzp06GCWLVt2xflnNp/nn3/eSDLvvfdelpczJSXFjBo1yoSHhxtvb29TqlQpM3ToUJfH5ThNnjzZSDJ9+vRxGR4VFWUkpet/Zsv/22+/mS5dupjQ0FDj7e1tSpQoYVq2bGnmzp3r0m7btm2mUaNGxtfX15QoUcKMGTPG/Oc//0m3DBcuXDDDhg0zoaGhxs/PzzRu3Njs3r3bFC5c2PTu3dtlmnY+C5lx7gcWL15satSoYRwOh6lUqVK69XHu3Dnz7LPPmuLFixs/Pz9Tv359s3bt2nT7/mnTppl77rnH2g7KlStnBg8ebE6ePOkyPTv7lMwkJyebIkWKmDFjxrgMz+xxPNdzzDhz5ox56aWXrG0pNDTUtG/f3uURM3aPX2fOnDE9evQwQUFBpkCBAqZDhw7WY6Gu9TO9Z88ec8899xg/P790j2rKSE4cA6/UBzvHvIweYZiammoeeeQR4+XlZebPn2+MufjooNdff91UrVrVOBwOU7BgQRMREWFGjRrlsn3ZWefJyclm8ODBpmbNmqZAgQImICDA1KxZ03o816Xq1KljHnvsMVu1uJTH/3cGwC2mVq1aKlq0aLY+Oge4FgkJCSpYsKBeeeUVvfTSS3ndnTw1ZswYzZgxQ/v27cu1GzNx69myZYvuvPNO/fLLL5ne/JeZbH+OI4AbS0pKSrqv+leuXKmtW7dm+BOdQE46e/ZsumHO6zbZHqVnnnlGp06d0uzZs/O6K7iJjRs3Tu3bt89yaJQkzjgCN7mDBw8qKipKjz32mMLCwrRnzx5NnTpVQUFB2rFjxxV/mgzIbjNnztTMmTP1wAMPKH/+/Prxxx/1+eefq1mzZhneCAPgxpLtDwAHcGMpWLCgIiIi9MEHH+jYsWMKCAhQixYtNG7cOEIjcl2NGjXk5eWl8ePHKzEx0bph5pVXXsnrrgGwgTOOAAAAsIVrHAEAAGALwREAAAC2cI3jNUpLS9PRo0dVoECBbP+JRAAAkDOMMUpKSlJYWFimvx2PzBEcr9HRo0fT/R4lAABwD4cPH1bJkiXzuhtuh+B4jZw/YXT48OEMf5fyWqWkpGjJkiVq1qxZpj8+j+tDjXMHdc551DjnUeOcl9s1TkxMVKlSpa75pwhvdQTHa+T8ejowMDDbg6O/v78CAwPZSeUQapw7qHPOo8Y5jxrnvLyqMZeZXRu+3AcAAIAtBEcAAADYQnAEAACALQRHAAAA2EJwBAAAgC0ERwAAANhCcAQAAIAtBEcAAADYQnAEAACALQRHAAAA2EJwBAAAgC0ERwAAANhCcAQAAIAtBEcAAADY4pXXHQBw8ys75Lu87kKWHRzXIq+7AAA3HM44AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGzxyusOIGPVRi5WcqpHXncjSw6Oa5HXXQAAADmIM44AAACwheAIAAAAWwiOAAAAsIVrHAE3U3bId3ndBVsc+YzG333xel3Jva7XBQBkjDOOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABb+MlBZBt3/Cm8va+2zOvuAADgNjjjCAAAAFvcLjimpqZq2LBhCg8Pl5+fn8qVK6cxY8bIGGO1McZo+PDhKl68uPz8/BQVFaV9+/a5TOfEiRPq3LmzAgMDFRwcrB49eujUqVO5vTgAAABuw+2C4+uvv64pU6bovffe0+7du/X6669r/PjxmjRpktVm/PjxevfddzV16lStX79eAQEBio6O1rlz56w2nTt31s6dOxUTE6MFCxZo9erV6tWrV14sEgAAgFtwu2sc16xZo9atW6tFixaSpLJly+rzzz/Xhg0bJF082zhx4kS9/PLLat26tSTp448/VkhIiObPn69OnTpp9+7dWrRokTZu3KjatWtLkiZNmqQHHnhAb775psLCwvJm4QAAAG5gbhcc69Wrp+nTp+vXX3/V7bffrq1bt+rHH3/UhAkTJEkHDhxQbGysoqKirPcEBQWpTp06Wrt2rTp16qS1a9cqODjYCo2SFBUVJU9PT61fv14PPfRQuvkmJycrOTnZep2YmChJSklJUUpKSrYtn3NaDk9zlZa4Vs7aOjxNtq673OLI5x7bxqV1dkfusG04++gOfXVX1Djn5XaNWZfXx+2C45AhQ5SYmKhKlSopX758Sk1N1auvvqrOnTtLkmJjYyVJISEhLu8LCQmxxsXGxqpYsWIu4728vFSoUCGrzeXGjh2rUaNGpRu+ZMkS+fv7X/dyXW5M7bRsnyZcjamdpu+//z6vu5Fl4+/O6x5kjbtuy+60bcTExOR1F2561Djn5VaNz5w5kyvzuVm5XXD88ssv9dlnn2nWrFmqWrWqtmzZooEDByosLExdu3bNsfkOHTpUgwYNsl4nJiaqVKlSatasmQIDA7NtPikpKYqJidGwnz2VnOaRbdPF/zg8jcbUTtOwnz21afj9ed2dLKs2cnFed8GWS+vsjtvyjpHRed2Fq3LuL5o2bSpvb++87s5NiRrnvNyusfMbQ1wbtwuOgwcP1pAhQ9SpUydJUvXq1fXHH39o7Nix6tq1q0JDQyVJcXFxKl68uPW+uLg41apVS5IUGhqq+Ph4l+leuHBBJ06csN5/OYfDIYfDkW64t7d3jmzoyWkeSk51v4OtO0lO83DLA4G7bRfuui2707aRU/sh/A81znm5VWPW4/Vxu7uqz5w5I09P127ny5dPaWkXvw4LDw9XaGioli1bZo1PTEzU+vXrFRkZKUmKjIxUQkKCNm3aZLVZvny50tLSVKdOnVxYCgAAAPfjdmccW7VqpVdffVWlS5dW1apVtXnzZk2YMEFPPPGEJMnDw0MDBw7UK6+8ogoVKig8PFzDhg1TWFiY2rRpI0mqXLmy7r//fj355JOaOnWqUlJS1L9/f3Xq1Ik7qgEAADLhdsFx0qRJGjZsmPr27av4+HiFhYXpX//6l4YPH261ef7553X69Gn16tVLCQkJatCggRYtWiRfX1+rzWeffab+/furSZMm8vT0VLt27fTuu+/mxSIBAAC4BbcLjgUKFNDEiRM1ceLETNt4eHho9OjRGj16dKZtChUqpFmzZuVADwEAAG5ObneNIwAAAPIGwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALZ45XUHgLxUdsh3ed0FAADcBmccAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGCLWwbHI0eO6LHHHlPhwoXl5+en6tWr6+eff7bGG2M0fPhwFS9eXH5+foqKitK+fftcpnHixAl17txZgYGBCg4OVo8ePXTq1KncXhQAAAC34XbB8Z9//lH9+vXl7e2thQsXateuXXrrrbdUsGBBq8348eP17rvvaurUqVq/fr0CAgIUHR2tc+fOWW06d+6snTt3KiYmRgsWLNDq1avVq1evvFgkAAAAt+CV1x3Iqtdff12lSpXSjBkzrGHh4eHW/40xmjhxol5++WW1bt1akvTxxx8rJCRE8+fPV6dOnbR7924tWrRIGzduVO3atSVJkyZN0gMPPKA333xTYWFhubtQAAAAbsDtguO3336r6OhoPfzww1q1apVKlCihvn376sknn5QkHThwQLGxsYqKirLeExQUpDp16mjt2rXq1KmT1q5dq+DgYCs0SlJUVJQ8PT21fv16PfTQQ+nmm5ycrOTkZOt1YmKiJCklJUUpKSnZtnzOaTk8TbZNE66ctaXGOcvd65ydn+uc4uyjO/TVXVHjnJfbNWZdXh+3C46///67pkyZokGDBunFF1/Uxo0b9fTTT8vHx0ddu3ZVbGysJCkkJMTlfSEhIda42NhYFStWzGW8l5eXChUqZLW53NixYzVq1Kh0w5csWSJ/f//sWDQXY2qnZfs04Yoa5w53rfP333+f112wLSYmJq+7cNOjxjkvt2p85syZXJnPzcrtgmNaWppq166t1157TZJ0xx13aMeOHZo6daq6du2aY/MdOnSoBg0aZL1OTExUqVKl1KxZMwUGBmbbfFJSUhQTE6NhP3sqOc0j26aL/3F4Go2pnUaNc5i713nHyOi87sJVOfcXTZs2lbe3d15356ZEjXNebtfY+Y0hro3bBcfixYurSpUqLsMqV66sefPmSZJCQ0MlSXFxcSpevLjVJi4uTrVq1bLaxMfHu0zjwoULOnHihPX+yzkcDjkcjnTDvb29c2RDT07zUHKq+x1s3Qk1zh3uWmd3Cgk5tR/C/1DjnJdbNWY9Xh+3u6u6fv362rt3r8uwX3/9VWXKlJF08UaZ0NBQLVu2zBqfmJio9evXKzIyUpIUGRmphIQEbdq0yWqzfPlypaWlqU6dOrmwFAAAAO7H7c44PvPMM6pXr55ee+01dejQQRs2bND06dM1ffp0SZKHh4cGDhyoV155RRUqVFB4eLiGDRumsLAwtWnTRtLFM5T333+/nnzySU2dOlUpKSnq37+/OnXqxB3VAAAAmXC74HjXXXfp66+/1tChQzV69GiFh4dr4sSJ6ty5s9Xm+eef1+nTp9WrVy8lJCSoQYMGWrRokXx9fa02n332mfr3768mTZrI09NT7dq107vvvpsXiwQAAOAW3C44SlLLli3VsmXLTMd7eHho9OjRGj16dKZtChUqpFmzZuVE9wAAAG5KbneNIwAAAPIGwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgi9sHx3HjxsnDw0MDBw60hp07d079+vVT4cKFlT9/frVr105xcXEu7zt06JBatGghf39/FStWTIMHD9aFCxdyufcAAADuw62D48aNGzVt2jTVqFHDZfgzzzyj//73v5ozZ45WrVqlo0ePqm3bttb41NRUtWjRQufPn9eaNWv00UcfaebMmRo+fHhuLwIAAIDbcNvgeOrUKXXu3Fn//ve/VbBgQWv4yZMn9Z///EcTJkxQ48aNFRERoRkzZmjNmjVat26dJGnJkiXatWuXPv30U9WqVUvNmzfXmDFjNHnyZJ0/fz6vFgkAAOCG5pXXHbhW/fr1U4sWLRQVFaVXXnnFGr5p0yalpKQoKirKGlapUiWVLl1aa9euVd26dbV27VpVr15dISEhVpvo6Gj16dNHO3fu1B133JFufsnJyUpOTrZeJyYmSpJSUlKUkpKSbcvlnJbD02TbNOHKWVtqnLPcvc7Z+bnOKc4+ukNf3RU1znm5XWPW5fVxy+A4e/Zs/fLLL9q4cWO6cbGxsfLx8VFwcLDL8JCQEMXGxlptLg2NzvHOcRkZO3asRo0alW74kiVL5O/vfy2LcUVjaqdl+zThihrnDnet8/fff5/XXbAtJiYmr7tw06PGOS+3anzmzJlcmc/Nyu2C4+HDhzVgwADFxMTI19c31+Y7dOhQDRo0yHqdmJioUqVKqVmzZgoMDMy2+aSkpCgmJkbDfvZUcppHtk0X/+PwNBpTO40a5zB3r/OOkdF53YWrcu4vmjZtKm9v77zuzk2JGue83K6x8xtDXBu3C46bNm1SfHy87rzzTmtYamqqVq9erffee0+LFy/W+fPnlZCQ4HLWMS4uTqGhoZKk0NBQbdiwwWW6zruunW0u53A45HA40g339vbOkQ09Oc1Dyanud7B1J9Q4d7hrnd0pJOTUfgj/Q41zXm7VmPV4fdzu5pgmTZpo+/bt2rJli/Wvdu3a6ty5s/V/b29vLVu2zHrP3r17dejQIUVGRkqSIiMjtX37dsXHx1ttYmJiFBgYqCpVquT6MgEAALgDtzvjWKBAAVWrVs1lWEBAgAoXLmwN79GjhwYNGqRChQopMDBQTz31lCIjI1W3bl1JUrNmzVSlShU9/vjjGj9+vGJjY/Xyyy+rX79+GZ5VBAAAgBsGRzvefvtteXp6ql27dkpOTlZ0dLTef/99a3y+fPm0YMEC9enTR5GRkQoICFDXrl01evToPOw1AADAje2mCI4rV650ee3r66vJkydr8uTJmb6nTJkybnXXJAAAQF5zu2scAQAAkDcIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwxSuvOwAAN6KyQ77L6y5clSOf0fi7pWojFys51UMHx7XI6y4BuMlxxhEAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALYQHAEAAGALwREAAAC2EBwBAABgC8ERAAAAthAcAQAAYAvBEQAAALa4XXAcO3as7rrrLhUoUEDFihVTmzZttHfvXpc2586dU79+/VS4cGHlz59f7dq1U1xcnEubQ4cOqUWLFvL391exYsU0ePBgXbhwITcXBQAAwK24XXBctWqV+vXrp3Xr1ikmJkYpKSlq1qyZTp8+bbV55pln9N///ldz5szRqlWrdPToUbVt29Yan5qaqhYtWuj8+fNas2aNPvroI82cOVPDhw/Pi0UCAABwC1553YGsWrRokcvrmTNnqlixYtq0aZPuuecenTx5Uv/5z380a9YsNW7cWJI0Y8YMVa5cWevWrVPdunW1ZMkS7dq1S0uXLlVISIhq1aqlMWPG6IUXXtDIkSPl4+OTF4sGAABwQ3O74Hi5kydPSpIKFSokSdq0aZNSUlIUFRVltalUqZJKly6ttWvXqm7dulq7dq2qV6+ukJAQq010dLT69OmjnTt36o477kg3n+TkZCUnJ1uvExMTJUkpKSlKSUnJtuVxTsvhabJtmnDlrC01zlnUOeddXuPs3BfhImdNqW3Oye0asy6vj1sHx7S0NA0cOFD169dXtWrVJEmxsbHy8fFRcHCwS9uQkBDFxsZabS4Njc7xznEZGTt2rEaNGpVu+JIlS+Tv73+9i5LOmNpp2T5NuKLGuYM65zxnjb///vs87snNKyYmJq+7cNPLrRqfOXMmV+Zzs3Lr4NivXz/t2LFDP/74Y47Pa+jQoRo0aJD1OjExUaVKlVKzZs0UGBiYbfNJSUlRTEyMhv3sqeQ0j2ybLv7H4Wk0pnYaNc5h1DnnXV7jHSOj87pLNx3nPrlp06by9vbO6+7clHK7xs5vDHFt3DY49u/fXwsWLNDq1atVsmRJa3hoaKjOnz+vhIQEl7OOcXFxCg0Ntdps2LDBZXrOu66dbS7ncDjkcDjSDff29s6RDT05zUPJqRxscxI1zh3UOec5a0ywyTk5ta/H/+RWjVmP18ft7qo2xqh///76+uuvtXz5coWHh7uMj4iIkLe3t5YtW2YN27t3rw4dOqTIyEhJUmRkpLZv3674+HirTUxMjAIDA1WlSpXcWRAAAAA343ZnHPv166dZs2bpm2++UYECBaxrEoOCguTn56egoCD16NFDgwYNUqFChRQYGKinnnpKkZGRqlu3riSpWbNmqlKlih5//HGNHz9esbGxevnll9WvX78MzyoCAADADYPjlClTJEn33nuvy/AZM2aoW7dukqS3335bnp6eateunZKTkxUdHa3333/fapsvXz4tWLBAffr0UWRkpAICAtS1a1eNHj06txYDAADA7bhdcDTm6o/28PX11eTJkzV58uRM25QpU4Y7EAEAALLA7a5xBAAAQN4gOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhOAIAAMAWgiMAAABsITgCAADAFq+87gAAIHuUHfJdXnchyw6Oa5HXXQCQBZxxBAAAgC0ERwAAANhCcAQAAIAtBEcAAADYQnAEAACALQRHAAAA2EJwBAAAgC0ERwAAANhCcAQAAIAtBEcAAADYwk8OAgDyzI3+M4mOfEbj75aqjVys5FQPSfxMIm5tnHEEAACALQRHAAAA2EJwBAAAgC0ERwAAANhCcAQAAIAtBEcAAADYQnAEAACALTzHEQCALLjRnz2ZEZ49iezCGUcAAADYQnAEAACALQRHAAAA2HLLB8fJkyerbNmy8vX1VZ06dbRhw4a87hIAAMAN6ZYOjl988YUGDRqkESNG6JdfflHNmjUVHR2t+Pj4vO4aAADADeeWDo4TJkzQk08+qe7du6tKlSqaOnWq/P399eGHH+Z11wAAAG44t+zjeM6fP69NmzZp6NCh1jBPT09FRUVp7dq16donJycrOTnZen3y5ElJ0okTJ5SSkpJt/UpJSdGZM2fkleKp1DSPbJsu/scrzejMmTRqnMOoc86jxjnvZqnx8ePH87oLmXIe944fPy5vb+8cn19SUpIkyRiT4/O6Gd2ywfHvv/9WamqqQkJCXIaHhIRoz5496dqPHTtWo0aNSjc8PDw8x/qInPNoXnfgFkGdcx41znk3Q42LvJXXPbjxJCUlKSgoKK+74XZu2eCYVUOHDtWgQYOs12lpaTpx4oQKFy4sD4/s+ys0MTFRpUqV0uHDhxUYGJht08X/UOPcQZ1zHjXOedQ45+V2jY0xSkpKUlhYWI7P62Z0ywbHIkWKKF++fIqLi3MZHhcXp9DQ0HTtHQ6HHA6Hy7Dg4OAc619gYCA7qRxGjXMHdc551DjnUeOcl5s15kzjtbtlb47x8fFRRESEli1bZg1LS0vTsmXLFBkZmYc9AwAAuDHdsmccJWnQoEHq2rWrateurbvvvlsTJ07U6dOn1b1797zuGgAAwA3nlg6OHTt21LFjxzR8+HDFxsaqVq1aWrRoUbobZnKTw+HQiBEj0n0tjuxDjXMHdc551DjnUeOcR43di4fhfnQAAADYcMte4wgAAICsITgCAADAFoIjAAAAbCE4AgAAwBaCIwAAAGwhON5gJk+erLJly8rX11d16tTRhg0b8rpLN6TVq1erVatWCgsLk4eHh+bPn+8y3hij4cOHq3jx4vLz81NUVJT27dvn0ubEiRPq3LmzAgMDFRwcrB49eujUqVMubbZt26aGDRvK19dXpUqV0vjx43N60W4YY8eO1V133aUCBQqoWLFiatOmjfbu3evS5ty5c+rXr58KFy6s/Pnzq127dul+jenQoUNq0aKF/P39VaxYMQ0ePFgXLlxwabNy5UrdeeedcjgcKl++vGbOnJnTi3dDmDJlimrUqGH9YkZkZKQWLlxojae+2W/cuHHy8PDQwIEDrWHU+fqNHDlSHh4eLv8qVapkjafGNxGDG8bs2bONj4+P+fDDD83OnTvNk08+aYKDg01cXFxed+2G8/3335uXXnrJfPXVV0aS+frrr13Gjxs3zgQFBZn58+ebrVu3mgcffNCEh4ebs2fPWm3uv/9+U7NmTbNu3Trzww8/mPLly5tHHnnEGn/y5EkTEhJiOnfubHbs2GE+//xz4+fnZ6ZNm5Zbi5mnoqOjzYwZM8yOHTvMli1bzAMPPGBKly5tTp06ZbXp3bu3KVWqlFm2bJn5+eefTd26dU29evWs8RcuXDDVqlUzUVFRZvPmzeb77783RYoUMUOHDrXa/P7778bf398MGjTI7Nq1y0yaNMnky5fPLFq0KFeXNy98++235rvvvjO//vqr2bt3r3nxxReNt7e32bFjhzGG+ma3DRs2mLJly5oaNWqYAQMGWMOp8/UbMWKEqVq1qvnrr7+sf8eOHbPGU+ObB8HxBnL33Xebfv36Wa9TU1NNWFiYGTt2bB726sZ3eXBMS0szoaGh5o033rCGJSQkGIfDYT7//HNjjDG7du0ykszGjRutNgsXLjQeHh7myJEjxhhj3n//fVOwYEGTnJxstXnhhRdMxYoVc3iJbkzx8fFGklm1apUx5mJNvb29zZw5c6w2u3fvNpLM2rVrjTEXA76np6eJjY212kyZMsUEBgZadX3++edN1apVXebVsWNHEx0dndOLdEMqWLCg+eCDD6hvNktKSjIVKlQwMTExplGjRlZwpM7ZY8SIEaZmzZoZjqPGNxe+qr5BnD9/Xps2bVJUVJQ1zNPTU1FRUVq7dm0e9sz9HDhwQLGxsS61DAoKUp06daxarl27VsHBwapdu7bVJioqSp6enlq/fr3V5p577pGPj4/VJjo6Wnv37tU///yTS0tz4zh58qQkqVChQpKkTZs2KSUlxaXOlSpVUunSpV3qXL16dZdfY4qOjlZiYqJ27txptbl0Gs42t9p2n5qaqtmzZ+v06dOKjIykvtmsX79+atGiRbpaUOfss2/fPoWFhem2225T586ddejQIUnU+GZDcLxB/P3330pNTU33c4chISGKjY3No165J2e9rlTL2NhYFStWzGW8l5eXChUq5NImo2lcOo9bRVpamgYOHKj69eurWrVqki7WwMfHR8HBwS5tL6/z1WqYWZvExESdPXs2JxbnhrJ9+3blz59fDodDvXv31tdff60qVapQ32w0e/Zs/fLLLxo7dmy6cdQ5e9SpU0czZ87UokWLNGXKFB04cEANGzZUUlISNb7J3NK/VQ3Ann79+mnHjh368ccf87orN52KFStqy5YtOnnypObOnauuXbtq1apVed2tm8bhw4c1YMAAxcTEyNfXN6+7c9Nq3ry59f8aNWqoTp06KlOmjL788kv5+fnlYc+Q3TjjeIMoUqSI8uXLl+4us7i4OIWGhuZRr9yTs15XqmVoaKji4+Ndxl+4cEEnTpxwaZPRNC6dx62gf//+WrBggVasWKGSJUtaw0NDQ3X+/HklJCS4tL+8zlerYWZtAgMDb4kDjo+Pj8qXL6+IiAiNHTtWNWvW1DvvvEN9s8mmTZsUHx+vO++8U15eXvLy8tKqVav07rvvysvLSyEhIdQ5BwQHB+v222/X/v372ZZvMgTHG4SPj48iIiK0bNkya1haWpqWLVumyMjIPOyZ+wkPD1doaKhLLRMTE7V+/XqrlpGRkUpISNCmTZusNsuXL1daWprq1KljtVm9erVSUlKsNjExMapYsaIKFiyYS0uTd4wx6t+/v77++mstX75c4eHhLuMjIiLk7e3tUue9e/fq0KFDLnXevn27S0iPiYlRYGCgqlSpYrW5dBrONrfqdp+Wlqbk5GTqm02aNGmi7du3a8uWLda/2rVrq3Pnztb/qXP2O3XqlH777TcVL16cbflmk9d35+B/Zs+ebRwOh5k5c6bZtWuX6dWrlwkODna5ywwXJSUlmc2bN5vNmzcbSWbChAlm8+bN5o8//jDGXHwcT3BwsPnmm2/Mtm3bTOvWrTN8HM8dd9xh1q9fb3788UdToUIFl8fxJCQkmJCQEPP444+bHTt2mNmzZxt/f/9b5nE8ffr0MUFBQWblypUuj9g4c+aM1aZ3796mdOnSZvny5ebnn382kZGRJjIy0hrvfMRGs2bNzJYtW8yiRYtM0aJFM3zExuDBg83u3bvN5MmTb5lHbAwZMsSsWrXKHDhwwGzbts0MGTLEeHh4mCVLlhhjqG9OufSuamOoc3Z49tlnzcqVK82BAwfMTz/9ZKKiokyRIkVMfHy8MYYa30wIjjeYSZMmmdKlSxsfHx9z9913m3Xr1uV1l25IK1asMJLS/evatasx5uIjeYYNG2ZCQkKMw+EwTZo0MXv37nWZxvHjx80jjzxi8ufPbwIDA0337t1NUlKSS5utW7eaBg0aGIfDYUqUKGHGjRuXW4uY5zKqryQzY8YMq83Zs2dN3759TcGCBY2/v7956KGHzF9//eUynYMHD5rmzZsbPz8/U6RIEfPss8+alJQUlzYrVqwwtWrVMj4+Pua2225zmcfN7IknnjBlypQxPj4+pmjRoqZJkyZWaDSG+uaUy4Mjdb5+HTt2NMWLFzc+Pj6mRIkSpmPHjmb//v3WeGp88/Awxpi8OdcJAAAAd8I1jgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsIXgCAAAAFsIjgAAALCF4AgAAABbCI4AAACwheAIAAAAWwiOAAAAsOX/AHKKH0s6UMTBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Lets find out the max token size using the embedding model for the chunk_size\n",
    "# if the max_token_length is < chunk_size, we need to increase the chunk_size or vise-versa\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v2-base-en\", use_fast=False)\n",
    "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "\n",
    "# Plot the distribution of document lengths, counted as the number of tokens\n",
    "fig = pd.Series(lengths).hist()\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4647"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Note: this will not work on a Macbook effectively\n",
    "\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"jinaai/jina-embeddings-v2-base-en\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=False,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True, \"batch_size\": 5},\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.24.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/riaz/miniconda3/envs/cookbook/lib/python3.10/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/riaz/miniconda3/envs/cookbook/lib/python3.10/site-packages (from plotly) (23.2)\n",
      "Downloading plotly-5.24.0-py3-none-any.whl (19.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: plotly\n",
      "Successfully installed plotly-5.24.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install pacmap datasets langchain-community ragatouille faiss-cpu plotly openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6266e1d8370b4decb4ee66261871b35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e72ff5afad4c099665d95e0bcb6966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"How to create a pipeline object?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riaz/miniconda3/envs/cookbook/lib/python3.10/site-packages/pacmap/pacmap.py:822: UserWarning: Warning: random state is set to 1\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    }
   ],
   "source": [
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Create an Endpoint\n\nAfter your first login, you will be directed to the [Endpoint creation page](htt..."
          ],
          [
           "Access and read Logs\n\nHugging Face Endpoints provides access to the logs of your Endpoints through t..."
          ],
          [
           "Hugging Face Inference Endpoints documentation\n\n## Setup\n\n```bash\npip install hf-doc-builder==0.4.0 ..."
          ],
          [
           "Pricing\n\n<div class=\"flex md:justify-start mb-2 text-gray-400 items-center\">\n  <a href=\"https://ui.e..."
          ],
          [
           "Supported Transformers & Diffusers Tasks\n\nInference Endpoints offers out-of-the-box support for Mach..."
          ],
          [
           "```\n\n### Image Segmentation\n\nImage Segmentation can receive `json` payloads or binary data from a `i..."
          ],
          [
           "Access and view Metrics\n\nHugging Face Endpoints provides access to the metrics and analytics of your..."
          ],
          [
           "# FAQs \n\n\n\n### Q: In which regions are Inference Endpoints available?\n\nA: Inference Endpoints are cu..."
          ],
          [
           "Help & Support \n\nWe have a variety of Inference Endpoints blog posts to help you at https://huggingf..."
          ],
          [
           "Pause and Resume your Endpoint\n\nYou can `pause` & `resume` endpoints to save cost and configurations..."
          ],
          [
           "API Reference (Swagger)\n\n🤗 Inference Endpoints can be used through the [UI](https://ui.endpoints.hug..."
          ],
          [
           "Use a custom Container Image\n\n\nInference Endpoints not only allows you to [customize your inference ..."
          ],
          [
           "Autoscaling\n\nAutoscaling allows you to dynamically adjust the number of endpoint replicas running yo..."
          ],
          [
           "Create a Private Endpoint with AWS PrivateLink\n\nSecurity and secure inference are key principles of ..."
          ],
          [
           "Security & Compliance\n\n🤗 Inference Endpoints is built with security and secure inference at its core..."
          ],
          [
           "Send Requests to Endpoints\n\nYou can send requests to Inference Endpoints using the UI leveraging the..."
          ],
          [
           "Change Organization or Account\n\nInference Endpoints uses your [Hugging Face](https://huggingface.co/..."
          ],
          [
           "Update your Endpoint\n\nYou can update `running` Endpoints to change some of the configurations. Howev..."
          ],
          [
           "Advanced Setup (Instance Types, Auto Scaling, Versioning)\n\nWe have seen how fast and easy it is to d..."
          ],
          [
           "Inference Endpoints Version\n\nHugging Face Inference Endpoints comes with a default serving container..."
          ],
          [
           "Serialization & Deserialization for Requests\n\nHugging Face Inference Endpount comes with a default s..."
          ],
          [
           "🤗 Inference Endpoints\n\n🤗 Inference Endpoints offers a secure production solution to easily deploy an..."
          ],
          [
           "Access 🤗 Inference Endpoints\n\nTo access the [Inference Endpoints web application](https://ui.endpoin..."
          ],
          [
           "Add custom Dependencies\n\nInference Endpoints’ base image includes all required libraries to run infe..."
          ],
          [
           "Create custom Inference Handler\n\nHugging Face Endpoints supports all of the Transformers and Sentenc..."
          ],
          [
           "```\n\n### 4. Test EndpointHandler\n\nTo test our EndpointHandler, we can simplify import, initialize an..."
          ]
         ],
         "hovertemplate": "source=hf-endpoints-documentation<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "hf-endpoints-documentation, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hf-endpoints-documentation, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -0.7082606,
          2.422584,
          0.06330848,
          -1.318277,
          -2.129853,
          1.2278214,
          -2.2145948,
          3.3455293,
          -2.4307833,
          -1.9449507,
          -0.22105877,
          -0.2666941,
          0.9994245,
          -2.36634,
          -3.8509178,
          2.2464495,
          0.091226876,
          -1.684869,
          4.7721543,
          -0.87017417,
          -2.2930646,
          1.9291008,
          0.7473169,
          0.481155,
          3.7027044,
          -1.3395307
         ],
         "xaxis": "x",
         "y": [
          -2.6361048,
          -2.1116457,
          -5.946178,
          -4.4405355,
          -4.489286,
          -5.0719275,
          -1.3842578,
          -1.0061685,
          1.280053,
          -0.03795459,
          -4.53829,
          -2.688548,
          3.0978127,
          -2.6848671,
          2.9637904,
          -1.4847618,
          1.9838398,
          -1.1726893,
          0.028495764,
          -4.9394407,
          -5.0084357,
          1.3620868,
          3.8045788,
          -1.1883972,
          -1.4055876,
          2.5298395
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Choosing a metric for your task\n\n**So you've trained your model and want to see how well it’s doing ..."
          ],
          [
           "--\ntitle: poseval\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: a..."
          ],
          [
           "--\ntitle: MAPE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: ROUGE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app..."
          ],
          [
           "--\ntitle: Word Length\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0.2\napp_f..."
          ],
          [
           "Working with Keras and Tensorflow\n\n\n\nEvaluate can be easily intergrated into your Keras and Tensorfl..."
          ],
          [
           "--\ntitle: CharCut\nemoji: 🔤\ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ap..."
          ],
          [
           "--\ntitle: IndicGLUE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "--\ntitle: Google BLEU\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_fil..."
          ],
          [
           "```\n\n## Limitations and Bias\n\nThe GoogleBLEU metric does not come with a predefined tokenization fun..."
          ],
          [
           "--\ntitle: \nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.py\np..."
          ],
          [
           "--\ntitle: Mean IoU\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ..."
          ],
          [
           "--\ntitle: SuperGLUE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "🤗 Transformers\n\nTo run the 🤗 Transformers examples make sure you have installed the following librar..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n    Args:\n        n_layers (`int`): The number of layers of the model.\n```\n\nIf the description i..."
          ],
          [
           "--\ntitle: Spearman Correlation Coefficient Metric \nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradi..."
          ],
          [
           "--\ntitle: TREC Eval\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "A quick tour\n\n🤗 Evaluate provides access to a wide range of evaluation tools. It covers a range of m..."
          ],
          [
           "```\n\nOnce you have gathered all predictions you can call `compute()` to compute the score based on a..."
          ],
          [
           "```\n\nCalculating the value of the metric alone is often not enough to know if a model performs signi..."
          ],
          [
           "Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge..."
          ],
          [
           "Using the `evaluator` with custom pipelines\n\nThe evaluator is designed to work with `transformer` pi..."
          ],
          [
           "--\ntitle: Matthews Correlation Coefficient\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_ve..."
          ],
          [
           "Evaluator\n\nThe evaluator classes for automatic evaluation.\n\n## Evaluator classes\n\nThe main entry poi..."
          ],
          [
           "Using the `evaluator`\n\nThe `Evaluator` classes allow to evaluate a  triplet of model, dataset, and m..."
          ],
          [
           "```\n\nThe result is a table that looks like this:\n\n|   model                                         ..."
          ],
          [
           "--\ntitle: Exact Match\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_fil..."
          ],
          [
           "--\ntitle: Wilcoxon\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: green\nsdk: gradio\nsdk_version: 3.0.2\napp_file:..."
          ],
          [
           "--\ntitle: SQuAD v2\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ..."
          ],
          [
           "```\n    \n## Further References \n\n- [The Stanford Question Answering Dataset: Background, Challenges,..."
          ],
          [
           "--\ntitle: BLEU\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "```\n\nExample with the word tokenizer from NLTK:\n```python\n>>> bleu = evaluate.load(\"bleu\")\n>>> from ..."
          ],
          [
           "--\ntitle: Pearson Correlation Coefficient \nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_ve..."
          ],
          [
           "--\ntitle: Code Eval\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/datasets/evaluate/media/resolve/main..."
          ],
          [
           "Types of Evaluations in 🤗 Evaluate\n\nThe goal of the 🤗 Evaluate library is to support different types..."
          ],
          [
           "--\ntitle: WER\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.p..."
          ],
          [
           "--\ntitle: chrF\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: Regard\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0.2\napp_file: ..."
          ],
          [
           "--\ntitle: Honest\nemoji: 🤗\ncolorFrom: blue\ncolorTo: green\nsdk: gradio\nsdk_version: 3.0.2\napp_file: ap..."
          ],
          [
           "--\ntitle: SQuAD\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app..."
          ],
          [
           "--\ntitle: Recall\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ap..."
          ],
          [
           "--\ntitle: BERT Score\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file..."
          ],
          [
           "--\ntitle: Competition MATH\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\nap..."
          ],
          [
           "--\ntitle: MSE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.p..."
          ],
          [
           "--\ntitle: WikiSplit\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "--\ntitle: r_squared\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.0.2\napp_file: ..."
          ],
          [
           "--\ntitle: Precision\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "--\ntitle: XTREME-S\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ..."
          ],
          [
           "--\ntitle: CER\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.p..."
          ],
          [
           "--\ntitle: {{ cookiecutter.module_name }}\ndatasets:\n- {{ cookiecutter.dataset_name }} \ntags:\n- evalua..."
          ],
          [
           "--\ntitle: McNemar\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: green\nsdk: gradio\nsdk_version: 3.0.2\napp_file: ..."
          ],
          [
           "--\ntitle: F1\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.py..."
          ],
          [
           "Considerations for model evaluation\n\nDeveloping an ML model is rarely a one-shot deal: it often invo..."
          ],
          [
           "Inference speed refers to the time that it takes for a model to make a prediction -- this will vary ..."
          ],
          [
           "--\ntitle: Mahalanobis Distance\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19...."
          ],
          [
           "--\ntitle: MAUVE\nemoji: 🤗\ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: BLEURT\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ap..."
          ],
          [
           "--\ntitle: Label Distribution\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0...."
          ],
          [
           "--\ntitle: XNLI\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: Text Duplicates\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0.2\na..."
          ],
          [
           "Creating an EvaluationSuite\n\nIt can be useful to evaluate models on a variety of different tasks to ..."
          ],
          [
           "--\ntitle: MAE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.p..."
          ],
          [
           "--\ntitle: GLUE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "Scikit-Learn\n\nTo run the scikit-learn examples make sure you have installed the following library:\n\n..."
          ],
          [
           "Logging methods\n\n🤗 Evaluate strives to be transparent and explicit about how it works, but this can ..."
          ],
          [
           "Installation\n\nBefore you start, you will need to setup your environment and install the appropriate ..."
          ],
          [
           "--\ntitle: Word Count\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0.2\napp_fi..."
          ],
          [
           "--\ntitle: seqeval\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: a..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/datasets/evaluate/media/resolve/main..."
          ],
          [
           "--\ntitle: SARI\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: METEOR\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ap..."
          ],
          [
           "--\ntitle: CharacTER\nemoji: 🔤\ncolorFrom: orange\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n   If you're modifying documents under `docs/source`, make sure to validate that\n   they can st..."
          ],
          [
           "--\ntitle: MASE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "--\ntitle: sMAPE\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app..."
          ],
          [
           "Saving methods\n\nMethods for saving evaluations results:\n\n## Save\n\n[[autodoc]] evaluate.save..."
          ],
          [
           "--\ntitle: Exact Match \nemoji: 🤗 \ncolorFrom: blue\ncolorTo: green\nsdk: gradio\nsdk_version: 3.0.2\napp_f..."
          ],
          [
           "--\ntitle: Perplexity\nemoji: 🤗\ncolorFrom: green\ncolorTo: purple\nsdk: gradio\nsdk_version: 3.0.2\napp_fi..."
          ],
          [
           "--\ntitle: Accuracy\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: ..."
          ],
          [
           "--\ntitle: RL Reliability\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_..."
          ],
          [
           "--\ntitle: \nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.py\np..."
          ],
          [
           "```\nIt also has several optional arguments:\n\n`keep_singletons`: After extracting all mentions of key..."
          ],
          [
           "```\n\n## Limitations and bias\n\nThis wrapper of CoVal currently only works with [CoNLL line format](ht..."
          ],
          [
           "```\n\n```bibtex\n@INPROCEEDINGS{Bagga98algorithmsfor,\n    author = {Amit Bagga and Breck Baldwin},\n   ..."
          ],
          [
           "--\ntitle: CUAD\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app...."
          ],
          [
           "```\n    \n## Further References \n\n- [CUAD dataset homepage](https://www.atticusprojectai.org/cuad-v1-..."
          ],
          [
           "Visualization methods\n\nMethods for visualizing evaluations results:\n\n## Radar Plot\n\n[[autodoc]] eval..."
          ],
          [
           "--\ntitle: TER\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app.p..."
          ],
          [
           "```\n\nExample ignoring punctuation and capitalization, but with an extra (incorrect) sample:\n```pytho..."
          ],
          [
           "--\ntitle: Toxicity\nemoji: 🤗\ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.0.2\napp_file: ap..."
          ],
          [
           "Hub methods\n\nMethods for using the Hugging Face Hub:\n\n## Push to hub \n\n[[autodoc]] evaluate.push_to_..."
          ],
          [
           "--\ntitle: COMET\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: app..."
          ],
          [
           "```\n\nNo match:\n\n```python\nfrom evaluate import load\ncomet_metric = load('comet') \nsource = [\"Dem Feu..."
          ],
          [
           "--\ntitle: Brier Score\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_fil..."
          ],
          [
           "--\ntitle: Perplexity\nemoji: 🤗\ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "Loading methods\n\nMethods for listing and loading evaluation modules:\n\n## List\n\n[[autodoc]] evaluate...."
          ],
          [
           "Creating and sharing a new evaluation\n\n## Setup\n\nBefore you can create a new metric make sure you ha..."
          ],
          [
           "Main classes\n\n## EvaluationModuleInfo\n\nThe base class `EvaluationModuleInfo` implements a the logic ..."
          ],
          [
           "--\ntitle: SacreBLEU\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ],
          [
           "--\ntitle: ROC AUC\nemoji: 🤗 \ncolorFrom: blue\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file: a..."
          ],
          [
           "```\n\nExample 2, the **multiclass** use case:\n```python\n>>> roc_auc_score = evaluate.load(\"roc_auc\", ..."
          ],
          [
           "--\ntitle: NIST_MT\nemoji: 🤗 \ncolorFrom: purple\ncolorTo: red\nsdk: gradio\nsdk_version: 3.19.1\napp_file:..."
          ]
         ],
         "hovertemplate": "source=evaluate<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "evaluate, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "evaluate, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -3.630602,
          -0.84012383,
          1.9184963,
          -4.005448,
          -3.9675362,
          3.5360796,
          0.9793184,
          2.2556505,
          4.5011907,
          -4.240092,
          0.85147506,
          4.645079,
          -2.8560014,
          -2.1880152,
          -1.9806528,
          0.06708525,
          -2.6190603,
          -1.981233,
          -0.57768345,
          1.9443312,
          2.019865,
          1.9444659,
          -3.1498926,
          1.2802684,
          -1.523125,
          -2.8660796,
          -0.6009516,
          -3.3812191,
          -1.3634397,
          0.12732111,
          -0.7165786,
          4.3592443,
          0.08723941,
          4.5083385,
          -0.83997905,
          -3.1768546,
          4.808732,
          -0.625369,
          2.918312,
          -3.4319122,
          -3.9238834,
          -0.66002226,
          -1.9148201,
          1.7271031,
          -3.2485385,
          1.2151297,
          2.475425,
          2.2488453,
          5.025496,
          1.9337361,
          4.9171844,
          1.5416808,
          -2.6784003,
          -1.0676572,
          -1.8405342,
          -0.21614319,
          5.177173,
          4.173349,
          0.50728494,
          -3.6628573,
          -4.04153,
          -1.3652257,
          -2.6172678,
          3.7601764,
          -0.10183781,
          -1.6343462,
          1.079419,
          -3.043399,
          1.0005987,
          -1.575035,
          0.19420248,
          -2.2062736,
          -2.7431266,
          4.057144,
          1.5871016,
          -1.3868836,
          -0.6777815,
          2.9390101,
          -4.481618,
          -2.1839952,
          2.2525306,
          3.1592002,
          1.4016005,
          0.88063115,
          2.9154954,
          -4.5925374,
          -0.051068485,
          3.3439028,
          -1.4703969,
          2.5445802,
          4.2870407,
          -3.2971404,
          3.133562,
          0.08308519,
          0.98201025,
          -0.6899362,
          -3.082951,
          4.5012894,
          -2.362877,
          -4.3321304,
          -2.2084548,
          1.6393603,
          3.695083,
          0.76118,
          2.3762753
         ],
         "xaxis": "x",
         "y": [
          0.3496138,
          0.22781165,
          -1.8174491,
          0.9738747,
          -0.24116096,
          1.5118362,
          -0.7105906,
          -2.8181667,
          -0.61950475,
          3.0310879,
          -2.7031538,
          0.3008236,
          1.0248927,
          -4.1805987,
          0.1732633,
          2.1053355,
          -0.41527092,
          2.8721642,
          -1.7470663,
          2.6557393,
          -2.176642,
          4.616044,
          -3.4616153,
          -2.8699956,
          -5.675672,
          -0.5665219,
          1.7199833,
          -2.2366877,
          -2.262345,
          -3.397741,
          1.5890573,
          1.2561843,
          -2.9706166,
          1.1670556,
          0.66658086,
          1.1439105,
          0.11286918,
          -0.7695558,
          -2.4107463,
          0.847166,
          2.4969387,
          -0.38337427,
          0.86511254,
          -1.4163145,
          -2.2776537,
          -3.782262,
          0.7245754,
          1.6467544,
          0.4893933,
          -3.7572074,
          0.9518318,
          2.1960535,
          1.2302465,
          -2.669563,
          2.6688738,
          1.0969485,
          1.2062116,
          1.0952815,
          -1.2709507,
          0.7835592,
          1.2240254,
          -6.3210826,
          0.60934937,
          2.122068,
          -2.6058736,
          1.0917203,
          1.0899469,
          -3.387285,
          -4.035707,
          1.9333584,
          -2.33028,
          -1.2625198,
          3.19313,
          0.9611286,
          -2.8472679,
          1.0344571,
          -4.803724,
          -1.7041738,
          -2.86501,
          -3.241007,
          0.37232438,
          2.6388626,
          -2.4341388,
          -0.5041185,
          2.6083477,
          1.8095207,
          -5.136468,
          -1.8815868,
          -2.8957582,
          -3.026442,
          0.024000185,
          -0.24875906,
          -1.0017182,
          1.434338,
          -3.1442657,
          2.286491,
          -3.0709686,
          0.7079909,
          -5.8087564,
          0.42482457,
          -5.6421375,
          -4.193237,
          1.2424879,
          4.038202,
          -0.21763347
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "主要特点\n\n让我们来介绍一下 Gradio 最受欢迎的一些功能！这里是 Gradio 的主要特点：\n\n1. [添加示例输入](#example-inputs)\n2. [传递自定义错误消息](#erro..."
          ],
          [
           "Gradio Demo: blocks_random_slider\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n\nimport gradio as gr\n\n\ndef..."
          ],
          [
           "State in Blocks\n\nWe covered [State in Interfaces](https://gradio.app/interface-state), this guide ta..."
          ],
          [
           "如何使用地图组件绘制图表\n\nRelated spaces:\nTags: PLOTS, MAPS\n\n## 简介\n\n本指南介绍如何使用 Gradio 的 `Plot` 组件在地图上绘制地理数据。Gradi..."
          ],
          [
           "Gradio Demo: examples_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the..."
          ],
          [
           "Gradio Demo: number_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr...."
          ],
          [
           "Gradio Demo: map_airbnb\n### Display an interactive map of AirBnB locations with Plotly. Data is host..."
          ],
          [
           "Gradio Demo: question-answering\n\n\n```\n!pip install -q gradio torch transformers\n```\n\n\n```\nimport gra..."
          ],
          [
           "`@gradio/button`\n\n```html\n<script>\n\timport { Button } from \"@gradio/button\";\n</script>\n\n<button type..."
          ],
          [
           "Gradio Demo: sales_projections\n\n\n```\n!pip install -q gradio pandas numpy matplotlib\n```\n\n\n```\nimport..."
          ],
          [
           "Gradio and W&B Integration\n\nRelated spaces: https://huggingface.co/spaces/akhaliq/JoJoGAN\nTags: WAND..."
          ],
          [
           "```\n\n4. Save, Download, and Load Model\n\n    Here's how to save and download your model.\n\n```python\n\n..."
          ],
          [
           "Gradio Demo: duplicatebutton_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n..."
          ],
          [
           "Gradio Demo: upload_button_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as..."
          ],
          [
           "@gradio/imageeditor\n\n## 0.2.0\n\n### Features\n\n- [#6809](https://github.com/gradio-app/gradio/pull/680..."
          ],
          [
           "Gradio Demo: chatinterface_system_prompt\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr..."
          ],
          [
           "Gradio Demo: streaming_wav2vec\n\n\n```\n!pip install -q gradio torch transformers \n```\n\n\n```\nfrom trans..."
          ],
          [
           "component-styles\n\n## Textbox\n\n| name        | type                                 | description    ..."
          ],
          [
           "Gradio Demo: blocks_webcam\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport numpy as np\n\nimport gradio..."
          ],
          [
           "Gradio Demo: on_listener_live\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.B..."
          ],
          [
           "主题 Theming\n\nTags: THEMES\n\n## 介绍\n\nGradio 具有内置的主题引擎，可让您自定义应用的外观和感觉。您可以选择各种主题，或者创建自己的主题。要这样做，请将 `theme=..."
          ],
          [
           "```\n\n现在，如果我们更改 `button_primary_background_fill` 变量，`button_primary_background_fill_hover` 和 `button_..."
          ],
          [
           "his demo shows how you can build an interactive dashboard with gradio. Click on a python library on ..."
          ],
          [
           "gradio\n\n## 4.11.0\n\n### Features\n\n- [#6842](https://github.com/gradio-app/gradio/pull/6842) [`846d52d..."
          ],
          [
           "## 4.9.0\n\n### Features\n\n- [#6726](https://github.com/gradio-app/gradio/pull/6726) [`21cfb0a`](https:..."
          ],
          [
           "## 4.8.0\n\n### Features\n\n- [#6624](https://github.com/gradio-app/gradio/pull/6624) [`1751f14`](https:..."
          ],
          [
           "## 4.5.0\n\n### Highlights\n\n#### New `ImageEditor` component ([#6169](https://github.com/gradio-app/gr..."
          ],
          [
           "```\n\n Thanks [@pngwn](https://github.com/pngwn)!\n\n### Fixes\n\n- [#6497](https://github.com/gradio-app..."
          ],
          [
           "### Fixes\n\n- [#6412](https://github.com/gradio-app/gradio/pull/6412) [`649f3ceb6`](https://github.co..."
          ],
          [
           "## 4.1.1\n\n### Fixes\n\n- [#6288](https://github.com/gradio-app/gradio/pull/6288) [`92278729e`](https:/..."
          ],
          [
           "<img src=\"https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExMm9pbzhvaTd1MTFlM3FrMmRweTh1ZWZiMmpvemhp..."
          ],
          [
           "```\n\nIn order for the HTML component to be able to serve `image.png`, you will need to add `image.pn..."
          ],
          [
           "```\n\nUnlike the `Image` component, which passes the input image as a single value into the predictio..."
          ],
          [
           "- [#6184](https://github.com/gradio-app/gradio/pull/6184) [`86edc0199`](https://github.com/gradio-ap..."
          ],
          [
           "- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.com/gradio-ap..."
          ],
          [
           "- [#6016](https://github.com/gradio-app/gradio/pull/6016) [`83e947676`](https://github.com/gradio-ap..."
          ],
          [
           "### Fixes\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.co..."
          ],
          [
           "## 3.45.0-beta.13\n\n### Features\n\n- [#5964](https://github.com/gradio-app/gradio/pull/5964) [`5fbda0b..."
          ],
          [
           "## 3.48.0\n\n### Features\n\n- [#5627](https://github.com/gradio-app/gradio/pull/5627) [`b67115e8e`](htt..."
          ],
          [
           "Thanks to a new capability that allows components to communicate directly with the server _without_ ..."
          ],
          [
           "## 3.45.2\n\n### Features\n\n- [#5722](https://github.com/gradio-app/gradio/pull/5722) [`dba651904`](htt..."
          ],
          [
           "## 3.45.1\n\n### Fixes\n\n- [#5701](https://github.com/gradio-app/gradio/pull/5701) [`ee8eec1e5`](https:..."
          ],
          [
           "## 3.44.4\n\n### Features\n\n- [#5514](https://github.com/gradio-app/gradio/pull/5514) [`52f783175`](htt..."
          ],
          [
           "## 3.43.2\n\n### Fixes\n\n- [#5456](https://github.com/gradio-app/gradio/pull/5456) [`6e381c4f`](https:/..."
          ],
          [
           "```\n\n Thanks [@aliabid94](https://github.com/aliabid94)!\n\n### Features\n\n- [#5334](https://github.com..."
          ],
          [
           "```\n\n Thanks [@hannahblair](https://github.com/hannahblair)!\n\n### Features\n\n- [#5268](https://github..."
          ],
          [
           "### Fixes\n\n- [#5256](https://github.com/gradio-app/gradio/pull/5256) [`933db53e`](https://github.com..."
          ],
          [
           "```\n\nFrom the backend, streamed outputs are served from the `/stream/` endpoint instead of the `/fil..."
          ],
          [
           "### Fixes\n\n- [#5062](https://github.com/gradio-app/gradio/pull/5062) [`7d897165`](https://github.com..."
          ],
          [
           "```\n\n<img src=\"https://gradio-builds.s3.amazonaws.com/demo-files/discordbots/guide/llama_chat.gif\">\n..."
          ],
          [
           "```\n\n- The `get_api_info` method of `Blocks` now supports layout output components [@freddyaboulton]..."
          ],
          [
           "### Bug Fixes:\n\n- Updated components with `info` attribute to update when `update()` is called on th..."
          ],
          [
           "### Bug Fixes:\n\n- Fix chatbot streaming by [@aliabid94](https://github.com/aliabid94) in [PR 4537](h..."
          ],
          [
           "```\n\n- Min and max value for gr.Number by [@artegoser](https://github.com/artegoser) and [@dawoodkha..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Add support for PAUSED state in the JS client by [@abidlabs](https://github.c..."
          ],
          [
           "### Other Changes:\n\n- More explicit error message when share link binary is blocked by antivirus by ..."
          ],
          [
           "### Other Changes:\n\n- Change `gr.Chatbot()` markdown parsing to frontend using `marked` library and ..."
          ],
          [
           "No changes to highlight.\n\n### Breaking Changes:\n\n- `gr.HuggingFaceDatasetSaver` behavior changed int..."
          ],
          [
           "```\n\nSee the [image_segmentation demo](https://github.com/gradio-app/gradio/tree/main/demo/image_seg..."
          ],
          [
           "```\n\n  ![Theme Builder](https://user-images.githubusercontent.com/7870876/228204929-d71cbba5-69c2-45..."
          ],
          [
           "By [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3428](https://github.com/gradio-app/g..."
          ],
          [
           "```\n\n2. Via the command line\n\nFirst save the theme to disk\n\n```python\nmy_theme.dump(filename=\"my_the..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Ensure uploaded images are always shown in the sketch tool by [@pngwn](https:..."
          ],
          [
           "```\n\nby [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 3211](https://github.com/gradio-app/..."
          ],
          [
           "- Fixed comment typo in components.py by [@eltociear](https://github.com/eltociear) in [PR 3235](htt..."
          ],
          [
           "```\n\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3157](https://github.com/gradio-..."
          ],
          [
           "```\n\nBy [@maxaudron](https://github.com/maxaudron) in [PR 3075](https://github.com/gradio-app/gradio..."
          ],
          [
           "```\n\n![chatbot_load](https://user-images.githubusercontent.com/41651716/213260220-3eaa25b7-a38b-48c6..."
          ],
          [
           "### Testing and Infrastructure Changes:\n\n- Adds a GitHub action to test if any large files (> 5MB) a..."
          ],
          [
           "```\n\nProgress indicator bar by [@aliabid94](https://github.com/aliabid94) in [PR 2750](https://githu..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Fixed issue where too many temporary files were created, all with randomly ge..."
          ],
          [
           "```\n\n![label_bg_color_update](https://user-images.githubusercontent.com/41651716/204400372-80e53857-..."
          ],
          [
           "```\n\n###### Revamped API documentation page\n\nNew API Docs page with in-browser playground and update..."
          ],
          [
           "```\n\nThe `api_name` parameter will take precedence over the `fn_index` parameter.\n\n### Bug Fixes:\n\n-..."
          ],
          [
           "```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference\ntime of..."
          ],
          [
           "```\n\n![stop_interface_rl](https://user-images.githubusercontent.com/41651716/195952883-e7ca4235-aae3..."
          ],
          [
           "### Contributors Shoutout:\n\nNo changes to highlight.\n\n## 3.4.1\n\n### New Features:\n\n###### 1. See Pas..."
          ],
          [
           "```\n\n<img src=\"https://user-images.githubusercontent.com/9021060/192399521-7360b1a9-7ce0-443e-8e94-8..."
          ],
          [
           "```\n\n![example](https://user-images.githubusercontent.com/9021060/189086273-f5e7087d-71fa-4158-90a9-..."
          ],
          [
           "```\n\nNote that we don't evaluate the function -- `datetime.datetime.now()` -- we pass in the functio..."
          ],
          [
           "```\n\nIf you're working from a Jupyter or Colab Notebook, use these magic commands instead: `%load_ex..."
          ],
          [
           "```\n\n![hello-blocks](https://user-images.githubusercontent.com/9021060/168684108-78cbd24b-e6bd-4a04-..."
          ],
          [
           "- Gradio dash fe by [@pngwn](https://github.com/pngwn) in [PR 807](https://github.com/gradio-app/gra..."
          ],
          [
           "- indentation fix by [@abidlabs](https://github.com/abidlabs) in [PR 993](https://github.com/gradio-..."
          ],
          [
           "- Flagging fixes by [@abidlabs](https://github.com/abidlabs) in [PR 1081](https://github.com/gradio-..."
          ],
          [
           "- async-function-support by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1190](https://gi..."
          ],
          [
           "### Contributors Shoutout:\n\n- [@JefferyChiang](https://github.com/JefferyChiang) made their first co..."
          ],
          [
           "@gradio/statustracker\n\n## 0.4.3\n\n### Features\n\n- [#6814](https://github.com/gradio-app/gradio/pull/6..."
          ],
          [
           "create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://g..."
          ],
          [
           "imple image classification in Pytorch with Gradio's Image input and Label output...."
          ],
          [
           "`@gradio/atoms`\n\n```html\n<script lang=\"ts\">\n\timport { Block, BlockTitle, BlockLabel, IconButton, Emp..."
          ],
          [
           "his text generation demo works like autocomplete. There's only one textbox and it's used for both th..."
          ],
          [
           "Gradio Demo: sound_alert\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo r..."
          ],
          [
           "Gradio Demo: theme_extended_step_2\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "实时语音识别\n\nRelated spaces: https://huggingface.co/spaces/abidlabs/streaming-asr-paused, https://hugging..."
          ],
          [
           "```\n\n然后，创建与之前相似的 `transcribe()` 函数：\n\n```python\nfrom deepspeech import Model\nimport numpy as np\n\nmode..."
          ],
          [
           "Gradio Demo: sine_curve\n\n\n```\n!pip install -q gradio plotly\n```\n\n\n```\nimport math\nimport gradio as g..."
          ],
          [
           "his text generation demo takes in input text and returns generated text. It uses the Transformers li..."
          ],
          [
           "Gradio Demo: color_generator\n\n\n```\n!pip install -q gradio opencv-python numpy\n```\n\n\n```\nimport gradi..."
          ],
          [
           "@gradio/client\n\n## 0.9.3\n\n### Features\n\n- [#6814](https://github.com/gradio-app/gradio/pull/6814) [`..."
          ],
          [
           "## 0.4.2\n\n### Features\n\n- [#5124](https://github.com/gradio-app/gradio/pull/5124) [`6e56a0d9b`](http..."
          ],
          [
           "@gradio/label\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/g..."
          ],
          [
           "Case Study: A Component to Display PDFs\n\nLet's work through an example of building a custom gradio c..."
          ],
          [
           "```\n\nYou should see the following when you navigate to your app after saving your current changes:\n\n..."
          ],
          [
           "```\n\nNow we will add them underneath the canvas in a separate `<div>`\n\n```ts\n    ...\n\n    <ModifyUpl..."
          ],
          [
           "```\n\n## Conclusion\n\nIn order to use our new component in **any** gradio 4.0 app, simply install it w..."
          ],
          [
           "Gradio Demo: stream_audio_out\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the d..."
          ],
          [
           "gradio-ui\n\nThis folder contains all of the Gradio UI and component source code.\n\n- [set up](#setup)\n..."
          ],
          [
           "Gradio Demo: gallery_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr..."
          ],
          [
           "Gradio Demo: blocks_scroll\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndemo = gr.B..."
          ],
          [
           "website\n\n## 0.20.3\n\n### Patch Changes\n\n- Updated dependencies []:\n  - @gradio/code@0.3.3\n\n## 0.20.2\n..."
          ],
          [
           "### Fixes\n\n- [#6046](https://github.com/gradio-app/gradio/pull/6046) [`dbb7de5e0`](https://github.co..."
          ],
          [
           "## 0.1.0\n\n### Features\n\n- [#5076](https://github.com/gradio-app/gradio/pull/5076) [`2745075a`](https..."
          ],
          [
           "Gradio Demo: live_dashboard\n### This demo shows how you can build a live interactive dashboard with ..."
          ],
          [
           "Image Classification in TensorFlow and Keras\n\nRelated spaces: https://huggingface.co/spaces/abidlabs..."
          ],
          [
           "Gradio Demo: queue_full_e2e_test\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport ..."
          ],
          [
           "Gradio Demo: blocks_simple_squares\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndemo..."
          ],
          [
           "Gradio Demo: blocks_static\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndemo = gr.Bl..."
          ],
          [
           "Gradio Demo: main_note\n\n\n```\n!pip install -q gradio scipy numpy matplotlib\n```\n\n\n```\n# Downloading f..."
          ],
          [
           "@gradio/atoms\n\n## 0.4.1\n\n### Fixes\n\n- [#6766](https://github.com/gradio-app/gradio/pull/6766) [`7326..."
          ],
          [
           "demo for predicting the depth of an image and generating a 3D model of it...."
          ],
          [
           "Gradio Demo: video_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the de..."
          ],
          [
           "TensorFlow 和 Keras 中的图像分类\n\n相关空间：https://huggingface.co/spaces/abidlabs/keras-image-classifier\n标签：VIS..."
          ],
          [
           "his demo identifies if two speakers are the same person using Gradio's Audio and HTML components...."
          ],
          [
           "Gradio Demo: image_classifier_interface_load\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading f..."
          ],
          [
           "@gradio/image\n\n## 0.5.3\n\n### Fixes\n\n- [#6766](https://github.com/gradio-app/gradio/pull/6766) [`7326..."
          ],
          [
           "```\n\nThanks [@pngwn](https://github.com/pngwn)!\n\n## 0.3.6\n\n### Fixes\n\n- [#6441](https://github.com/g..."
          ],
          [
           "## 0.4.0\n\n### Features\n\n- [#5627](https://github.com/gradio-app/gradio/pull/5627) [`b67115e8e`](http..."
          ],
          [
           "Gradio Demo: latex\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Blocks() as ..."
          ],
          [
           "Gradio Demo: video_identity\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the dem..."
          ],
          [
           "@gradio/fallback\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "🚀 Creating Discord Bots from Gradio Apps 🚀\n\nTags: NLP, TEXT, CHAT\n\nWe're excited to announce that Gr..."
          ],
          [
           "Gradio Demo: blocks_essay\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ncountries_cit..."
          ],
          [
           "Gradio Demo: generate_tone\n\n\n```\n!pip install -q gradio numpy\n```\n\n\n```\nimport numpy as np\nimport gr..."
          ],
          [
           "`@gradio/form`\n\n```html\n<script>\n\timport { Form } from \"@gradio/form\";\n</script>\n```\n\nForm\n```javasc..."
          ],
          [
           "Gradio Demo: hello_world_3\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef greet(na..."
          ],
          [
           "Gradio Components: The Key Concepts\n\nIn this section, we discuss a few important concepts when it co..."
          ],
          [
           "Real Time Speech Recognition\n\nTags: ASR, SPEECH, STREAMING\n\n## Introduction\n\nAutomatic speech recogn..."
          ],
          [
           "Gradio Demo: unified_demo_text_generation\n\n\n```\n!pip install -q gradio torch transformers\n```\n\n\n```\n..."
          ],
          [
           "Gradio Demo: calculator_blocks_cached\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\n..."
          ],
          [
           "Gradio Demo: image-simple\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo ..."
          ],
          [
           "`@gradio/imageeditor`..."
          ],
          [
           "Gradio Demo: chatbot_multimodal\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the..."
          ],
          [
           "Gradio Demo: dataframe_block-ui-test\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwi..."
          ],
          [
           "Gradio Demo: on_listener_test\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.B..."
          ],
          [
           "The Backend 🐍\n\nThis guide will cover everything you need to know to implement your custom component'..."
          ],
          [
           "```\n\nEven if your component does not expect a \"complex\" JSON data structure it can be beneficial to ..."
          ],
          [
           "Gradio Demo: blocks_flag\n\n\n```\n!pip install -q gradio numpy\n```\n\n\n```\nimport numpy as np\nimport grad..."
          ],
          [
           "Gradio Demo: concurrency_without_queue\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\ni..."
          ],
          [
           "Gradio Demo: dashboard\n### This demo shows how you can build an interactive dashboard with gradio. C..."
          ],
          [
           "@gradio/slider\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/..."
          ],
          [
           "@gradio/model3d\n\n## 0.4.11\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "## 0.3.0-beta.6\n\n### Features\n\n- [#5960](https://github.com/gradio-app/gradio/pull/5960) [`319c30f3f..."
          ],
          [
           "mport { Meta } from \"@storybook/blocks\";\n\n<Meta title=\"Introduction\" />\n\n<style>\n\t{`\n    img {\n     ..."
          ],
          [
           "simple demo showcasing the upload button used with its `upload` event trigger...."
          ],
          [
           "`@gradio/highlightedtext`\n\n```html\n<script>\n    import { BaseStaticHighlightedText, BaseInteractiveH..."
          ],
          [
           "Gradio Demo: image_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwit..."
          ],
          [
           "Gradio Demo: reverse_audio\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo..."
          ],
          [
           "Gradio Demo: blocks_page_load\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef prin..."
          ],
          [
           "Gradio & LLM Agents 🤝\n\nLarge Language Models (LLMs) are very impressive but they can be made even mo..."
          ],
          [
           "```\n\nSome notes on this implementation:\n\n1. All instances of `GradioTool` have an attribute called `..."
          ],
          [
           "his simple demo takes advantage of Gradio's HighlightedText, JSON and HTML outputs to create a clear..."
          ],
          [
           "`@gradio/video`\n\n```javascript\n<script>\n\timport { BaseInteractiveVideo, BaseStaticVideo, BasePlayer ..."
          ],
          [
           "utomatic speech recognition English. Record from your microphone and the app will transcribe the aud..."
          ],
          [
           "Gradio Demo: longest_word\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef longest_..."
          ],
          [
           "`@gradio/colorpicker`\n\n```html\n<script>\n    import { BaseColorPicker, BaseExample } from \"@gradio/co..."
          ],
          [
           "Gradio Demo: annotatedimage_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nim..."
          ],
          [
           "Running a Gradio App on your Web Server with Nginx\n\nTags: DEPLOYMENT, WEB SERVER, NGINX\n\n## Introduc..."
          ],
          [
           "@gradio/upload\n\n## 0.5.6\n\n### Fixes\n\n- [#6766](https://github.com/gradio-app/gradio/pull/6766) [`732..."
          ],
          [
           "```\n\nThanks [@pngwn](https://github.com/pngwn)!\n\n## 0.4.2\n\n### Fixes\n\n- [#6441](https://github.com/g..."
          ],
          [
           "## 0.0.3\n\n### Fixes\n\n- [#5077](https://github.com/gradio-app/gradio/pull/5077) [`667875b2`](https://..."
          ],
          [
           "```\n\nFrom the backend, streamed outputs are served from the `/stream/` endpoint instead of the `/fil..."
          ],
          [
           "Getting Started with the Gradio Python client\n\nTags: CLIENT, API, SPACES\n\nThe Gradio Python client m..."
          ],
          [
           "```\n\n## Status\n\nThe `Job` object also allows you to get the status of the running job by calling the..."
          ],
          [
           "Frequently Asked Questions\n\n## What do I need to install before using Custom Components?\nBefore usin..."
          ],
          [
           "Create Your Own Friends with a GAN\n\nRelated spaces: https://huggingface.co/spaces/NimaBoscarino/cryp..."
          ],
          [
           "```\n\n\n## Step 4 — Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd lik..."
          ],
          [
           "Gradio Demo: blocks_component_shortcut\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n..."
          ],
          [
           "Gradio Demo: progress_component\n\n\n```\n!pip install -q gradio tqdm\n```\n\n\n```\nimport gradio as gr\nimpo..."
          ],
          [
           "Gradio Demo: calculator\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo re..."
          ],
          [
           "Gradio Demo: cancel_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport time\nimport gradio as gr\n\n..."
          ],
          [
           "Gradio Demo: live_with_vars\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndemo = gr.I..."
          ],
          [
           "反应式界面 (Reactive Interfaces)\n\n本指南介绍了如何使 Gradio 界面自动刷新或连续流式传输数据。\n\n## 实时界面 (Live Interfaces)\n\n您可以通过在界面中..."
          ],
          [
           "Gradio Demo: gpt2_xl\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ntitle = \"gpt2-xl\"\n..."
          ],
          [
           "Gradio Demo: uploadbutton_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef..."
          ],
          [
           "Vision Transformers 图像分类\n\n相关空间：https://huggingface.co/spaces/abidlabs/vision-transformer\n标签：VISION, ..."
          ],
          [
           "Gradio Demo: blocks_speech_text_sentiment\n\n\n```\n!pip install -q gradio torch transformers\n```\n\n\n```\n..."
          ],
          [
           "Gradio Demo: spectogram\n\n\n```\n!pip install -q gradio scipy numpy matplotlib\n```\n\n\n```\nimport matplot..."
          ],
          [
           "Gradio Demo: clustering\n### This demo built with Blocks generates 9 plots based on the input.\n      ..."
          ],
          [
           "```\n\n\n```\nimport gradio as gr\nimport math\nfrom functools import partial\nimport matplotlib.pyplot as ..."
          ],
          [
           "@gradio/html\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gr..."
          ],
          [
           "`@gradio/gallery`\n\n```html\n<script>\n\timport { BaseGallery } from \"@gradio/gallery\";\n</script>\n```\n\nB..."
          ],
          [
           "命名实体识别 （Named-Entity Recognition）\n\n相关空间：https://huggingface.co/spaces/rajistics/biobert_ner_demo，htt..."
          ],
          [
           "Blocks and Event Listeners\n\nWe briefly descirbed the Blocks class in the [Quickstart](/main/guides/q..."
          ],
          [
           "```\n\nAbove, each return statement returns two values corresponding to `food_box` and `status_box`, r..."
          ],
          [
           "Gradio Demo: no_input\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport random\n\nsen..."
          ],
          [
           "Gradio Demo: hello_world_2\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef greet(na..."
          ],
          [
           "Gradio Demo: blocks_plug\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef change_ta..."
          ],
          [
           "PyTorch 图像分类\n\nRelated spaces: https://huggingface.co/spaces/abidlabs/pytorch-image-classifier, https..."
          ],
          [
           "Gradio Demo: video_subtitle\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the dem..."
          ],
          [
           "@gradio/state\n\n## 0.1.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`2..."
          ],
          [
           "分享您的应用\n\n如何分享您的 Gradio 应用：\n\n1. [使用 share 参数分享演示](#sharing-demos)\n2. [在 HF Spaces 上托管](#hosting-on-hf-..."
          ],
          [
           "Gradio Demo: english_translator\n\n\n```\n!pip install -q gradio transformers torch\n```\n\n\n```\nimport gra..."
          ],
          [
           "@gradio/row\n\n## 0.1.1\n\n### Features\n\n- [#6399](https://github.com/gradio-app/gradio/pull/6399) [`053..."
          ],
          [
           "Gradio Demo: image_editor\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo ..."
          ],
          [
           "分块状态 (State in Blocks)\n\n我们已经介绍了[接口状态](https://gradio.app/interface-state)，这篇指南将介绍分块状态，它的工作原理大致相同。\n\n#..."
          ],
          [
           "ote: This is a simplified version of the code needed to create the Stable Diffusion demo. See full c..."
          ],
          [
           "Gradio Demo: matrix_transpose\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport numpy as np\n\nimport gra..."
          ],
          [
           "Gradio Demo: blocks_textbox_max_lines\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\n..."
          ],
          [
           "ecreate the viral AnimeGAN image transformation demo...."
          ],
          [
           "Gradio Demo: calculator_list_and_dict\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nw..."
          ],
          [
           "区块和事件监听器 (Blocks and Event Listeners)\n\n我们在[快速入门](https://gradio.app/quickstart/#blocks-more-flexibil..."
          ],
          [
           "Gradio Demo: checkbox_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith g..."
          ],
          [
           "@gradio/icons\n\n## 0.3.2\n\n### Features\n\n- [#6399](https://github.com/gradio-app/gradio/pull/6399) [`0..."
          ],
          [
           "Gradio Demo: audio_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwit..."
          ],
          [
           "Gradio Demo: chatinterface_random_response\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport random\nimp..."
          ],
          [
           "Gradio Demo: colorpicker_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwit..."
          ],
          [
           "Gradio Demo: blocks_update\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Bloc..."
          ],
          [
           "Getting Started with the Gradio JavaScript client\n\nTags: CLIENT, API, SPACES\n\nThe Gradio JavaScript ..."
          ],
          [
           "```\n\n## Using events\n\nIf the API you are working with can return results over time, or you wish to a..."
          ],
          [
           "更多示例 (More on Examples)\n\n本指南介绍了有关示例的更多内容：从目录中加载示例，提供部分示例和缓存。如果你对示例还不熟悉，请查看 [关键特性](../key-features/#e..."
          ],
          [
           "从 Supabase 数据创建仪表盘\n\nTags: TABULAR, DASHBOARD, PLOTS\n\n[Supabase](https://supabase.com/) 是一个基于云的开源后端，提..."
          ],
          [
           "Gradio Demo: model3d_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr..."
          ],
          [
           "@gradio/markdown\n\n## 0.6.0\n\n### Features\n\n- [#6842](https://github.com/gradio-app/gradio/pull/6842) ..."
          ],
          [
           "### Fixes\n\n- [#5604](https://github.com/gradio-app/gradio/pull/5604) [`faad01f8e`](https://github.co..."
          ],
          [
           "Gradio Demo: video_identity_2\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef video..."
          ],
          [
           "`gradio_client`: Use a Gradio app as an API -- in 3 lines of Python\n\nThis directory contains the sou..."
          ],
          [
           "Gradio Demo: image_classification\n### Simple image classification in Pytorch with Gradio's Image inp..."
          ],
          [
           "Gradio Demo: label_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.B..."
          ],
          [
           "自定义的 JS 和 CSS\n\n本指南介绍了如何更灵活地为 Blocks 添加样式，并添加 JavaScript 代码到事件监听器中。\n\n**警告**：在自定义的 JS 和 CSS 中使用查询选择器不能..."
          ],
          [
           "Gradio Demo: bokeh_plot\n\n\n```\n!pip install -q gradio bokeh>=3.0 xyzservices\n```\n\n\n```\nimport gradio ..."
          ],
          [
           "# JavaScript Client Library\n\nA javascript (and typescript) client to call Gradio APIs.\n\n## Installat..."
          ],
          [
           "```\n\n##### `cancel`\n\nCertain types of gradio function can run repeatedly and in some cases indefinit..."
          ],
          [
           "iles in this directory are used in:\n\n- tests for the gradio library\n- example inputs in the view API..."
          ],
          [
           "How to Use the 3D Model Component\n\nRelated spaces: https://huggingface.co/spaces/gradio/Model3D, htt..."
          ],
          [
           "@gradio/dataset\n\n## 0.1.13\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "Gradio Demo: blocks_kinematics\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport pandas as pd\nimport nu..."
          ],
          [
           "Gradio Demo: blocks_neural_instrument_coding\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading f..."
          ],
          [
           "Gradio Demo: image_classifier\n\n\n```\n!pip install -q gradio numpy tensorflow\n```\n\n\n```\n# Downloading ..."
          ],
          [
           "Using Gradio Blocks Like Functions\n\nTags: TRANSLATION, HUB, SPACES\n\n**Prerequisite**: This Guide bui..."
          ],
          [
           "Gradio Demo: animeganv2\n### Recreate the viral AnimeGAN image transformation demo.\n        \n\n\n```\n!p..."
          ],
          [
           "Gradio Demo: image_segmentation\n### Simple image segmentation using gradio's AnnotatedImage componen..."
          ],
          [
           "Gradio Demo: stable-diffusion\n### Note: This is a simplified version of the code needed to create th..."
          ],
          [
           "`@gradio/statustracker`\n\n```html\n<script>\n    import {StatusTracker, Toast, Loader} from `@gradio/st..."
          ],
          [
           "@gradio/simpletextbox\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://gith..."
          ],
          [
           "Gradio Demo: chatbot_consecutive\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport ..."
          ],
          [
           "Gradio Demo: file_explorer\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nfrom pathlib ..."
          ],
          [
           "运行后台任务\n\nRelated spaces: https://huggingface.co/spaces/freddyaboulton/gradio-google-forms\nTags: TASKS..."
          ],
          [
           "Gradio Demo: file_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.Bl..."
          ],
          [
           "Gradio Demo: blocks_group\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef greet(nam..."
          ],
          [
           "通过自动重载实现更快的开发\n\n**先决条件**：本指南要求您了解块的知识。请确保[先阅读块指南](https://gradio.app/quickstart/#blocks-more-flexibil..."
          ],
          [
           "Gradio Demo: sentiment_analysis\n### This sentiment analaysis demo takes in input text and returns it..."
          ],
          [
           "Gradio Demo: image_mod\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo rep..."
          ],
          [
           "Gradio Demo: hello_blocks\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef greet(nam..."
          ],
          [
           "Installing Gradio in a Virtual Environment\n\nTags: INSTALLATION\n\nIn this guide, we will describe step..."
          ],
          [
           "Gradio Demo: score_tracker\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nscores = []\n..."
          ],
          [
           "`@gradio/file`\n\n```html\n<script>\n\timport { BaseFile, BaseFileUpload, FilePreview, BaseExample } from..."
          ],
          [
           "Gradio Demo: scatterplot_component\n\n\n```\n!pip install -q gradio vega_datasets\n```\n\n\n```\nimport gradi..."
          ],
          [
           "Gradio Demo: xgboost-income-prediction-with-explainability\n### This demo takes in 12 inputs from the..."
          ],
          [
           "his demo built with Blocks generates 9 plots based on the input...."
          ],
          [
           "Gradio & LLM Agents 🤝\n\n非常强大的大型语言模型（LLM），如果我们能赋予它们完成专门任务的技能，它们将变得更加强大。\n\n[gradio_tools](https://github..."
          ],
          [
           "Gradio Demo: barplot_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport pa..."
          ],
          [
           "Gradio Demo: blocks_hello\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef welcome(n..."
          ],
          [
           "his is a fake GAN that shows how to create a text-to-image interface for image generation. Check out..."
          ],
          [
           "Gradio Demo: loginbutton_component\n\n\n```\n!pip install -q gradio gradio[oauth]\n```\n\n\n```\nimport gradi..."
          ],
          [
           "@gradio/gallery\n\n## 0.4.14\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "## 0.4.0-beta.7\n\n### Patch Changes\n\n- Updated dependencies []:\n  - @gradio/image@0.3.0-beta.7\n\n## 0...."
          ],
          [
           "在 Web 服务器上使用 Nginx 运行 Gradio 应用\n\n标签：部署，Web 服务器，Nginx\n\n## 介绍\n\nGradio 是一个 Python 库，允许您快速创建可定制的 Web 应用程..."
          ],
          [
           "@gradio/highlightedtext\n\n## 0.4.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://gi..."
          ],
          [
           "##### Various performance improvements\n\nThese improvements will be particularly beneficial to large ..."
          ],
          [
           "Gradio Demo: stream_frames\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport numpy ..."
          ],
          [
           "@gradio/utils\n\n## 0.2.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`2..."
          ],
          [
           "从 Google Sheets 创建实时仪表盘\n\nTags: TABULAR, DASHBOARD, PLOTS\n[Google Sheets](https://www.google.com/shee..."
          ],
          [
           "@gradio/radio\n\n## 0.3.7\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/g..."
          ],
          [
           "##### Various performance improvements\n\nThese improvements will be particularly beneficial to large ..."
          ],
          [
           "Gradio Demo: markdown_example\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ncss = (\n ..."
          ],
          [
           "gradio_client\n\n## 0.7.3\n\n### Fixes\n\n- [#6693](https://github.com/gradio-app/gradio/pull/6693) [`34f9..."
          ],
          [
           "```\n\n Thanks [@freddyaboulton](https://github.com/freddyaboulton)!\n\n### Fixes\n\n- [#5295](https://git..."
          ],
          [
           "```\n\n<img src=\"https://gradio-builds.s3.amazonaws.com/demo-files/discordbots/guide/llama_chat.gif\">\n..."
          ],
          [
           "- Progress Updates from `gr.Progress()` can be accessed via `job.status().progress_data` by @freddya..."
          ],
          [
           "```\n\nRead more about how to use the `gradio_client` library here: https://gradio.app/getting-started..."
          ],
          [
           "Gradio Demo: blocks_form\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Blocks..."
          ],
          [
           "Gradio Demo: tictactoe\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Blocks()..."
          ],
          [
           "Gradio Demo: fake_gan_2\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo re..."
          ],
          [
           "simple dashboard ranking spaces by number of likes...."
          ],
          [
           "@gradio/json\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gr..."
          ],
          [
           "`gradio/model3d`\n\n```html\n<script>\n    import {BaseModel3D, BaseModel3DUpload, BaseExample } from `@..."
          ],
          [
           "@gradio/theme\n\n## 0.2.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`2..."
          ],
          [
           "Gradio Demo: automatic-speech-recognition\n### Automatic speech recognition English. Record from your..."
          ],
          [
           "Gradio Demo: event_trigger\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo..."
          ],
          [
           "`@gradio/button`\n\n```html\n<script>\n\timport { BaseChatBot } from \"@gradio/chatbot\";\n</script>\n```\n\n\nB..."
          ],
          [
           "div align=\"center\">\n\n[<img src=\"readme_files/gradio.svg\" alt=\"gradio\" width=400>](https://gradio.app..."
          ],
          [
           "Gradio Demo: theme_new_step_3\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nfrom __future__ import annotat..."
          ],
          [
           "Gradio Demo: dataframe_datatype\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport p..."
          ],
          [
           "Gradio Demo: Echocardiogram-Segmentation\n\n\n```\n!pip install -q gradio -f https://download.pytorch.or..."
          ],
          [
           "`@gradio/button`\n\n```javascript\n<script>\n\timport { BaseButton } from \"@gradio/button\";\n\timport { cre..."
          ],
          [
           "Gradio Demo: reverse_audio_2\n\n\n```\n!pip install -q gradio numpy\n```\n\n\n```\nimport gradio as gr\nimport..."
          ],
          [
           "Gradio Demo: model3d_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nw..."
          ],
          [
           "Gradio Demo: sentence_builder\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef sent..."
          ],
          [
           "@gradio/audio\n\n## 0.6.3\n\n### Fixes\n\n- [#6766](https://github.com/gradio-app/gradio/pull/6766) [`7326..."
          ],
          [
           "## 0.4.0-beta.8\n\n### Features\n\n- [#6016](https://github.com/gradio-app/gradio/pull/6016) [`83e947676..."
          ],
          [
           "Gradio Demo: waveform\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport random\n\n\nCO..."
          ],
          [
           "Gradio Demo: hello_login\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport argparse..."
          ],
          [
           "@gradio/fileexplorer\n\n## 0.3.13\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://gith..."
          ],
          [
           "Using Gradio and Comet\n\nTags: COMET, SPACES\nContributed by the Comet team\n\n## Introduction\n\nIn this ..."
          ],
          [
           "```\n\nThe last line in this snippet will log the URL of the Gradio Application to your Comet Experime..."
          ],
          [
           "`@gradio/markdown`\n\n```html\n<script>\n    import { BaseMarkdown, MarkdownCode, BaseExample } from `@g..."
          ],
          [
           "Gradio Demo: calculator_live\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef calcul..."
          ],
          [
           "Named-Entity Recognition\n\nRelated spaces: https://huggingface.co/spaces/rajistics/biobert_ner_demo, ..."
          ],
          [
           "Gradio Demo: fraud_detector\n\n\n```\n!pip install -q gradio pandas\n```\n\n\n```\n# Downloading files from t..."
          ],
          [
           "!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides/1)getting_start..."
          ],
          [
           "```\n\nWhen you run this code, a public URL will be generated for your demo in a matter of seconds, so..."
          ],
          [
           "Building a FastAPI App with the Gradio Python Client\n\nTags: CLIENT, API, WEB APP\n\nIn this blog post,..."
          ],
          [
           "```\n\nWrite the following as the contents of `home.html`:\n\n```html\n&lt;!DOCTYPE html> &lt;html> &lt;h..."
          ],
          [
           "Developing Faster with Auto-Reloading\n\n**Prerequisite**: This Guide requires you to know about Block..."
          ],
          [
           "Running Background Tasks\n\nRelated spaces: https://huggingface.co/spaces/freddyaboulton/gradio-google..."
          ],
          [
           "How to Use the Plot Component for Maps\n\nTags: PLOTS, MAPS\n\n## Introduction\n\nThis guide explains how ..."
          ],
          [
           "Gradio Demo: blocks_style\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Block..."
          ],
          [
           "Using Flagging\n\nRelated spaces: https://huggingface.co/spaces/gradio/calculator-flagging-crowdsource..."
          ],
          [
           "```\n\nNotice that we define our own\ninstance of `gradio.HuggingFaceDatasetSaver` using our Hugging Fa..."
          ],
          [
           "his demo shows how you can build a live interactive dashboard with gradio.\nThe current time is refre..."
          ],
          [
           "Gradio Demo: plot_component\n\n\n```\n!pip install -q gradio matplotlib numpy\n```\n\n\n```\nimport gradio as..."
          ],
          [
           "Gradio Demo: request_ip_headers\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef pr..."
          ],
          [
           "连接到数据库\n\n相关空间：https://huggingface.co/spaces/gradio/chicago-bike-share-dashboard\n标签：TABULAR, PLOTS\n\n##..."
          ],
          [
           "Gradio Demo: chatinterface_streaming_echo\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport time\nimport..."
          ],
          [
           "Gradio Demo: hangman\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nsecret_word = \"gra..."
          ],
          [
           "The 4 Kinds of Gradio Interfaces\n\nSo far, we've always assumed that in order to build an Gradio demo..."
          ],
          [
           "`@gradio/dataframe`\n\n```html\n<script>\n    import { BaseDataFrame, BaseExample } from \"@gradio/datafr..."
          ],
          [
           "Gradio Demo: line_plot\n\n\n```\n!pip install -q gradio vega_datasets pandas\n```\n\n\n```\nimport gradio as ..."
          ],
          [
           "Contributing to Gradio\n\n![GitHub issues by-label](https://img.shields.io/github/issues/gradio-app/gr..."
          ],
          [
           "```\n\nDelete `/node_modules` and `pnpm-lock.yaml`:\n\n```\nrm -rf node_modules/\nrm pnpm-lock.yaml\n```\n\na..."
          ],
          [
           "Gradio Demo: leaderboard\n### A simple dashboard ranking spaces by number of likes.\n        \n\n\n```\n!p..."
          ],
          [
           "Gradio 界面的 4 种类型\n\n到目前为止，我们一直假设构建 Gradio 演示需要同时具备输入和输出。但对于机器学习演示来说，并不总是如此：例如，*无条件图像生成模型*不需要任何输入，但会生成一..."
          ],
          [
           "Gradio Demo: calculator_blocks\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef cal..."
          ],
          [
           "@gradio/dataframe\n\n## 0.4.3\n\n### Patch Changes\n\n- Updated dependencies [[`846d52d`](https://github.c..."
          ],
          [
           "### Fixes\n\n- [#5755](https://github.com/gradio-app/gradio/pull/5755) [`e842a561a`](https://github.co..."
          ],
          [
           "Gradio Demo: rows_and_columns\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the d..."
          ],
          [
           "Gradio Demo: lineplot_component\n\n\n```\n!pip install -q gradio vega_datasets\n```\n\n\n```\nimport gradio a..."
          ],
          [
           "@gradio/box\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`73268ee`](https://github.com/gra..."
          ],
          [
           "Gradio Demo: webcam\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n\nimport gradio as gr\n\n\ndef snap(image, v..."
          ],
          [
           "Gradio Demo: theme_new_step_2\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nfrom __future__ import annotat..."
          ],
          [
           "Gradio 和 ONNX 在 Hugging Face 上\n\nRelated spaces: https://huggingface.co/spaces/onnx/EfficientNet-Lite..."
          ],
          [
           "Gradio Demo: slider_release\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef identi..."
          ],
          [
           "How to add support for more languages\n\nWe would love to support more languages for Gradio 🌎\n\nTo add ..."
          ],
          [
           "Setting Up a Demo for Maximum Performance\n\nTags: CONCURRENCY, LATENCY, PERFORMANCE\n\nLet's say that y..."
          ],
          [
           "```\n1 2 3 4 5 6 7\n-------------\nA B A A C B A\n```\n\nInitially, 3 workers will get dispatched to handl..."
          ],
          [
           "Gradio Demo: blocks_outputs\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef make_m..."
          ],
          [
           "Gradio Demo: slider_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr...."
          ],
          [
           "`@gradio/radio`\n\n```html\n<script>\n    import { BaseRadio, BaseExample } from \"@gradio/radio\"; \n</scr..."
          ],
          [
           "Gradio Demo: clearbutton_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\nwit..."
          ],
          [
           "`@gradio/html`\n\n```javascript\nimport { BaseHTML } from \"@gradio/html\";\n```\n\nBaseHTML\n```javascript\n\t..."
          ],
          [
           "Gradio Demo: hello_world\n### The simplest possible Gradio demo. It wraps a 'Hello {name}!' function ..."
          ],
          [
           "Gradio Demo: ner_pipeline\n\n\n```\n!pip install -q gradio torch transformers\n```\n\n\n```\nfrom transformer..."
          ],
          [
           "接口状态 (Interface State)\n\n本指南介绍了 Gradio 中如何处理状态。了解全局状态和会话状态的区别，以及如何同时使用它们。\n\n## 全局状态 (Global State)\n\n您的..."
          ],
          [
           "使用 Hugging Face 集成\n\n相关空间：https://huggingface.co/spaces/gradio/helsinki_translation_en_es\n标签：HUB，SPAC..."
          ],
          [
           "Gradio Demo: chatbot_dialogpt\n\n\n```\n!pip install -q gradio torch transformers\n```\n\n\n```\nimport gradi..."
          ],
          [
           "Gradio Demo: blocks_joined\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo..."
          ],
          [
           "Gradio Demo: zip_to_json\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nfrom zipfile import ZipFile\n\nimport..."
          ],
          [
           "@gradio/group\n\n## 0.1.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`2..."
          ],
          [
           "Gradio Demo: titanic_survival\n\n\n```\n!pip install -q gradio scikit-learn numpy pandas\n```\n\n\n```\n# Dow..."
          ],
          [
           "`@gradio/uploadbutton`\n\n```html\n<script>\n    import { BaseUploadButton } from \"@gradio/uploadbutton\"..."
          ],
          [
           "Gradio Demo: translation\n### This translation demo takes in the text, source and target languages, a..."
          ],
          [
           "Using Hugging Face Integrations\n\nRelated spaces: https://huggingface.co/spaces/gradio/en2es\nTags: HU..."
          ],
          [
           "使用 Gradio 块像函数一样\n\nTags: TRANSLATION, HUB, SPACES\n\n**先决条件**: 本指南是在块介绍的基础上构建的。请确保[先阅读该指南](https://grad..."
          ],
          [
           "Gradio Demo: unispeech-speaker-verification\n\n\n```\n!pip install -q gradio git+https://github.com/hugg..."
          ],
          [
           "Gradio Demo: white_noise_vid_not_playable\n\n\n```\n!pip install -q gradio opencv-python\n```\n\n\n```\nimpor..."
          ],
          [
           "Gradio Demo: logoutbutton_component\n\n\n```\n!pip install -q gradio gradio[oauth]\n```\n\n\n```\nimport grad..."
          ],
          [
           "`@gradio/button`\n\n```html\n<script>\n\timport { Button } from \"@gradio/button\";\n</script>\n\n<button type..."
          ],
          [
           "Gradio Demo: chicago-bikeshare-dashboard\n\n\n```\n!pip install -q gradio psycopg2 matplotlib SQLAlchemy..."
          ],
          [
           "Gradio Demo: textbox_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr..."
          ],
          [
           "使用标记\n\n相关空间：https://huggingface.co/spaces/gradio/calculator-flagging-crowdsourced, https://huggingfac..."
          ],
          [
           "Image Classification in PyTorch\n\nRelated spaces: https://huggingface.co/spaces/abidlabs/pytorch-imag..."
          ],
          [
           "Theming\n\nTags: THEMES\n\n## Introduction\n\nGradio features a built-in theming engine that lets you cust..."
          ],
          [
           "```\n\n<div class=\"wrapper\">\n<iframe\n\tsrc=\"https://gradio-theme-extended-step-3.hf.space?__theme=light..."
          ],
          [
           "```\n\n- Via the command line\n\nFirst save the theme to disk\n\n```python\nseafoam.dump(filename=\"seafoam...."
          ],
          [
           "@gradio/tabs\n\n## 0.1.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`28..."
          ],
          [
           "如何创建一个新组件\n\n## 简介\n\n本指南旨在说明如何添加一个新组件，你可以在 Gradio 应用程序中使用该组件。该指南将通过代码片段逐步展示如何添加[ColorPicker](https://gr..."
          ],
          [
           "```\n\n- 通过执行 `export { default as FileName } from \"./FileName.svelte\"`，在您将 Svelte 组件放置的包的 index.ts 文件..."
          ],
          [
           "Gradio Demo: concurrency_with_queue\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpo..."
          ],
          [
           "Gradio Demo: blocks_essay_simple\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef c..."
          ],
          [
           "@gradio/form\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`73268ee`](https://github.com/gr..."
          ],
          [
           "Gradio Demo: blocks_chained_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "Gradio Demo: dataframe_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith g..."
          ],
          [
           "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser\n\nTags: SERVERLESS, BROWSER, PYODIDE\n..."
          ],
          [
           "控制布局 (Controlling Layout)\n\n默认情况下，块中的组件是垂直排列的。让我们看看如何重新排列组件。在幕后，这种布局结构使用了[Web 开发的 flexbox 模型](https:/..."
          ],
          [
           "Gradio Demo: blocks_kitchen_sink\n\n\n```\n!pip install -q gradio \n```..."
          ],
          [
           "```\nimport gradio as gr\nimport time\nfrom os.path import abspath, join, pardir\n\nKS_FILES = abspath(jo..."
          ],
          [
           "with gr.Row():\n        with gr.Column(scale=2):\n            highlight = gr.HighlightedText(\n        ..."
          ],
          [
           "```..."
          ],
          [
           "isplay an interactive map of AirBnB locations with Plotly. Data is hosted on HuggingFace Datasets...."
          ],
          [
           "使用 Gradio 和 Comet\n\nTags: COMET, SPACES\n由 Comet 团队贡献\n\n## 介绍\n\n在这个指南中，我们将展示您可以如何使用 Gradio 和 Comet。我们将介绍..."
          ],
          [
           "```\n\n此片段中的最后一行将将 Gradio 应用程序的 URL 记录到您的 Comet 实验中。您可以在实验的文本选项卡中找到该 URL。\n\n<video width=\"560\" height=\"..."
          ],
          [
           "@gradio/column\n\n## 0.1.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`..."
          ],
          [
           "Gradio Demo: asr\n\n\n```\n!pip install -q gradio torch torchaudio transformers\n```\n\n\n```\nimport gradio ..."
          ],
          [
           "he simplest possible Gradio demo. It wraps a 'Hello {name}!' function in an Interface that accepts a..."
          ],
          [
           "his  demo converts text to speech in 14 languages...."
          ],
          [
           "Contributing a Guide\n\nWant to help teach Gradio? Consider contributing a Guide! 🤗\n\nBroadly speaking,..."
          ],
          [
           "Gradio Demo: blocks_xray\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport time\n\ndi..."
          ],
          [
           "Gradio Demo: fake_gan\n### This is a fake GAN that shows how to create a text-to-image interface for ..."
          ],
          [
           "如何使用 3D 模型组件\n\n相关空间：https://huggingface.co/spaces/dawood/Model3D, https://huggingface.co/spaces/radam..."
          ],
          [
           "@gradio/accordion\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.c..."
          ],
          [
           "Gradio Demo: highlightedtext_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n..."
          ],
          [
           "Gradio Demo: on_listener_decorator\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith..."
          ],
          [
           "Gradio Demo: zip_files\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo rep..."
          ],
          [
           "his demo uses a fake model to showcase iterative output. The Image output will update every time a g..."
          ],
          [
           "Gradio Demo: color_picker\n\n\n```\n!pip install -q gradio Pillow\n```\n\n\n```\n# Downloading files from the..."
          ],
          [
           "Gradio Demo: tax_calculator\n### Calculate taxes using Textbox, Radio, and Dataframe components\n     ..."
          ],
          [
           "Customizing your demo with CSS and Javascript\n\nGradio allows you to customize your demo in several w..."
          ],
          [
           "The `Interface` class\n\nAs mentioned in the [Quickstart](/main/guides/quickstart), the `gr.Interface`..."
          ],
          [
           "Gradio Demo: variable_outputs\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nmax_textb..."
          ],
          [
           "Security Policy\n\n## Reporting a Vulnerability\n\nIf you discover a security vulnerability, we would be..."
          ],
          [
           "Configuring Your Custom Component\n\nThe custom components workflow focuses on [convention over config..."
          ],
          [
           "Gradio Demo: blocks_gpt\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\napi = gr.load(\"..."
          ],
          [
           "imple image segmentation using gradio's AnnotatedImage component...."
          ],
          [
           "Gradio Demo: save_file_no_output\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport random\nimport string..."
          ],
          [
           "@gradio/colorpicker\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github..."
          ],
          [
           "Gradio Demo: code_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Blo..."
          ],
          [
           "Gradio Demo: fake_diffusion\n### This demo uses a fake model to showcase iterative output. The Image ..."
          ],
          [
           "Gradio Demo: altair_plot\n\n\n```\n!pip install -q gradio altair vega_datasets\n```\n\n\n```\nimport altair a..."
          ],
          [
           "Gradio Demo: native_plots\n\n\n```\n!pip install -q gradio vega_datasets\n```\n\n\n```\n# Downloading files f..."
          ],
          [
           "create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://g..."
          ],
          [
           "Gradio Demo: same-person-or-different\n### This demo identifies if two speakers are the same person u..."
          ],
          [
           "How to Create a Custom Chatbot with Gradio Blocks\n\nTags: NLP, TEXT, CHAT\nRelated spaces: https://hug..."
          ],
          [
           "Gradio Demo: video_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwit..."
          ],
          [
           "Gradio Demo: bar_plot\n\n\n```\n!pip install -q gradio pandas\n```\n\n\n```\nimport gradio as gr\nimport panda..."
          ],
          [
           "Gradio Demo: progress_simple\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport time..."
          ],
          [
           "@gradio/uploadbutton\n\n## 0.3.4\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://githu..."
          ],
          [
           "## 0.0.10\n\n### Patch Changes\n\n- Updated dependencies [[`e4a307ed6`](https://github.com/gradio-app/gr..."
          ],
          [
           "The Frontend 🌐⭐️\n\nThis guide will cover everything you need to know to implement your custom compone..."
          ],
          [
           "```\n\nThe component exposes a prop named `root`. \nThis is passed down by the parent gradio app and it..."
          ],
          [
           "@gradio/simpledropdown\n\n## 0.1.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://git..."
          ],
          [
           "Test Coverage\n\nJust a little reference docs to understand what is tested/ needs testing. Perhaps tem..."
          ],
          [
           "### `AnnotatedImage`\n\n### `Audio`\n\n### `BarPlot`\n\n### `Button`\n\n### `Chatbot`\n\n### `Checkbox`\n\n### `..."
          ],
          [
           "@gradio/code\n\n## 0.3.3\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gr..."
          ],
          [
           "Thanks [@pngwn](https://github.com/pngwn)!\n\n### Features\n\n- [#5215](https://github.com/gradio-app/gr..."
          ],
          [
           "Gradio Demo: text_analysis\n### This simple demo takes advantage of Gradio's HighlightedText, JSON an..."
          ],
          [
           "Gradio Demo: diff_texts\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nfrom difflib import Differ\n\nimport g..."
          ],
          [
           "Gradio Demo: code\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo repo\nimp..."
          ],
          [
           "Reactive Interfaces\n\nFinally, we cover how to get Gradio demos to refresh automatically or continuou..."
          ],
          [
           "`@gradio/theme`\n\ncss for gradio..."
          ],
          [
           "Gradio Demo: chatbot_simple\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport rando..."
          ],
          [
           "his sentiment analaysis demo takes in input text and returns its classification for either positive,..."
          ],
          [
           "Gradio Demo: count_generator\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport time..."
          ],
          [
           "Creating a Real-Time Dashboard from Google Sheets\n\nTags: TABULAR, DASHBOARD, PLOTS\n\n[Google Sheets](..."
          ],
          [
           "@gradio/number\n\n## 0.3.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/..."
          ],
          [
           "@gradio/plot\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gr..."
          ],
          [
           "Gradio Demo: chatbot_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr...."
          ],
          [
           "Gradio Demo: interface_random_slider\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\nd..."
          ],
          [
           "his demo identifies musical instruments from an audio file. It uses Gradio's Audio and Label compone..."
          ],
          [
           "Gradio Demo: blocks_js_load\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef welcome..."
          ],
          [
           "Gradio Demo: image_mod_default_image\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files fro..."
          ],
          [
           "Gradio Demo: on_listener_basic\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr...."
          ],
          [
           "Gradio Demo: reversible_flow\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef increa..."
          ],
          [
           "@gradio/checkboxgroup\n\n## 0.3.7\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://gith..."
          ],
          [
           "Gradio Demo: digit_classifier\n\n\n```\n!pip install -q gradio tensorflow\n```\n\n\n```\nfrom urllib.request ..."
          ],
          [
           "@gradio/wasm\n\n## 0.4.0\n\n### Features\n\n- [#6398](https://github.com/gradio-app/gradio/pull/6398) [`67..."
          ],
          [
           "@gradio/checkbox\n\n## 0.2.6\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "Gradio Demo: input_output\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef image_mo..."
          ],
          [
           "Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a hi..."
          ],
          [
           "```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, h..."
          ],
          [
           "Gradio Demo: file_explorer_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nw..."
          ],
          [
           "Gradio Demo: timeseries-forecasting-with-prophet\n### A simple dashboard showing pypi stats for pytho..."
          ],
          [
           "Custom Components in 5 minutes\n\nGradio 4.0 introduces Custom Components -- the ability for developer..."
          ],
          [
           "Test Strategy\n\nVery brief, mildly aspirational test strategy document. This isn't where we are but i..."
          ],
          [
           "Gradio Demo: audio_debugger\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the dem..."
          ],
          [
           "`@gradio/upload`\n\n```html\n<script>\n    import { Upload, ModifyUpload, normalise_file, get_fetchable_..."
          ],
          [
           "Gradio Demo: hello_blocks_decorator\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\nwi..."
          ],
          [
           "Connecting to a Database\n\nRelated spaces: https://huggingface.co/spaces/gradio/chicago-bikeshare-das..."
          ],
          [
           "Gradio Demo: image_classifier_2\n\n\n```\n!pip install -q gradio pillow torch torchvision\n```\n\n\n```\n# Do..."
          ],
          [
           "Gradio Demo: scatter_plot\n\n\n```\n!pip install -q gradio vega_datasets pandas\n```\n\n\n```\nimport gradio ..."
          ],
          [
           "使用Gradio Python客户端构建FastAPI应用\n\nTags: CLIENT, API, WEB APP\n\n在本博客文章中，我们将演示如何使用 `gradio_client` [Python..."
          ],
          [
           "Gradio Demo: theme_extended_step_3\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "@gradio/tabitem\n\n## 0.1.0\n\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [..."
          ],
          [
           "从 BigQuery 数据创建实时仪表盘\n\nTags: 表格 , 仪表盘 , 绘图\n\n[Google BigQuery](https://cloud.google.com/bigquery) 是一个基..."
          ],
          [
           "Gradio Demo: progress\n\n\n```\n!pip install -q gradio tqdm datasets\n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "Gradio Demo: theme_new_step_1\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nfrom gradi..."
          ],
          [
           "Interface State\n\nSo far, we've assumed that your demos are *stateless*: that they do not persist inf..."
          ],
          [
           "Gradio Demo: tabbed_interface_lite\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nhell..."
          ],
          [
           "Gradio Demo: theme_extended_step_1\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "使用 GAN 创建您自己的朋友\n\nspaces/NimaBoscarino/cryptopunks, https://huggingface.co/spaces/nateraw/cryptopunks..."
          ],
          [
           "```\n\n新的输入将传递给我们的 `predict()` 函数，所以我们必须对该函数进行一些更改，以接受一个新的参数 :\n\n```python\ndef predict(seed, num_punks)..."
          ],
          [
           "Gradio Demo: blocks_flipper\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport numpy as np\nimport gradio..."
          ],
          [
           "@gradio/annotatedimage\n\n## 0.3.13\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://gi..."
          ],
          [
           "## 0.1.1\n\n### Patch Changes\n\n- Updated dependencies [[`abf1c57d`](https://github.com/gradio-app/grad..."
          ],
          [
           "Gradio Demo: stt_or_tts\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ntts_examples = ..."
          ],
          [
           "gradio_client\n\n## 0.7.3\n\n### Fixes\n\n- [#6693](https://github.com/gradio-app/gradio/pull/6693) [`34f9..."
          ],
          [
           "```\n\n Thanks [@freddyaboulton](https://github.com/freddyaboulton)!\n\n### Fixes\n\n- [#5295](https://git..."
          ],
          [
           "```\n\n<img src=\"https://gradio-builds.s3.amazonaws.com/demo-files/discordbots/guide/llama_chat.gif\">\n..."
          ],
          [
           "- Progress Updates from `gr.Progress()` can be accessed via `job.status().progress_data` by @freddya..."
          ],
          [
           "```\n\nRead more about how to use the `gradio_client` library here: https://gradio.app/getting-started..."
          ],
          [
           "Gradio and W&B Integration\n\n相关空间：https://huggingface.co/spaces/akhaliq/JoJoGAN\n标签：WANDB, SPACES\n由 Gr..."
          ],
          [
           "```\n\n5. 构建 Gradio 演示\n\n   ```python\n\n   import gradio as gr\n\n   title = \"JoJoGAN\"\n   description = \"J..."
          ],
          [
           "Gradio Demo: dataset\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo repo\n..."
          ],
          [
           "`@gradio/dropdown`\n\n```html\n<script>\n    import {BaseDropdown, BaseMultiselect, BaseExample } from \"..."
          ],
          [
           "Gradio Demo: fake_diffusion_with_gif\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files fro..."
          ],
          [
           "Gradio Demo: theme_soft\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport time\n\nwit..."
          ],
          [
           "Gradio Demo: radio_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.B..."
          ],
          [
           "Gradio Demo: image_selections\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport num..."
          ],
          [
           "使用 Gradio Python 客户端入门\n\nTags: CLIENT, API, SPACES\n\nGradio Python 客户端使得将任何 Gradio 应用程序作为 API 使用变得非常容易..."
          ],
          [
           "Gradio Demo: markdown_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr..."
          ],
          [
           "Gradio Demo: gpt2_xl_unified\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ncomponent ..."
          ],
          [
           "How to Create a Chatbot with Gradio\n\nTags: NLP, TEXT, CHAT\n\n## Introduction\n\nChatbots are a popular ..."
          ],
          [
           "```\n\nIf you need to create something even more custom, then its best to construct the chatbot UI usi..."
          ],
          [
           "Create a Dashboard from Supabase Data\n\nTags: TABULAR, DASHBOARD, PLOTS\n\n[Supabase](https://supabase...."
          ],
          [
           "Gradio Demo: hello_world_4\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndef greet(na..."
          ],
          [
           "Gradio Demo: fake_gan_no_input\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport time\n\nimport gradio as..."
          ],
          [
           "gradio_test\n\n## 0.3.3\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gra..."
          ],
          [
           "@gradio/preview\n\n## 0.6.0\n\n### Features\n\n- [#6738](https://github.com/gradio-app/gradio/pull/6738) [..."
          ],
          [
           "```\n\n Thanks [@pngwn](https://github.com/pngwn)!\n\n## 0.2.2\n\n### Features\n\n- [#6467](https://github.c..."
          ],
          [
           "Gradio Demo: blocks_js_methods\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nblocks =..."
          ],
          [
           "Gradio Demo: theme_extended_step_4\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimpor..."
          ],
          [
           "@gradio/textbox\n\n## 0.4.7\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com..."
          ],
          [
           "Thanks [@pngwn](https://github.com/pngwn)!\n\n## 0.1.0\n\n### Features\n\n- [#5005](https://github.com/gra..."
          ],
          [
           "Gradio Demo: dataset_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr...."
          ],
          [
           "Gradio Demo: blocks_layout\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndemo = gr.B..."
          ],
          [
           "@gradio/app\n\n## 1.17.0\n\n### Features\n\n- [#6831](https://github.com/gradio-app/gradio/pull/6831) [`f3..."
          ],
          [
           "```\n\nThanks [@pngwn](https://github.com/pngwn)!\n\n## 1.12.0\n\n### Features\n\n- [#6427](https://github.c..."
          ],
          [
           "### Fixes\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.co..."
          ],
          [
           "## 1.7.1\n\n### Patch Changes\n\n- Updated dependencies [[`796145e2c`](https://github.com/gradio-app/gra..."
          ],
          [
           "## 1.4.3\n\n### Patch Changes\n\n- Updated dependencies [[`6e381c4f`](https://github.com/gradio-app/grad..."
          ],
          [
           "```\n\nThanks [@hannahblair](https://github.com/hannahblair)!\n\n### Features\n\n- [#5215](https://github...."
          ],
          [
           "Gradio Demo: kitchen_sink\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo ..."
          ],
          [
           "`@gradio/utils`\n\nGeneral functions for handling events in Gradio Svelte components\n\n\n```javascript\ne..."
          ],
          [
           "Gradio Demo: audio_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.Bl..."
          ],
          [
           "Gradio Demo: musical_instrument_identification\n### This demo identifies musical instruments from an ..."
          ],
          [
           "Gradio Demo: change_vs_input\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the de..."
          ],
          [
           "@gradio/chatbot\n\n## 0.5.5\n\n### Patch Changes\n\n- Updated dependencies [[`846d52d`](https://github.com..."
          ],
          [
           "### Fixes\n\n- [#6046](https://github.com/gradio-app/gradio/pull/6046) [`dbb7de5e0`](https://github.co..."
          ],
          [
           "### Fixes\n\n- [#5242](https://github.com/gradio-app/gradio/pull/5242) [`2b397791`](https://github.com..."
          ],
          [
           "@gradio/button\n\n## 0.2.13\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com..."
          ],
          [
           "Thanks [@pngwn](https://github.com/pngwn)!\n\n### Fixes\n\n- [#5285](https://github.com/gradio-app/gradi..."
          ],
          [
           "Gradio Demo: dataframe_colorful\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport pandas as pd \nimport ..."
          ],
          [
           "How to Style the Gradio Dataframe\n\nTags: DATAFRAME, STYLE, COLOR\n\n## Introduction\n\nData visualizatio..."
          ],
          [
           "Image Classification with Vision Transformers\n\nRelated spaces: https://huggingface.co/spaces/abidlab..."
          ],
          [
           "Gradio Demo: text_generation\n### This text generation demo takes in input text and returns generated..."
          ],
          [
           "Gradio Demo: diffusers_with_batching\n\n\n```\n!pip install -q gradio torch transformers diffusers\n```\n\n..."
          ],
          [
           "Gradio Demo: depth_estimation\n### A demo for predicting the depth of an image and generating a 3D mo..."
          ],
          [
           "Using Gradio for Tabular Data Science Workflows\n\nRelated spaces: https://huggingface.co/spaces/sciki..."
          ],
          [
           "Controlling Layout\n\nBy default, Components in Blocks are arranged vertically. Let's take a look at h..."
          ],
          [
           "gradio\n\n## 4.11.0\n\n### Features\n\n- [#6842](https://github.com/gradio-app/gradio/pull/6842) [`846d52d..."
          ],
          [
           "## 4.9.0\n\n### Features\n\n- [#6726](https://github.com/gradio-app/gradio/pull/6726) [`21cfb0a`](https:..."
          ],
          [
           "## 4.8.0\n\n### Features\n\n- [#6624](https://github.com/gradio-app/gradio/pull/6624) [`1751f14`](https:..."
          ],
          [
           "## 4.5.0\n\n### Highlights\n\n#### New `ImageEditor` component ([#6169](https://github.com/gradio-app/gr..."
          ],
          [
           "```\n\n Thanks [@pngwn](https://github.com/pngwn)!\n\n### Fixes\n\n- [#6497](https://github.com/gradio-app..."
          ],
          [
           "### Fixes\n\n- [#6412](https://github.com/gradio-app/gradio/pull/6412) [`649f3ceb6`](https://github.co..."
          ],
          [
           "## 4.1.1\n\n### Fixes\n\n- [#6288](https://github.com/gradio-app/gradio/pull/6288) [`92278729e`](https:/..."
          ],
          [
           "<img src=\"https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExMm9pbzhvaTd1MTFlM3FrMmRweTh1ZWZiMmpvemhp..."
          ],
          [
           "```\n\nIn order for the HTML component to be able to serve `image.png`, you will need to add `image.pn..."
          ],
          [
           "```\n\nUnlike the `Image` component, which passes the input image as a single value into the predictio..."
          ],
          [
           "- [#6184](https://github.com/gradio-app/gradio/pull/6184) [`86edc0199`](https://github.com/gradio-ap..."
          ],
          [
           "- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.com/gradio-ap..."
          ],
          [
           "- [#6016](https://github.com/gradio-app/gradio/pull/6016) [`83e947676`](https://github.com/gradio-ap..."
          ],
          [
           "### Fixes\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.co..."
          ],
          [
           "## 3.45.0-beta.13\n\n### Features\n\n- [#5964](https://github.com/gradio-app/gradio/pull/5964) [`5fbda0b..."
          ],
          [
           "## 3.48.0\n\n### Features\n\n- [#5627](https://github.com/gradio-app/gradio/pull/5627) [`b67115e8e`](htt..."
          ],
          [
           "Thanks to a new capability that allows components to communicate directly with the server _without_ ..."
          ],
          [
           "## 3.45.2\n\n### Features\n\n- [#5722](https://github.com/gradio-app/gradio/pull/5722) [`dba651904`](htt..."
          ],
          [
           "## 3.45.1\n\n### Fixes\n\n- [#5701](https://github.com/gradio-app/gradio/pull/5701) [`ee8eec1e5`](https:..."
          ],
          [
           "## 3.44.4\n\n### Features\n\n- [#5514](https://github.com/gradio-app/gradio/pull/5514) [`52f783175`](htt..."
          ],
          [
           "## 3.43.2\n\n### Fixes\n\n- [#5456](https://github.com/gradio-app/gradio/pull/5456) [`6e381c4f`](https:/..."
          ],
          [
           "```\n\n Thanks [@aliabid94](https://github.com/aliabid94)!\n\n### Features\n\n- [#5334](https://github.com..."
          ],
          [
           "```\n\n Thanks [@hannahblair](https://github.com/hannahblair)!\n\n### Features\n\n- [#5268](https://github..."
          ],
          [
           "### Fixes\n\n- [#5256](https://github.com/gradio-app/gradio/pull/5256) [`933db53e`](https://github.com..."
          ],
          [
           "```\n\nFrom the backend, streamed outputs are served from the `/stream/` endpoint instead of the `/fil..."
          ],
          [
           "### Fixes\n\n- [#5062](https://github.com/gradio-app/gradio/pull/5062) [`7d897165`](https://github.com..."
          ],
          [
           "```\n\n<img src=\"https://gradio-builds.s3.amazonaws.com/demo-files/discordbots/guide/llama_chat.gif\">\n..."
          ],
          [
           "```\n\n- The `get_api_info` method of `Blocks` now supports layout output components [@freddyaboulton]..."
          ],
          [
           "### Bug Fixes:\n\n- Updated components with `info` attribute to update when `update()` is called on th..."
          ],
          [
           "### Bug Fixes:\n\n- Fix chatbot streaming by [@aliabid94](https://github.com/aliabid94) in [PR 4537](h..."
          ],
          [
           "```\n\n- Min and max value for gr.Number by [@artegoser](https://github.com/artegoser) and [@dawoodkha..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Add support for PAUSED state in the JS client by [@abidlabs](https://github.c..."
          ],
          [
           "### Other Changes:\n\n- More explicit error message when share link binary is blocked by antivirus by ..."
          ],
          [
           "### Other Changes:\n\n- Change `gr.Chatbot()` markdown parsing to frontend using `marked` library and ..."
          ],
          [
           "No changes to highlight.\n\n### Breaking Changes:\n\n- `gr.HuggingFaceDatasetSaver` behavior changed int..."
          ],
          [
           "```\n\nSee the [image_segmentation demo](https://github.com/gradio-app/gradio/tree/main/demo/image_seg..."
          ],
          [
           "```\n\n  ![Theme Builder](https://user-images.githubusercontent.com/7870876/228204929-d71cbba5-69c2-45..."
          ],
          [
           "By [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3428](https://github.com/gradio-app/g..."
          ],
          [
           "```\n\n2. Via the command line\n\nFirst save the theme to disk\n\n```python\nmy_theme.dump(filename=\"my_the..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Ensure uploaded images are always shown in the sketch tool by [@pngwn](https:..."
          ],
          [
           "```\n\nby [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 3211](https://github.com/gradio-app/..."
          ],
          [
           "- Fixed comment typo in components.py by [@eltociear](https://github.com/eltociear) in [PR 3235](htt..."
          ],
          [
           "```\n\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3157](https://github.com/gradio-..."
          ],
          [
           "```\n\nBy [@maxaudron](https://github.com/maxaudron) in [PR 3075](https://github.com/gradio-app/gradio..."
          ],
          [
           "```\n\n![chatbot_load](https://user-images.githubusercontent.com/41651716/213260220-3eaa25b7-a38b-48c6..."
          ],
          [
           "### Testing and Infrastructure Changes:\n\n- Adds a GitHub action to test if any large files (> 5MB) a..."
          ],
          [
           "```\n\nProgress indicator bar by [@aliabid94](https://github.com/aliabid94) in [PR 2750](https://githu..."
          ],
          [
           "```\n\n### Bug Fixes:\n\n- Fixed issue where too many temporary files were created, all with randomly ge..."
          ],
          [
           "```\n\n![label_bg_color_update](https://user-images.githubusercontent.com/41651716/204400372-80e53857-..."
          ],
          [
           "```\n\n###### Revamped API documentation page\n\nNew API Docs page with in-browser playground and update..."
          ],
          [
           "```\n\nThe `api_name` parameter will take precedence over the `fn_index` parameter.\n\n### Bug Fixes:\n\n-..."
          ],
          [
           "```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference\ntime of..."
          ],
          [
           "```\n\n![stop_interface_rl](https://user-images.githubusercontent.com/41651716/195952883-e7ca4235-aae3..."
          ],
          [
           "### Contributors Shoutout:\n\nNo changes to highlight.\n\n## 3.4.1\n\n### New Features:\n\n###### 1. See Pas..."
          ],
          [
           "```\n\n<img src=\"https://user-images.githubusercontent.com/9021060/192399521-7360b1a9-7ce0-443e-8e94-8..."
          ],
          [
           "```\n\n![example](https://user-images.githubusercontent.com/9021060/189086273-f5e7087d-71fa-4158-90a9-..."
          ],
          [
           "```\n\nNote that we don't evaluate the function -- `datetime.datetime.now()` -- we pass in the functio..."
          ],
          [
           "```\n\nIf you're working from a Jupyter or Colab Notebook, use these magic commands instead: `%load_ex..."
          ],
          [
           "```\n\n![hello-blocks](https://user-images.githubusercontent.com/9021060/168684108-78cbd24b-e6bd-4a04-..."
          ],
          [
           "- Gradio dash fe by [@pngwn](https://github.com/pngwn) in [PR 807](https://github.com/gradio-app/gra..."
          ],
          [
           "- indentation fix by [@abidlabs](https://github.com/abidlabs) in [PR 993](https://github.com/gradio-..."
          ],
          [
           "- Flagging fixes by [@abidlabs](https://github.com/abidlabs) in [PR 1081](https://github.com/gradio-..."
          ],
          [
           "- async-function-support by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1190](https://gi..."
          ],
          [
           "### Contributors Shoutout:\n\n- [@JefferyChiang](https://github.com/JefferyChiang) made their first co..."
          ],
          [
           "Build a Custom Multimodal Chatbot - Part 1\n\nThis is the first in a two part series where we build a ..."
          ],
          [
           "```\n\nWe also need to modify the `handle_select` and `handle_like` functions:\n\n```ts\nfunction handle_..."
          ],
          [
           "Creating a Real-Time Dashboard from BigQuery Data\n\nTags: TABULAR, DASHBOARD, PLOTS\n\n[Google BigQuery..."
          ],
          [
           "Gradio Demo: sepia_filter\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport numpy as np\nimport gradio a..."
          ],
          [
           "`@gradio/image`\n\n```html\n<script>\n\timport { BaseImageUploader, BaseStaticImage, Webcam, BaseExample ..."
          ],
          [
           "`@gradio/audio`\n\n```html\n<script>\n\timport { BaseStaticAudio, BaseInteractiveAudio, BasePlayer, BaseE..."
          ],
          [
           "Gradio Demo: blocks_multiple_event_triggers\n\n\n```\n!pip install -q gradio plotly pypistats\n```\n\n\n```\n..."
          ],
          [
           "!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides/1)getting_start..."
          ],
          [
           "More on Examples\n\nIn the [previous Guide](/main/guides/the-interface-class), we discussed how to pro..."
          ],
          [
           "Backend Testing Guidelines\n\n- All the tests should test Backend functionalities. Frontend functional..."
          ],
          [
           "Gradio and ONNX on Hugging Face\n\nRelated spaces: https://huggingface.co/spaces/onnx/EfficientNet-Lit..."
          ],
          [
           "```\n\n## How to contribute Gradio demos on HF spaces using ONNX models\n\n- Add model to the [onnx mode..."
          ],
          [
           "# 使用 Gradio 进行表格数据科学工作流\n\nRelated spaces: https://huggingface.co/spaces/scikit-learn/gradio-skops-int..."
          ],
          [
           "his translation demo takes in the text, source and target languages, and returns the translation. It..."
          ],
          [
           "Gradio Demo: model3D\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo repo\n..."
          ],
          [
           "@gradio/lite\n\n## 0.4.4\n\n## 0.4.4-beta.0\n\n### Features\n\n- [#6147](https://github.com/gradio-app/gradi..."
          ],
          [
           "@gradio/video\n\n## 0.2.3\n\n### Fixes\n\n- [#6766](https://github.com/gradio-app/gradio/pull/6766) [`7326..."
          ],
          [
           "## 0.1.0-beta.8\n\n### Features\n\n- [#6016](https://github.com/gradio-app/gradio/pull/6016) [`83e947676..."
          ],
          [
           "Gradio Demo: outbreak_forecast\n### Generate a plot based on 5 inputs.\n        \n\n\n```\n!pip install -q..."
          ],
          [
           "@gradio/file\n\n## 0.4.3\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com/gr..."
          ],
          [
           "## 0.2.0-beta.7\n\n### Features\n\n- [#6016](https://github.com/gradio-app/gradio/pull/6016) [`83e947676..."
          ],
          [
           "### Fixes\n\n- [#5253](https://github.com/gradio-app/gradio/pull/5253) [`ddac7e4d`](https://github.com..."
          ],
          [
           "Gradio Demo: blocks_flashcards\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport random\n\nimport gradio ..."
          ],
          [
           "`@gradio/json`\n\n```html\n<script>\n\timport { BaseJSON } from \"@gradio/json\";\n</script>\n```\n\nBaseJSON\n`..."
          ],
          [
           "使用Gradio JavaScript客户端快速入门\n\nTags: CLIENT, API, SPACES\n\nGradio JavaScript客户端使得使用任何Gradio应用作为API非常简单。例..."
          ],
          [
           "@gradio/tootils\n\n## 0.1.7\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.com..."
          ],
          [
           "Quickstart\n\nGradio is an open-source Python package that allows you to quickly **build** a demo or w..."
          ],
          [
           "```\n\nWhen you run this code, a public URL will be generated for your demo in a matter of seconds, so..."
          ],
          [
           "如何创建一个聊天机器人\n\nTags: NLP, TEXT, CHAT\nRelated spaces: https://huggingface.co/spaces/gradio/chatbot_stre..."
          ],
          [
           "Gradio Demo: chatbot_streaming\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport ra..."
          ],
          [
           "Gradio Demo: upload_button\n### A simple demo showcasing the upload button used with its `upload` eve..."
          ],
          [
           "Gradio Demo: button_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\nwith gr.B..."
          ],
          [
           "Gradio Demo: image_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.B..."
          ],
          [
           "`@gradio/checkbox`\n\n```html\n<script>\n    import { BaseCheckbox } from \"@gradio/checkbox\";\n</script>\n..."
          ],
          [
           "Gradio Demo: dropdown_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith g..."
          ],
          [
           "Gradio Demo: filter_records\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\n\ndef filter..."
          ],
          [
           "@gradio/dropdown\n\n## 0.4.3\n\n### Patch Changes\n\n- Updated dependencies [[`828fb9e`](https://github.co..."
          ],
          [
           "### Fixes\n\n- [#5360](https://github.com/gradio-app/gradio/pull/5360) [`64666525`](https://github.com..."
          ],
          [
           "Gradio Demo: autocomplete\n### This text generation demo works like autocomplete. There's only one te..."
          ],
          [
           "Gradio Demo: generate_english_german\n\n\n```\n!pip install -q gradio transformers torch\n```\n\n\n```\nimpor..."
          ],
          [
           "Gradio Demo: gallery_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\n..."
          ],
          [
           "Gradio Demo: theme_builder\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\n\ndemo = gr.th..."
          ],
          [
           "Gradio Demo: blocks_inputs\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the demo..."
          ],
          [
           "Gradio Demo: html_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.Bl..."
          ],
          [
           "Gradio Demo: checkboxgroup_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nw..."
          ],
          [
           "Gradio Demo: state_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.B..."
          ],
          [
           "`@gradio/textbox`\n\n```html\n<script>\n    import { BaseTextbox, BaseExample } from \"@gradio/textbox\";\n..."
          ],
          [
           "Gradio Demo: clear_components\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading files from the d..."
          ],
          [
           "快速开始\n\n**先决条件**：Gradio 需要 Python 3.8 或更高版本，就是这样！\n\n## Gradio 是做什么的？\n\n与他人分享您的机器学习模型、API 或数据科学流程的*最佳方式之一..."
          ],
          [
           "@gradio/storybook\n\n## 0.2.0\n\n### Features\n\n- [#6451](https://github.com/gradio-app/gradio/pull/6451)..."
          ],
          [
           "Sharing Your App\n\nHow to share your Gradio app:\n\n1. [Sharing demos with the share parameter](#sharin..."
          ],
          [
           "```\n\nHere's another example of how to use the `render` event. An event listener is used to capture t..."
          ],
          [
           "```\n\nNote: if your function is called directly instead of through the UI (this happens, for\nexample,..."
          ],
          [
           "`@gradio/tooltip`\n\n```javascript\nimport { Tooltip } from \"@gradio/tooltip\";\n```\n\n```javascript\n\texpo..."
          ],
          [
           "enerate a plot based on 5 inputs...."
          ],
          [
           "Gradio Demo: stock_forecast\n\n\n```\n!pip install -q gradio numpy matplotlib\n```\n\n\n```\nimport matplotli..."
          ],
          [
           "simple dashboard showing pypi stats for python libraries. Updates on load, and has no buttons!..."
          ],
          [
           "Gradio Demo: neon-tts-plugin-coqui\n### This  demo converts text to speech in 14 languages.\n        \n..."
          ],
          [
           "@gradio/tooltip\n\n## 0.1.0\n\n## 0.1.0-beta.2\n\n### Features\n\n- [#6136](https://github.com/gradio-app/gr..."
          ],
          [
           "`@gradio/code`\n\n```html\n<script>\n    import { BaseCode, BaseCopy, BaseDownload, BaseWidget, BaseExam..."
          ],
          [
           "Gradio Demo: gif_maker\n\n\n```\n!pip install -q gradio opencv-python\n```\n\n\n```\nimport cv2\nimport gradio..."
          ],
          [
           "Gradio Demo: file_explorer_component_events\n\n\n```\n!pip install -q gradio \n```\n\n\n```\n# Downloading fi..."
          ],
          [
           "Gradio Demo: stream_audio\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport numpy a..."
          ],
          [
           "Gradio Demo: gallery_selections\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport n..."
          ],
          [
           "Gradio Demo: stream_asr\n\n\n```\n!pip install -q gradio torch torchaudio transformers\n```\n\n\n```\nimport ..."
          ],
          [
           "his demo takes in 12 inputs from the user in dropdowns and sliders and predicts income. It also has ..."
          ],
          [
           "`@gradio/label`\n\n```html\n<script>\n\timport { BaseLabel } from \"@gradio/label\";\n</script>\n```\n\nBaseLab..."
          ],
          [
           "Contributing a Guide\n\nWant to help teach Gradio? Consider contributing a Guide! 🤗\n\nBroadly speaking,..."
          ],
          [
           "alculate taxes using Textbox, Radio, and Dataframe components..."
          ],
          [
           "Gradio Demo: json_component\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr \n\nwith gr.Bl..."
          ]
         ],
         "hovertemplate": "source=gradio<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "gradio, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "gradio, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0.8727937,
          1.5776645,
          -3.1122148,
          -0.92079663,
          0.90688163,
          3.6950352,
          5.0622897,
          -2.968999,
          -2.2539713,
          0.42327136,
          1.0036564,
          2.2664819,
          2.3436587,
          -0.4980297,
          1.5022805,
          -0.921139,
          -2.600097,
          -2.1537087,
          -1.2539694,
          2.7317572,
          0.40755704,
          -2.9485395,
          -2.3697581,
          1.757237,
          0.8380908,
          -2.000514,
          2.8088799,
          -0.41389957,
          -1.3026555,
          -2.0476465,
          -3.1762109,
          -2.9645116,
          -4.9450436,
          2.7462306,
          -2.308643,
          -1.9914738,
          0.14869072,
          4.117003,
          -0.21316959,
          2.992675,
          -0.17542265,
          -2.320592,
          -1.1128813,
          3.422286,
          -0.6924428,
          -0.98810995,
          -2.7984157,
          -1.181514,
          -0.9053089,
          -4.2334757,
          -0.75208753,
          2.9884567,
          4.4391794,
          -1.5960331,
          4.011514,
          -4.176762,
          -1.5562294,
          3.6380014,
          -3.2667522,
          2.372047,
          4.327842,
          -0.80473334,
          2.3056865,
          0.14323875,
          4.4272575,
          -0.3565424,
          2.2008007,
          3.6712976,
          -1.5402193,
          -4.14826,
          4.794434,
          -4.113094,
          1.1848199,
          0.21419697,
          1.5107727,
          1.3284614,
          4.741007,
          -2.0008645,
          -4.854915,
          1.0655607,
          -4.966688,
          -0.7472299,
          1.2290967,
          -3.138912,
          4.2159624,
          -1.6269158,
          -0.29622322,
          -0.23653193,
          -0.38443762,
          -3.951916,
          -1.5688021,
          -3.7854898,
          2.391096,
          2.0731292,
          0.21496996,
          0.94584894,
          -4.2176876,
          -3.5973318,
          2.4617128,
          -1.2431538,
          -1.3901484,
          3.8207805,
          1.4175725,
          0.4044685,
          -1.4264221,
          -3.0419981,
          2.9525607,
          -1.5632217,
          1.3098917,
          0.08457666,
          -3.5753798,
          -0.37193513,
          -3.463109,
          -2.7770288,
          -2.7854257,
          5.7879515,
          -2.6336977,
          -4.3587875,
          3.3752527,
          -1.5176581,
          -4.021128,
          0.8643055,
          0.28162196,
          -0.47436005,
          3.3275373,
          -0.09344595,
          3.5735986,
          -3.5899935,
          -0.90304995,
          3.8276424,
          0.35767514,
          -3.6018429,
          -1.412788,
          1.9445144,
          0.69792,
          -0.8813418,
          4.2371354,
          -0.14437667,
          -0.7804694,
          -1.2728745,
          -1.5258787,
          1.4654967,
          -1.7769375,
          -3.5269306,
          -2.9229112,
          -3.3609405,
          2.7227807,
          -3.4198136,
          0.9220071,
          -3.2930834,
          -1.6042367,
          0.70073986,
          0.67416924,
          2.6382697,
          -4.9838986,
          -0.74947506,
          -2.0430753,
          -3.2180855,
          0.5482465,
          3.123585,
          1.5971017,
          -1.0605576,
          -1.946078,
          -0.74810606,
          -1.130997,
          -1.2323744,
          -1.8814263,
          0.75158066,
          -2.5620642,
          0.20792213,
          -1.7817541,
          -0.09955212,
          1.0572096,
          -1.5574098,
          -1.2714142,
          -3.8907692,
          3.7450888,
          -2.0635285,
          1.9299008,
          1.8654668,
          -3.7746978,
          -0.022545356,
          1.2057441,
          0.30576596,
          1.0359513,
          -2.1695704,
          2.951385,
          -1.7626922,
          1.2647502,
          4.0040116,
          -2.8661077,
          -0.8336633,
          -4.734902,
          -1.528335,
          -2.66288,
          -2.410594,
          -1.4212502,
          -2.4467325,
          -0.009953315,
          1.191054,
          1.2697349,
          -0.2810713,
          -0.014172668,
          2.7466965,
          3.2621813,
          0.5191602,
          1.711894,
          -2.9841728,
          1.5008674,
          -4.458516,
          -1.5633458,
          0.24045606,
          0.87243146,
          -0.52560014,
          5.338737,
          0.8537614,
          5.6624546,
          0.37845972,
          -3.2360604,
          3.969661,
          -4.780295,
          -5.23943,
          -0.807187,
          2.101441,
          -1.6808642,
          3.7764122,
          -2.3039289,
          2.5532598,
          0.382317,
          -4.1061816,
          -1.9542766,
          3.9414742,
          0.4817691,
          0.28286034,
          2.456987,
          -3.7468827,
          1.2980183,
          0.081593,
          -1.4737389,
          -2.2256935,
          -2.2105758,
          -3.426612,
          -0.42133498,
          -1.5573769,
          0.51066,
          1.413479,
          0.8651264,
          1.2928379,
          0.6316492,
          -2.5997748,
          1.7692713,
          0.2493827,
          -1.2940427,
          1.205163,
          0.8360933,
          -1.1489493,
          -3.033774,
          -0.11145815,
          0.2584401,
          3.2479594,
          -1.5199987,
          -0.49771014,
          -1.5328209,
          1.7866691,
          1.1163883,
          -3.7239854,
          -0.66916513,
          -0.25995982,
          -0.22897431,
          0.82859254,
          -1.6653746,
          2.8522446,
          -0.8708471,
          0.72720224,
          -1.4922907,
          -2.5561097,
          0.3604176,
          0.35759744,
          1.8135867,
          3.2571435,
          0.5478028,
          -0.11041644,
          -0.99882257,
          3.1850927,
          -4.623323,
          0.0881936,
          -3.4146721,
          0.2699176,
          0.08990748,
          0.58241725,
          -1.699375,
          -3.7343414,
          2.5471587,
          1.4490504,
          0.14371869,
          -1.3092109,
          -4.0334992,
          1.9626946,
          -2.9816978,
          0.9894158,
          -1.1177515,
          -1.7494944,
          -1.5573841,
          0.30797997,
          -3.2933214,
          -2.2671382,
          0.5926554,
          -1.0151712,
          4.512809,
          2.7664719,
          1.4600397,
          2.1491563,
          0.12240954,
          -2.2365675,
          -0.10572992,
          2.519017,
          -1.5230341,
          0.8541528,
          -3.6391423,
          3.4615817,
          0.65241855,
          1.2588142,
          -0.29714766,
          -4.3918276,
          -2.6210225,
          0.8111603,
          -1.684026,
          -1.5942968,
          -2.1854188,
          -2.067453,
          -4.568232,
          2.3878472,
          0.77057064,
          -0.70985407,
          -1.4374342,
          -0.37931558,
          -2.1114414,
          -1.610556,
          3.2191157,
          -2.884656,
          -1.1144154,
          0.02236891,
          0.3385099,
          -3.4958787,
          3.6456232,
          -0.46373138,
          1.9798291,
          0.54935884,
          -1.647247,
          1.2886047,
          1.1857005,
          -1.6324359,
          1.1512508,
          0.84630305,
          0.4902853,
          -2.2187395,
          0.9644823,
          -1.3307542,
          2.8731017,
          0.5770624,
          -1.2390445,
          1.2698575,
          -2.667986,
          -1.2281046,
          -3.9960477,
          -4.3970976,
          1.3800678,
          -2.3139913,
          1.7555273,
          -1.7626581,
          1.2234819,
          -4.292711,
          -2.5096965,
          -2.9366913,
          -0.6543232,
          -2.896927,
          1.5974499,
          -0.2700581,
          0.7679016,
          -0.5802147,
          2.8920188,
          -0.25320047,
          -3.1628044,
          1.2703013,
          0.7607508,
          3.882378,
          1.3269219,
          0.45757744,
          10.3216715,
          0.42764458,
          -3.1764147,
          -1.7892452,
          1.9710094,
          -2.08638,
          4.8937087,
          -2.2529695,
          -2.8270903,
          -3.2548687,
          1.3228314,
          0.12530695,
          -0.03355421,
          -1.3341869,
          -1.0638556,
          -4.5362473,
          0.68990034,
          1.187326,
          -1.1174494,
          0.19574444,
          4.057185,
          1.1787381,
          0.19771402,
          0.35763353,
          -4.288818,
          1.0403763,
          0.16302516,
          0.53572416,
          -1.0518353,
          2.7628531,
          2.101273,
          1.4695472,
          -0.25783587,
          3.3852046,
          -0.84254384,
          4.3950367,
          -4.0706506,
          -1.6978068,
          0.7487933,
          -0.6827048,
          -3.6589186,
          -2.4863944,
          0.17344093,
          -1.6433353,
          -1.7824916,
          0.2177785,
          -1.4865888,
          -3.5017724,
          1.8786943,
          -4.1393247,
          -2.5075269,
          2.1003973,
          -2.115249,
          -1.5561451,
          1.7881738,
          3.4167864,
          -0.16327047,
          -1.3767602,
          -0.6679919,
          1.1182845,
          0.047252323,
          2.2830157,
          4.507673,
          2.3878934,
          -0.39257768,
          1.2614948,
          -0.10929283,
          -3.820753,
          2.5780346,
          0.6220473,
          -1.7079992,
          -0.887094,
          1.3013622,
          1.0131199,
          3.1698945,
          -3.209325,
          -1.202143,
          -3.2816246,
          -2.9785948,
          1.1823844,
          -2.769137,
          -3.6084914,
          1.4790125,
          1.7249098,
          -2.059812,
          -4.2087917,
          1.4251568,
          1.4879665,
          1.8938758,
          1.424748,
          1.5823978,
          -0.73710644,
          -1.6270932,
          -2.9068272,
          2.956323,
          2.6524642,
          -4.1783366,
          0.55193585,
          0.5565441,
          2.100042,
          3.0232105,
          0.5931659,
          0.73585564,
          -5.34904,
          -1.0541748,
          -0.8823226,
          2.0128975,
          0.8219254,
          1.4140705,
          -3.0027852,
          -1.3806581,
          -0.19903962,
          -2.2723951,
          -3.300341,
          -1.3462982,
          -0.059566118,
          -1.6241875,
          1.1720617,
          -0.28308976,
          1.5175903,
          2.0648363,
          -3.608669,
          -3.5269818,
          0.9156986,
          -0.26988208,
          -1.1139144,
          -3.2324636,
          -0.46938753,
          3.4940538,
          -3.121826,
          -0.44085804,
          -3.3084333,
          1.563387,
          0.915477,
          -1.8724627,
          0.77530575,
          -1.760654,
          0.6160731,
          0.38783422,
          -0.063237004,
          -1.812204,
          0.39013064,
          -4.1252403,
          -2.6676204,
          -3.3892305,
          3.3393226,
          0.29942095,
          -0.023148715,
          2.382967,
          -1.6331424,
          3.0972764,
          1.5738354,
          0.76238376,
          -2.0125866,
          2.7481873,
          -0.9467096,
          -1.3463837,
          -2.073372,
          -3.578034,
          -2.5340047,
          -5.0224757,
          2.6864295,
          -2.1855867,
          -1.9798117,
          0.073919356,
          4.1647615,
          -0.24646117,
          3.1575575,
          -0.44147465,
          -2.4715722,
          -1.475553,
          3.5914347,
          -1.1602439,
          -1.0109377,
          -2.7976432,
          -1.1288671,
          -1.0524265,
          -4.180113,
          -1.0360912,
          3.3495004,
          4.4564857,
          -1.4955001,
          3.9079368,
          -3.9220202,
          -1.7067844,
          3.5221589,
          -3.2227929,
          2.4346538,
          4.278791,
          -0.53061575,
          2.303002,
          0.15615885,
          4.538563,
          -0.5896236,
          2.1574085,
          2.6249166,
          -2.0099418,
          -4.2068067,
          4.7824564,
          -4.1306424,
          1.3312767,
          0.32253608,
          1.463539,
          1.1779684,
          4.7365026,
          -1.9816705,
          -4.859864,
          1.1756318,
          -5.04128,
          -0.68183756,
          1.5857636,
          -3.2800043,
          4.0991154,
          -1.6968869,
          -1.0107499,
          -0.82475376,
          4.4466534,
          1.0893338,
          0.83459026,
          -1.4262133,
          -1.1191182,
          -3.8434794,
          0.807036,
          3.1240602,
          -0.68404716,
          -0.7330559,
          2.247855,
          -1.6547451,
          3.790683,
          -4.0040536,
          -0.8297513,
          0.84391135,
          0.06866387,
          0.9529931,
          -1.2368242,
          -1.0565712,
          -0.6624516,
          0.6462251,
          -1.8094206,
          0.050337598,
          4.2575283,
          -3.9340367,
          -2.0303946,
          0.37058982,
          1.9923255,
          -3.5235791,
          1.0589272,
          -3.5893714,
          -0.358136,
          -1.0410056,
          0.2920583,
          0.77945143,
          3.6989596,
          -3.0047255,
          0.7282234,
          -0.18584378,
          0.3561805,
          -3.3596945,
          -2.1256204,
          0.84079474,
          1.5124916,
          -1.1406085,
          3.413795,
          -0.9146504,
          -1.0099646,
          0.0690559,
          3.496024,
          4.3595395,
          4.2920485,
          3.1177442,
          0.47684225,
          0.6099366,
          -4.3030524,
          -0.6393857,
          -1.6374341,
          -4.2579145,
          -0.35346603,
          -0.37913314,
          -4.745396,
          -1.015843,
          4.002356,
          1.7096914,
          -3.043784,
          -0.5642588,
          -0.055707615
         ],
         "xaxis": "x",
         "y": [
          -2.9950175,
          -5.2091346,
          -2.8350642,
          -5.2923365,
          2.3692398,
          -2.4817798,
          0.49666247,
          -0.6238623,
          -5.9101458,
          -5.2374773,
          2.8889308,
          -0.68551457,
          -4.220539,
          -5.7306695,
          3.870152,
          -4.9250927,
          -4.618416,
          4.5279303,
          -5.134667,
          -3.7042062,
          -5.262185,
          -2.670041,
          4.2271714,
          1.7109183,
          2.4861975,
          3.506242,
          -0.27172172,
          0.4933078,
          3.6457787,
          3.079326,
          -0.042089727,
          -2.7957108,
          -0.20596536,
          -0.0056539895,
          3.2106996,
          4.344126,
          2.8071346,
          -3.1848488,
          0.6357298,
          -3.5218992,
          2.0780616,
          4.070653,
          2.3395197,
          -0.68959713,
          3.1291666,
          3.6312697,
          4.3183875,
          3.2690122,
          -3.2710192,
          2.328568,
          3.3832529,
          0.2032581,
          -3.1606522,
          3.6867163,
          -2.0300043,
          -0.93108016,
          4.6119423,
          -2.7650406,
          4.093739,
          -0.14709456,
          -2.026911,
          4.0488195,
          -1.1878371,
          2.4373543,
          1.4310108,
          3.6377835,
          -0.3098093,
          2.6687949,
          3.4010432,
          3.335442,
          -1.0705855,
          3.5962713,
          3.6813953,
          3.9075656,
          3.720527,
          4.545649,
          2.883565,
          4.1727405,
          1.4927117,
          2.4769566,
          0.4951866,
          -3.591704,
          2.3170056,
          3.9375806,
          -2.4224243,
          3.515946,
          -5.3794346,
          2.5280504,
          -4.9540696,
          3.7696927,
          -6.9831476,
          1.3170886,
          -2.7842932,
          -4.838499,
          -5.702142,
          -5.372258,
          3.6590075,
          3.384103,
          -1.7158126,
          2.5747745,
          3.5719664,
          -3.4036222,
          -2.4157984,
          -2.3100467,
          -5.2724795,
          -3.8720787,
          -3.6689553,
          -4.3010178,
          3.0442004,
          -4.745671,
          3.8509703,
          -3.8970306,
          4.578815,
          0.13224299,
          -1.001193,
          0.21744154,
          -3.624381,
          -0.3422237,
          -2.9880588,
          3.3734586,
          3.5639544,
          -4.092677,
          -5.1213365,
          3.4217896,
          -3.452878,
          3.9238153,
          1.4862725,
          0.6299039,
          -4.1785264,
          -2.3970728,
          -0.21698615,
          2.918797,
          -4.4757657,
          -4.5143986,
          -5.838102,
          -5.648692,
          -0.9776436,
          -1.6531392,
          -5.6535077,
          -5.1406417,
          -4.662358,
          0.36761048,
          -3.8866134,
          -2.988789,
          -4.3546576,
          -2.9201226,
          -2.9100997,
          3.4171937,
          -4.6137934,
          -3.3671246,
          3.4370713,
          0.82259464,
          -3.7603838,
          -3.4371731,
          -1.5309646,
          -6.1604104,
          -4.2719817,
          3.3990734,
          -5.329631,
          -0.6569021,
          1.3743938,
          3.803671,
          -5.26112,
          1.382363,
          -4.98475,
          -6.1232414,
          -4.440053,
          -2.7220926,
          4.421009,
          1.0824544,
          -4.693746,
          -6.1285954,
          -0.34644124,
          -3.269843,
          3.4713118,
          1.7258134,
          1.9382406,
          -4.4359837,
          -4.040361,
          -4.7896185,
          -1.3308953,
          -5.5081606,
          -3.8632498,
          -2.9180372,
          -5.200044,
          2.397851,
          -3.9921317,
          -4.728136,
          -4.742504,
          2.2366111,
          1.7990168,
          -6.0722065,
          2.5060656,
          -0.80403715,
          -1.0987595,
          -4.9572754,
          -4.538524,
          -5.041064,
          -4.8803716,
          -3.0612316,
          1.842277,
          -5.837803,
          -6.0051026,
          -3.8576322,
          0.12721665,
          -5.677976,
          3.7205665,
          -4.336646,
          -5.264448,
          2.043789,
          -4.4380183,
          0.53550935,
          -5.516321,
          3.5423613,
          2.084977,
          -5.677438,
          1.0362482,
          -0.60650396,
          -0.6558857,
          0.37697154,
          3.1309955,
          1.2323601,
          -5.0244846,
          -0.24386232,
          -4.154293,
          -2.632601,
          1.4444156,
          -2.4562988,
          -5.6561832,
          -2.6284385,
          -5.081143,
          -1.9010254,
          -4.2238965,
          4.3479333,
          1.4393566,
          1.3171494,
          -3.0281672,
          3.7959847,
          -3.8348954,
          -1.4349658,
          -3.7809782,
          -1.631319,
          4.0808268,
          -6.8949885,
          -4.5317597,
          -5.1723347,
          -5.242547,
          -4.325703,
          -5.4512386,
          -4.653888,
          0.30103406,
          -5.4262466,
          -4.0525775,
          -5.611934,
          -4.9491763,
          -5.1258507,
          4.9644556,
          -5.0420246,
          3.0790846,
          2.3346372,
          -5.0875998,
          -5.4422054,
          -5.756741,
          0.9814292,
          -5.862049,
          -2.3007102,
          2.6357095,
          -5.2017155,
          2.0835345,
          2.8769667,
          -4.4383802,
          -4.0756574,
          -4.8791633,
          1.6280377,
          4.6300907,
          -0.6488277,
          2.3586118,
          -3.8034186,
          -0.45368525,
          -2.9842808,
          -6.2980466,
          -3.6441512,
          -5.7346334,
          2.2520168,
          -4.005059,
          -0.55360144,
          4.9092684,
          1.3117013,
          -4.7525997,
          -5.2172437,
          -7.059036,
          2.5068839,
          2.7328386,
          -4.742876,
          3.5635817,
          -6.016234,
          -1.3894571,
          -2.729131,
          -3.1294568,
          1.8663051,
          3.3369524,
          -3.9949055,
          -4.959149,
          1.2451487,
          -1.7513759,
          0.48312938,
          -5.752176,
          -6.393192,
          -0.81053245,
          -2.550751,
          -1.5639083,
          1.9862891,
          -3.2240121,
          -2.4821725,
          3.1057923,
          -2.2489924,
          -2.4165075,
          -5.44785,
          0.7457498,
          -1.7770131,
          4.830162,
          -4.7935076,
          -5.524074,
          2.7750247,
          -4.353006,
          -5.29663,
          -1.8392125,
          -6.665839,
          2.0311859,
          -1.496474,
          0.5844177,
          -3.7007067,
          -5.658103,
          -5.1025968,
          3.285605,
          2.7492554,
          -4.915949,
          -5.0769076,
          -3.5403826,
          -2.9035785,
          2.1688032,
          -5.597345,
          -4.4210734,
          -1.0215136,
          1.8969905,
          -1.4521359,
          -4.4097147,
          -5.59373,
          -6.732198,
          -5.3052673,
          5.012724,
          -5.0935173,
          -4.7188473,
          -5.87165,
          -5.2418666,
          -5.1334634,
          -4.903718,
          -4.4732556,
          -3.961528,
          3.7874014,
          -5.50276,
          -3.7854774,
          0.39539403,
          -5.233136,
          3.0498717,
          -0.5463429,
          -5.754041,
          -5.7727604,
          2.663464,
          -4.6956444,
          1.1673301,
          1.8468899,
          -0.8490434,
          -0.9725822,
          -3.697082,
          1.9482337,
          -4.845251,
          -4.9712,
          -4.6105075,
          -6.184319,
          -3.9149609,
          -4.3301578,
          -2.769769,
          2.3544264,
          -5.1381917,
          3.3322933,
          -5.897575,
          -5.323182,
          19.58312,
          4.558408,
          2.453474,
          -4.64366,
          1.5377553,
          -3.469314,
          1.2618443,
          4.7826624,
          -1.501489,
          -3.4407437,
          -5.1703963,
          -5.8118596,
          1.7530916,
          4.7972174,
          -6.1311445,
          -0.96486557,
          5.1647162,
          -0.67801595,
          -5.2721105,
          1.5997833,
          -0.76717085,
          -5.400912,
          3.9852514,
          -4.4221535,
          0.14876942,
          4.027104,
          -5.691913,
          -0.3090305,
          -4.9895434,
          -3.9047494,
          -0.2699963,
          -4.965875,
          -5.058771,
          -0.7102059,
          0.5381737,
          -0.8630807,
          2.4890995,
          -2.5157855,
          1.2337312,
          -6.290852,
          2.7631447,
          -3.7741582,
          -4.937547,
          -6.977349,
          -6.534988,
          -0.20912065,
          4.23871,
          -2.7961533,
          -4.008762,
          1.1328042,
          -2.6280563,
          2.821718,
          -5.0705295,
          -5.143022,
          1.0338418,
          1.7614919,
          0.4085588,
          2.9698403,
          -5.3830395,
          -4.5913463,
          4.4420695,
          -4.4275446,
          -0.74816287,
          -3.4803405,
          -5.635998,
          0.24949566,
          -5.3593497,
          -0.5518917,
          -1.3679428,
          -5.693438,
          -3.05232,
          -0.28065413,
          -5.3994,
          -4.9509397,
          -1.0342228,
          2.6008382,
          -2.0157425,
          -3.4459026,
          -4.2462263,
          -2.5327313,
          2.1272876,
          1.3842452,
          -4.1921654,
          -5.0758038,
          2.7787137,
          -1.787773,
          -5.668883,
          4.6693816,
          0.32635748,
          -5.749799,
          -4.913872,
          -5.3806014,
          -4.3428044,
          -5.1923594,
          -4.518797,
          -3.7105577,
          1.4930006,
          2.0952802,
          -3.7531002,
          -0.54581916,
          -3.175412,
          -6.154975,
          -3.6842048,
          0.960602,
          -4.5190835,
          -5.990313,
          -3.900159,
          -2.7694037,
          -5.421231,
          -4.428401,
          -5.5966344,
          4.864385,
          -3.0078115,
          2.6538703,
          -0.1750085,
          -2.1186123,
          -5.3623238,
          0.5612711,
          -4.731572,
          3.184424,
          -4.0471377,
          -1.6890076,
          -4.4279175,
          0.23071589,
          3.3980963,
          -3.9337194,
          -4.4520493,
          3.862544,
          -2.442715,
          0.62396884,
          2.3304687,
          3.383377,
          2.3393571,
          0.101092584,
          -6.231574,
          -5.52762,
          -2.345654,
          -4.4559455,
          0.4225304,
          1.4807063,
          2.4039462,
          0.5622954,
          -0.89304805,
          2.5093281,
          2.974133,
          -1.5449519,
          -4.5633144,
          -5.1884494,
          1.7831013,
          0.69275284,
          -2.5955539,
          1.6836085,
          2.3227246,
          3.4436123,
          -0.036131185,
          0.29184246,
          3.6654406,
          2.838896,
          -0.24075331,
          -2.815511,
          -0.0067949295,
          -0.36423084,
          2.9713438,
          4.1419506,
          2.9568958,
          -3.3260062,
          1.0505546,
          -3.3149989,
          2.1786385,
          3.9149098,
          2.5662503,
          -0.9310447,
          2.6684463,
          3.7470424,
          4.357407,
          3.206793,
          -3.5102537,
          2.6020997,
          3.2867794,
          0.056406047,
          -2.943188,
          3.5687418,
          -1.9637494,
          -0.8751084,
          4.742858,
          -2.726123,
          4.2258277,
          -0.34832865,
          -2.3173933,
          4.1203156,
          -1.17799,
          2.245089,
          1.6234354,
          3.6856227,
          -0.3633808,
          2.8148253,
          3.091811,
          3.2965245,
          -0.82582253,
          3.3515563,
          3.5631406,
          3.9190876,
          3.6610355,
          4.5988336,
          2.9601326,
          4.0313897,
          1.4767909,
          2.643071,
          0.65711,
          -3.6798472,
          2.1276188,
          3.661553,
          -2.2721713,
          3.584063,
          -5.3974605,
          -3.609388,
          1.1694599,
          0.18372974,
          -5.15942,
          -6.680679,
          -6.318194,
          -3.9112399,
          -4.7941465,
          -2.1316936,
          4.7778788,
          0.10126127,
          -3.2157712,
          3.7840855,
          1.664006,
          -1.988032,
          0.94375867,
          -0.30696508,
          -0.1080098,
          -4.327719,
          -4.8382854,
          3.2625716,
          -5.051449,
          0.35324317,
          -6.311983,
          -5.836171,
          -3.0651195,
          -1.1748295,
          3.9689555,
          -5.9902906,
          -4.9882555,
          -1.6962199,
          -5.5297527,
          -4.8347554,
          -5.5100007,
          -5.03209,
          -0.7897809,
          -4.2418013,
          -3.146835,
          -2.6510148,
          -5.618515,
          2.4623218,
          -5.6450214,
          -3.7244835,
          -4.484366,
          3.1477363,
          -5.681214,
          -4.7019024,
          2.1389925,
          -4.2659826,
          2.676649,
          -2.595219,
          -1.7535259,
          -0.2923979,
          -2.9780347,
          3.5847182,
          1.075875,
          4.0695243,
          -1.3918647,
          -5.828364,
          -6.8200636,
          -1.1933917,
          -4.5644937,
          -4.8583403,
          1.211448,
          -4.196679,
          2.929055,
          -5.8491473,
          -1.5276175,
          4.6567016,
          -5.8026342
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThis might seem very restrictive at first, but most neural net code doesn’t need to do this. Yo..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n     <img src=\"https://huggingface.co/datasets/huggingface/do..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "🤗 Transformers опирается на три самые популярные библиотеки глубокого обучения - [Jax](https://jax.r..."
          ],
          [
           "```\n\nВторая строка кода загружает и кэширует предварительно обученную модель, используемую конвейеро..."
          ],
          [
           "```\n\nО том, как установить Flax, PyTorch или TensorFlow с помощью conda, читайте на страницах, посвя..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (fr..."
          ],
          [
           "1. **[LeViT](https://huggingface.co/docs/transformers/model_doc/levit)** (from Meta AI) released wit..."
          ],
          [
           "1. **[MEGA](https://huggingface.co/docs/transformers/model_doc/mega)** (from Meta/USC/CMU/SJTU) rele..."
          ],
          [
           "1. **[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)** (from Meta AI) released ..."
          ],
          [
           "1. **[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)** (from Facebook), releas..."
          ],
          [
           "1. **[TAPAS](https://huggingface.co/docs/transformers/model_doc/tapas)** (from Google AI) released w..."
          ],
          [
           "1. **[VITS](https://huggingface.co/docs/transformers/model_doc/vits)** (from Kakao Enterprise) relea..."
          ],
          [
           "Чтобы проверить, есть ли у каждой модели реализация на Flax, PyTorch или TensorFlow, или связанный с..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThis creates a repository under your username with the model name `my-awesome-model`. Users can..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Author: [@vasudevgupta7](https://github.com/thevasudevgupta/)\n\n## Intro\n\nIn this project, we fine-tu..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "### PyTorch Examples\n\n#### Natural Language Processing[[pytorch-nlp]]\n\n| Notebook     |      Descrip..."
          ],
          [
           "#### Computer Vision[[pytorch-cv]]\n\n| Notebook                                                      ..."
          ],
          [
           "#### Audio[[pytorch-audio]]\n\n| Notebook     |      Description      |   |   |\n|:----------|:--------..."
          ],
          [
           "### TensorFlow Examples\n\n#### Natural Language Processing[[tensorflow-nlp]]\n\n| Notebook     |      D..."
          ],
          [
           "#### Biological Sequences[[tensorflow-bio]]\n\n| Notebook     |      Description      |   |   |\n|:----..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "*TEMPLATE**\n=====================================\n\n*search & replace the following keywords, e.g.:*\n..."
          ],
          [
           "```\n\nSimilar to the model, the configuration inherits basic serialization and\ndeserialization functi..."
          ],
          [
           "```\n\n3.  Set up a development environment, for instance by running the\n    following command:\n\n    `..."
          ],
          [
           "```\n\nNext, regarding the debugging strategy, there are generally a few from\nwhich to choose from:\n\n-..."
          ],
          [
           "```\n\nWe expect that every model added to 🤗 Transformers passes a couple of\nintegration tests, meanin..."
          ],
          [
           "```\n    git checkout -b add_[lowercase name of model]\n```\n\n2.  Commit the automatically generated co..."
          ],
          [
           "```\n\nNow we can create an instance of this model definition which will fill\nall weights: `dense`, `i..."
          ],
          [
           "```\n\nIt is very likely that the 🤗 Transformers implementation and the\noriginal model implementation ..."
          ],
          [
           "```\n\nYou might have to take a deeper look again into the original repository\nto find the correct tok..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\n- [Translation task guide](../tasks/translation)\n- [Summarization task guide](../..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe warning is telling us we are throwing away some weights (e.g. the weights and bias of the `..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/doc..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n第二行代码下载并缓存了流水线使用的预训练模型，而第三行代码则在给定的文本上进行了评估。这里的答案“正面” (positive) 具有 99 的置信度。\n\n许多的 NLP 任务都有开箱即用的预..."
          ],
          [
           "```\n\n要通过 conda 安装 Flax、PyTorch 或 TensorFlow 其中之一，请参阅它们各自安装页的说明。\n\n## 模型架构\n\n🤗 Transformers 支持的[**所有的模型..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (来自 Google Research and t..."
          ],
          [
           "1. **[BROS](https://huggingface.co/docs/transformers/model_doc/bros)** (来自 NAVER CLOVA) 伴随论文 [BROS: ..."
          ],
          [
           "1. **[Deformable DETR](https://huggingface.co/docs/transformers/model_doc/deformable_detr)** (来自 Sen..."
          ],
          [
           "1. **[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)** (from Technology Innovati..."
          ],
          [
           "1. **[Graphormer](https://huggingface.co/docs/transformers/model_doc/graphormer)** (from Microsoft) ..."
          ],
          [
           "1. **[LLaVa](https://huggingface.co/docs/transformers/model_doc/llava)** (来自 Microsoft Research & Un..."
          ],
          [
           "1. **[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)** (来自 CMU/Google Br..."
          ],
          [
           "1. **[Perceiver IO](https://huggingface.co/docs/transformers/model_doc/perceiver)** (来自 Deepmind) 伴随..."
          ],
          [
           "1. **[SeamlessM4Tv2](https://huggingface.co/docs/transformers/model_doc/seamless_m4t_v2)** (from Met..."
          ],
          [
           "1. **[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)** (来自 Microsoft) 伴随论文 [TrOCR:..."
          ],
          [
           "1. **[Wav2Vec2-Conformer](https://huggingface.co/docs/transformers/model_doc/wav2vec2-conformer)** (..."
          ],
          [
           "要检查某个模型是否已有 Flax、PyTorch 或 TensorFlow 的实现，或其是否在 🤗 Tokenizers 库中有对应词符化器（tokenizer），敬请参阅[此表](https://h..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe parameter `modules_to_fuse` should include:\n\n- `\"attention\"`: The names of the attention la..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"4-bit\">\n\n```bash\npip install bitsandbytes>=0.39.0\npip install --upgra..."
          ],
          [
           "```\n\n#### Normal Float 4 (NF4)\n\nNF4 is a 4-bit data type from the [QLoRA](https://hf.co/papers/2305...."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<PipelineTag pipeline=\"question-answering\"/>\n\n- [`XLMRobertaForQuestionAnswering`] is supported by t..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n\n- Example of processing multiple audio files in batch (Using `Pop2PianoFeatureExtractor` and `..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### Fine-tuning BERT on SQuAD1.0 with relative position embeddings\n\nThe following examples show how ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Note that `config.num_buckets` can also be factorized into a list \\\\((n_{\\text{buckets}}^1,\nn_{\\text..."
          ],
          [
           "```\n\n## Resources\n\n- [Text classification task guide](../tasks/sequence_classification)\n- [Question ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nFor larger datasets where the inputs are big (like in speech or vision), you'll want to pass a ..."
          ],
          [
           "```\n\n<Tip>\n\nSee the [task summary](./task_summary) for tasks supported by an [`AutoModel`] class.\n\n<..."
          ],
          [
           "```\n\n6. A [`DataCollatorWithPadding`] to create a batch of examples from your dataset:\n\n   ```py\n   ..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Training\n\nOnce the model is created, it can be fine-tuned similar to BART, T5 or any other e..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n- After conversion, the model and tokenizer can be loaded via:\n\n```python\nfrom transformers imp..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Performer fine-tuning\n\nExample authors: @TevenLeScao, @Patrickvonplaten\n\nPaper authors: Krzysztof Ch..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "End-to-End finetuning of RAG (including DPR retriever) for Question Answering.\n\nThis finetuning scri..."
          ],
          [
           "!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\n\nLicensed under ..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n- Step-by-step Document Visual Question Answering (DocVQA)\n\n```py\n>>> import re\n\n>>> from trans..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## Resources\n\nDemo notebooks regarding inference as well as fine-tuning ViT on custom data can be fo..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n It results in a Micro F1 score of around 0.82 without any text and label filtering. Note that y..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Preprocessing data\n\nThe next step is to load a ViLT processor to prepare the image and text ..."
          ],
          [
           "```\n\nThe model takes image and text as input, so let's use the exact same image/question pair from t..."
          ],
          [
           "!---\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\n\nLicense..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n코드의 두번째 줄은 pipeline이 사용하는 사전학습 모델을 다운로드하고 캐시로 저장합니다. 세번째 줄에선 그 모델이 주어진 텍스트를 평가합니다. 여기서 모델은 99.9..."
          ],
          [
           "```\n\nFlax, PyTorch, TensorFlow 설치 페이지에서 이들을 conda로 설치하는 방법을 확인하세요.\n\n## 모델 구조\n\n**🤗 Transformers가 제공하는..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (Microsoft 에서) Pe..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (Baidu 에서) Yu Sun, Shuohuan..."
          ],
          [
           "1. **[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (from EleutherAI) released i..."
          ],
          [
           "1. **[LiLT](https://huggingface.co/docs/transformers/model_doc/lilt)** (South China University of Te..."
          ],
          [
           "1. **[Megatron-GPT2](https://huggingface.co/docs/transformers/model_doc/megatron_gpt2)** (NVIDIA 에서)..."
          ],
          [
           "1. **[OneFormer](https://huggingface.co/docs/transformers/model_doc/oneformer)** (SHI Labs 에서) Jites..."
          ],
          [
           "1. **[Reformer](https://huggingface.co/docs/transformers/model_doc/reformer)** (Google Research 에서) ..."
          ],
          [
           "1. **[SwitchTransformers](https://huggingface.co/docs/transformers/model_doc/switch_transformers)** ..."
          ],
          [
           "1. **[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)** (Google AI..."
          ],
          [
           "1. **[XLNet](https://huggingface.co/docs/transformers/model_doc/xlnet)** (Google/CMU 에서) Zhilin Yang..."
          ],
          [
           "각 모델이 Flax, PyTorch, TensorFlow으로 구현되었는지 또는 🤗 Tokenizers 라이브러리가 지원하는 토크나이저를 사용하는지 확인하려면, [이 표](https..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\nFROM intel/ai-workflows:torch-2.0.1-huggingface-multinode-py3.9\n\nWORKDIR /workspace\n\n# Download ..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team and The OpenBMB Team. All rights reserved.\n\nLicensed under th..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<Tip>\n\nIt is a good idea to include the `bad_words_ids` in the call to `generate` to avoid erro..."
          ],
          [
           "```\n\n## Image classification\n\nIDEFICS is capable of classifying images into different categories wit..."
          ],
          [
           "```\n\n## IDEFICS instruct for conversational use\n\nFor conversational use cases, you can find fine-tun..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "🤗 Transformers is backed by the three most popular deep learning libraries — [Jax](https://jax.readt..."
          ],
          [
           "```\n\nThe second line of code downloads and caches the pretrained model used by the pipeline, while t..."
          ],
          [
           "```\n\nFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with co..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (fr..."
          ],
          [
           "1. **[LED](https://huggingface.co/docs/transformers/model_doc/led)** (from AllenAI) released with th..."
          ],
          [
           "1. **[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from Facebook) released..."
          ],
          [
           "1. **[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta) released with the..."
          ],
          [
           "1. **[PVT](https://huggingface.co/docs/transformers/model_doc/pvt)** (from Nanjing University, The U..."
          ],
          [
           "1. **[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)** (from Berkeley)..."
          ],
          [
           "1. **[UPerNet](https://huggingface.co/docs/transformers/model_doc/upernet)** (from Peking University..."
          ],
          [
           "1. **[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook) released togeth..."
          ],
          [
           "To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated to..."
          ],
          [
           "```..."
          ],
          [
           "CodeParrot 🦜\n<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/lvwerra/repo-images/ra..."
          ],
          [
           "```\n\nNote that during the `accelerate` configuration we enabled FP16. Then to train the large model ..."
          ],
          [
           "```\nThe training takes almost 12 hours in this setting.\n\n### Convert model to `transformers`\nAfter t..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n<Tip>\n\n If you plan to run multiple experiments, in order to properly clear the memory between ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNow create a batch of examples using [`DataCollatorWithPadding`]. It's more efficient to *dynam..."
          ],
          [
           "```\n\nThe simplest way to try out your finetuned model for inference is to use it in a [`pipeline`]. ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 NVIDIA and The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache L..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "[[autodoc]] models.perceiver.modeling_perceiver.PerceiverDecoderOutput\n\n[[autodoc]] models.perceiver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pled..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nthen\n\n```bash\npython run_summarization_no_trainer.py \\\n    --model_name_or_path t5-small \\\n    ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIn the above example, your effective batch size becomes 4. \n\nAlternatively, use 🤗 Accelerate to..."
          ],
          [
           "```\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.allow_tf32 = True..."
          ],
          [
           "```\n\nFinally, pass the custom optimizer as an argument to the `Trainer`:\n\n```py\ntrainer = Trainer(mo..."
          ],
          [
           "```\n\nThe full example training loop with 🤗 Accelerate is only a handful of lines of code long:\n\n```p..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "## Motivation\nWithout processing, english-> romanian mbart-large-en-ro gets BLEU score 26.8 on the W..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n   As compared to providing just the last line of the error message, e.g.:\n   ```python\n   Modu..."
          ],
          [
           "```\n   <details>\n   <summary>Full log</summary>\n   <pre>\n\n   many\n   lines\n   go\n   here\n\n   </pre>\n..."
          ],
          [
           "```\n    > How big is your gpu cluster?\n\n    Our cluster is made of 256 gpus.\n    ```\n\n    If you are..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nAdditional checks concern PRs that add new models, mainly that:\n\n- All models added are in an A..."
          ],
          [
           "Movement Pruning: Adaptive Sparsity by Fine-Tuning\n\nAuthor: @VictorSanh\n\n*Magnitude pruning is a wid..."
          ],
          [
           "```\n\nL0 regularization\n```bash\npython examples/movement-pruning/masked_run_squad.py \\\n    --output_d..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### Encoder[[nlp-encoder]]\n\n[BERT](model_doc/bert) is an encoder-only Transformer that randomly mask..."
          ],
          [
           "### Encoder[[mm-encoder]]\n\n[VisualBERT](model_doc/visual_bert) is a multimodal model for vision-lang..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "```\n\n2. Add adapter to the model.\n\n```py\nmodel.add_adapter(peft_config)\n```\n\n3. Now you can pass the..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 Mistral AI and The HuggingFace Team. All rights reserved.\n\nLicensed under the Apac..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Image segmentation\n\nImage segmentation is a pixel-level task that assigns every pixel in an..."
          ],
          [
           "```\n\n### Summarization\n\nSummarization creates a shorter version of a text from a longer one while tr..."
          ],
          [
           "!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\n\nLicensed under ..."
          ],
          [
           "Summarization (Seq2Seq model) training examples\n\nThe following example showcases how to finetune a s..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n**Use case 3: token classification (training), parse_html=False**\n\nFor token classification tas..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\nA list of official Hugging Face and community (indicated by 🌎) resources to help ..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n3. Create a new branch to hold your development changes:\n\n   ```bash\n   git checkout -b a-descr..."
          ],
          [
           "```\n\nSimilarly, for the `examples` directory, specify a *path to a subfolder or test file* to run th..."
          ],
          [
           "!--Copyright 2023 The Intel Labs Team Authors, The Microsoft Research Team Authors and HuggingFace I..."
          ],
          [
           "```\n\nTips:\n\n- This implementation of BridgeTower uses [`RobertaTokenizer`] to generate text embeddin..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 NVIDIA Corporation. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nTokenize the text:\n\n```py\n>>> encoded_en = tokenizer(en_text, return_tensors=\"pt\")\n```\n\nMBart f..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nAnd that's it! In a few lines of code, you can harness the power of an LLM.\n\n\n## Common pitfall..."
          ],
          [
           "```\n\n## Further resources\n\nWhile the autoregressive generation process is relatively straightforward..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIf you only want the infilled part:\n```python\n>>> from transformers import pipeline\n>>> import ..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Expected speedups\n\nBelow is an expected speedup diagram that compares pure inference time b..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<PipelineTag pipeline=\"fill-mask\"/>\n\n- A blog on [How to train a new language model from scratch usi..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "```\nand run the example command as usual afterward.\n\n## Running the Examples on Remote Hardware with..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The Microsoft Inc. and The HuggingFace Inc. Team. All rights reserved.\n\nLicensed..."
          ],
          [
           "```\n\n### How to Evaluate TAPEX Fine-tuned Models on TableQA\n\nWe provide fine-tuned model weights to ..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "En visión de ordenador:\n- [Clasificación de imágenes con ViT](https://huggingface.co/google/vit-base..."
          ],
          [
           "```\n\nLa segunda línea de código descarga y almacena en caché el modelo previamente entrenado que usa..."
          ],
          [
           "```\n\nSigue las páginas de instalación de Flax, PyTorch o TensorFlow para ver cómo instalarlos con co..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (fr..."
          ],
          [
           "1. **[LED](https://huggingface.co/docs/transformers/model_doc/led)** (from AllenAI) released with th..."
          ],
          [
           "1. **[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from Facebook) released..."
          ],
          [
           "1. **[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta) released with the..."
          ],
          [
           "1. **[PVT](https://huggingface.co/docs/transformers/model_doc/pvt)** (from Nanjing University, The U..."
          ],
          [
           "1. **[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)** (from Berkeley)..."
          ],
          [
           "1. **[UPerNet](https://huggingface.co/docs/transformers/model_doc/upernet)** (from Peking University..."
          ],
          [
           "1. **[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook) released togeth..."
          ],
          [
           "Para comprobar si cada modelo tiene una implementación en Flax, PyTorch o TensorFlow, o tiene un tok..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\nrm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 \\\npython examples/pytorch/language-modeling/run_cl..."
          ],
          [
           "```\n\nIn this example, when data moves from layer 0 to 3, it's no different from regular forward pass..."
          ],
          [
           "Other approaches:\n\nDeepSpeed, Varuna and SageMaker use the concept of an [Interleaved Pipeline](http..."
          ],
          [
           "🤗 Transformers status: not yet implemented, since we have no PP and TP.\n\n## ZeRO Data Parallelism + ..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"Accelerate\">\n\nUse `--num_processes` to select how many GPUs to use.\n\n..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nOr you can replace the text-to-text generation snippet with the model dedicated to the T2TT tas..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Wav2Vec2 specific outputs\n\n[[autodoc]] models.wav2vec2_with_lm.processing_wav2vec2_with_lm.W..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nRunning this with the stride length equal to the max input length is equivalent to the suboptim..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "# 🔥 Model cards now live inside each huggingface.co model repo 🔥\n\n\nFor consistency, ease of use and ..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "🤗 Transformers तीन सबसे लोकप्रिय गहन शिक्षण पुस्तकालयों का समर्थन करता है： [Jax](https://jax.readthe..."
          ],
          [
           "```\n\nकोड की दूसरी पंक्ति पाइपलाइन द्वारा उपयोग किए गए पूर्व-प्रशिक्षित मॉडल को डाउनलोड और कैश करती ह..."
          ],
          [
           "```\n\nकोंडा के माध्यम से Flax, PyTorch, या TensorFlow में से किसी एक को स्थापित करने के लिए, निर्देशो..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (Google Research and the ..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (हरबिन इंस्टिट्..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (Microsoft से) सा..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)**(Baidu से) साथ देने वाला पेप..."
          ],
          [
           "1. **[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (EleutherAI से) साथ वाला पेप..."
          ],
          [
           "1. **[LeViT](https://huggingface.co/docs/transformers/model_doc/levit)** (मेटा AI से) साथ वाला पेपर ..."
          ],
          [
           "1. **[MEGA](https://huggingface.co/docs/transformers/model_doc/mega)** (Facebook से) Xuezhe Ma, Chun..."
          ],
          [
           "1. **[Nougat](https://huggingface.co/docs/transformers/model_doc/nougat)** (Meta AI से) Lukas Bleche..."
          ],
          [
           "1. **[QDQBert](https://huggingface.co/docs/transformers/model_doc/qdqbert)** (NVIDIA से) साथ वाला पे..."
          ],
          [
           "1. **[SwiftFormer](https://huggingface.co/docs/transformers/model_doc/swiftformer)** (MBZUAI से) Abd..."
          ],
          [
           "1. **[VAN](https://huggingface.co/docs/transformers/model_doc/van)** (सिंघुआ यूनिवर्सिटी और ननकाई यू..."
          ],
          [
           "1. **[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (फेसबुक से) साथ में पेपर [क्रॉस..."
          ],
          [
           "यह जांचने के लिए कि क्या किसी मॉडल में पहले से ही Flax, PyTorch या TensorFlow का कार्यान्वयन है, या ..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\nor use the launcher provided by `deepspeed`:\n\n```bash\ndeepspeed --num_gpus=2 your_program.py <no..."
          ],
          [
           "```\n\nAll is left is to schedule it to run:\n```bash\nsbatch launch.slurm\n```\n\n`srun` will take care of..."
          ],
          [
           "```\n\nor:\n\n```python\nds_config_dict = dict(scheduler=scheduler_params, optimizer=optimizer_params)\nTr..."
          ],
          [
           "```\n\nIf you are getting OOMs, because your model or activations don't fit into the GPU memory and yo..."
          ],
          [
           "```\n\nYou can choose to offload both optimizer states and params to NVMe, or just one of them or none..."
          ],
          [
           "```\n\n#### How to Choose Which ZeRO Stage and Offloads To Use For Best Performance\n\nSo now you know t..."
          ],
          [
           "```\n\nBut then you're on your own synchronizing the [`Trainer`] command line arguments and the DeepSp..."
          ],
          [
           "```\n\nBut then you're on your own synchronizing the [`Trainer`] command line arguments and the DeepSp..."
          ],
          [
           "```\n\nIf you're using the `--load_best_model_at_end` class:*~transformers.TrainingArguments* argument..."
          ],
          [
           "```\n\nstress on `tensor([1.])`, or if you get an error where it says the parameter is of size `1`, in..."
          ],
          [
           "```\n\n4. If possible include a link to a Google Colab notebook that we can reproduce the problem with..."
          ],
          [
           "```\n\nor for non-pretrained model:\n\n```python\nfrom transformers.integrations import HfDeepSpeedConfig..."
          ],
          [
           "```\n\nLet's save it as `t0.py` and run it:\n```\n$ deepspeed --num_gpus 2 t0.py\nrank0:\n   in=Is this re..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nand reply to the questions asked regarding the environment on which you'd like to train. Then\n\n..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n</tf>\n</frameworkcontent>\n\n## Distributed training and mixed precision\n\nThe [Trainer](https://hu..."
          ],
          [
           "```\n\n## Share your model\n\nAll scripts can upload your final model to the [Model Hub](https://hugging..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nWhen you load pretrained weights, the default model configuration is automatically loaded if th..."
          ],
          [
           "```\n\n<Tip>\n\nIf you aren't looking for any customization, just use the `from_pretrained` method to lo..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n## Evaluation Commands\n\nTo create summaries for each article in dataset, we use `run_eval.py`, ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\npip install --upgrade pip\npip install datasets[audio]\n```\n\n```python\n>>> from transformers impor..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nEach subfield is now a separate column as indicated by the `answers` prefix, and the `text` fie..."
          ],
          [
           "```\n\nOnce training is completed, your model is automatically uploaded to the Hub so everyone can use..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n```bash\npytest --picked\n```\n\nAll tests will be run from files and folders which are modified, b..."
          ],
          [
           "```\n\nIf a test requires `tensorflow` use the `require_tf` decorator. For example:\n\n```python no-styl..."
          ],
          [
           "```\n\nSame as with `parameterized`, with `pytest.mark.parametrize` you can have a fine control over w..."
          ],
          [
           "```\n\nor the whole module:\n\n```python\nimport pytest\n\nif not pytest.config.getoption(\"--custom-flag\"):..."
          ],
          [
           "```\n\nHere is a full test example:\n\n```python\nfrom transformers.testing_utils import CaptureStdout\n\nm..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Awesome projects built with Transformers\n\nThis page lists awesome projects built on top of Transform..."
          ],
          [
           "Keywords: Adapters, LoRA, Parameter-efficient fine-tuning, Hub\n\n## [NeMo](https://github.com/NVIDIA/..."
          ],
          [
           "Keywords: Stable-Diffusion, Blender\n\n## [seldon-core](https://github.com/SeldonIO/seldon-core)\n\nSeld..."
          ],
          [
           "## [text-generation-webui](https://github.com/oobabooga/text-generation-webui/)\n\n[text-generation-we..."
          ],
          [
           "Keywords: Differential privacy\n\n## [LAVIS](https://github.com/salesforce/LAVIS)\n\n[LAVIS](https://git..."
          ],
          [
           "Keywords: Federated learning, Event-driven\n\n## [pythainlp](https://github.com/PyThaiNLP/pythainlp)\n\n..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "A biblioteca 🤗 Transformers é respaldada pelas três bibliotecas de aprendizado profundo mais popular..."
          ],
          [
           "```\n\nA segunda linha de código baixa e armazena em cache o modelo pré-treinado usado pelo pipeline, ..."
          ],
          [
           "```\n\nSiga as páginas de instalação do Flax, PyTorch ou TensorFlow para ver como instalá-los com cond..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (from EleutherAI) released i..."
          ],
          [
           "1. **[LiLT](https://huggingface.co/docs/transformers/model_doc/lilt)** (from South China University ..."
          ],
          [
           "1. **[Megatron-GPT2](https://huggingface.co/docs/transformers/model_doc/megatron_gpt2)** (from NVIDI..."
          ],
          [
           "1. **[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)** (from Meta AI) released ..."
          ],
          [
           "1. **[RoCBert](https://huggingface.co/docs/transformers/model_doc/roc_bert)** (from WeChatAI) releas..."
          ],
          [
           "1. **[Time Series Transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transf..."
          ],
          [
           "1. **[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)** (from Facebook AI) re..."
          ],
          [
           "1. Quer contribuir com um novo modelo? Adicionamos um **guia detalhado e modelos de exemplo** para o..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nWhile this may look like a lot, you're only really interested in the `text` field. What's cool ..."
          ],
          [
           "```\n</pt>\n<tf>\n<Tip>\n\nIf you aren't familiar with finetuning a model with Keras, take a look at the ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Token classification\n\n## PyTorch version, no Trainer\n\nFine-tuning (m)LUKE for token classification t..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nYour `compute_metrics` function is ready to go now, and you'll return to it when you setup your..."
          ],
          [
           "```\n</pt>\n<tf>\nTokenize the text and return the `input_ids` as TensorFlow tensors:\n\n```py\n>>> from t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<Tip>\n\nThis can be helpful when the model is unable to understand your request and mixes tools...."
          ],
          [
           "```\n\nreturns the following code\n\n```python\nfrom transformers import load_tool\n\nimage_generator = loa..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### autoencoding models\n\nSee [encoder models](#encoder-models) and [masked language modeling](#..."
          ],
          [
           "```\n\nThe tokenizer takes care of splitting the sequence into tokens available in the tokenizer vocab..."
          ],
          [
           "```\n\nbecause this is the way a [`BertModel`] is going to expect its inputs.\n\n## L\n\n### labels\n\nThe l..."
          ],
          [
           "## R\n\n### recurrent neural network (RNN)\n\nA type of model that uses a loop over a layer to process t..."
          ],
          [
           "```\n\nWe can use our tokenizer to automatically generate such a sentence by passing the two sequences..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n2. Log in with your HuggingFace account credentials using `huggingface-cli`:\n\n```bash\n$ hugging..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNow you have two sets of characters: one with the vocabulary from the dataset and one with the ..."
          ],
          [
           "```\n\nYou'll see a warning saying that some examples in the dataset are longer than the maximum input..."
          ],
          [
           "```\n\nPick an example from the test dataset obtain a speaker embedding. \n\n```py \n>>> example = datase..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## Usage: fine-tuning\n\nHere we explain how you can fine-tune [`TapasForQuestionAnswering`] on your o..."
          ],
          [
           "```\n\nOf course, you don't necessarily have to follow one of these three ways in which TAPAS was fine..."
          ],
          [
           "```\n\nNote that [`TapasTokenizer`] expects the data of the table to be **text-only**. You can use `.a..."
          ],
          [
           "```\n</tf>\n</frameworkcontent>\n\nNote that here, we encode each table-question pair independently. Thi..."
          ],
          [
           "```\n</pt>\n<tf>\nHere we explain how you can use [`TFTapasForQuestionAnswering`] for inference (i.e. m..."
          ],
          [
           "## Translating the Transformers documentation into your language\n\nAs part of our mission to democrat..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nTo apply the preprocessing function over the entire dataset, use 🤗 Datasets [`~datasets.Dataset..."
          ],
          [
           "```\n\nThen you can load BERT with [`TFAutoModelForMultipleChoice`]:\n\n```py\n>>> from transformers impo..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nLet's have a side by side comparison for all types of segmentation.\n\n<div class=\"flex justify-c..."
          ],
          [
           "```\n\nTo apply the `jitter` over the entire dataset, use the 🤗 Datasets [`~datasets.Dataset.set_trans..."
          ],
          [
           "```\n\nOnce training is completed, share your model to the Hub with the [`~transformers.Trainer.push_t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Zero-shot classifier distillation\n\nAuthor: @joeddav \n\nThis script provides a way to improve the spee..."
          ],
          [
           "```\n\n> Tip: pass `device=0` when constructing a pipeline to run on a GPU\n\nAs we can see, the results..."
          ],
          [
           "!--Copyright 2023 Mistral AI and The HuggingFace Team. All rights reserved.\n\nLicensed under the Apac..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n````\n\nThe pattern the model is prompted to repeat has three parts: The task statement, the agen..."
          ],
          [
           "```\n\nNow \"modify\" is a strong cue to use the new image processor which should help with the above pr..."
          ],
          [
           "```\n\n<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transfo..."
          ],
          [
           "```\n\nWe pass that instance to the `Tool.from_gradio` method:\n\n```python\nfrom transformers import Too..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n</tf>\n</frameworkcontent>\n\nBy default, the _time_ and the _required memory_ for _inference_ are ..."
          ],
          [
           "```\n</tf>\n</frameworkcontent>\n\nAgain, _inference time_ and _required memory_ for _inference_ are mea..."
          ],
          [
           "!--Copyright 2023 IBM and HuggingFace Inc. team. All rights reserved.\n\nLicensed under the Apache Lic..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "[[autodoc]] GPT2DoubleHeadsModel\n    - forward\n\n## GPT2ForQuestionAnswering\n\n[[autodoc]] GPT2ForQues..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n    2. Save your files to a specified directory with [`PreTrainedModel.save_pretrained`]:\n\n    ..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "DeeBERT: Early Exiting for *BERT\n\nThis is the code base for the paper [DeeBERT: Dynamic Early Exitin..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nBefore passing the images to the `image_processor`, apply two preprocessing transformations to ..."
          ],
          [
           "```\n\nIn the [`TrainingArguments`] use `output_dir` to specify where to save your model, then configu..."
          ],
          [
           "```\n\nFinally, load the metrics and run the evaluation.\n\n```py\n>>> import evaluate\n>>> from tqdm impo..."
          ],
          [
           "Fine-Tuning week of XLSR-Wav2Vec2 on 60 languages 🌍\n\nWelcome to the fine-tuning week! The goal of th..."
          ],
          [
           "**2.**: Next, head over to the official [Fine-Tune XLSR-Wav2Vec2 with 🤗 Transformes](https://colab.r..."
          ],
          [
           "```\n\nand the line:\n\n```python\n  output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo..."
          ],
          [
           "```\n\nThen and add the following files that fully define a XLSR-Wav2Vec2 checkpoint into the reposito..."
          ],
          [
           "```\n\n\n## Evaluation\n\nThe model can be evaluated as follows on the {language} test data of Common Voi..."
          ],
          [
           "```\n\n**Test Result**: XX.XX %  # TODO: write output of print here. IMPORTANT: Please remember to als..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Flax/JAX community week 🤗\n\nWelcome to the Flax/JAX community week! The goal of this week is to make ..."
          ],
          [
           "All officially defined projects can be seen [here](https://docs.google.com/spreadsheets/d/1GpHebL7qr..."
          ],
          [
           "### Workload division\n\nTo effectively work as a team, it is crucial to divide the workload among eve..."
          ],
          [
           "```\n- Ask for help. If you are stuck, use the public Slack channel or the [forum](https://discuss.hu..."
          ],
          [
           "```\nJax should have been installed correctly nevertheless.\n\nTo verify that JAX was correctly install..."
          ],
          [
           "```\n\n## Quickstart flax and jax\n\n[JAX](https://jax.readthedocs.io/en/latest/index.html) is Autograd ..."
          ],
          [
           "```\n\nAt first glance the linear layer class `flax.linen.Dense` looks very similar to PyTorch's `torc..."
          ],
          [
           "```\n\n\nNow we can define our model class as follows.\n\n```python\nclass FlaxMLPModel(FlaxMLPPreTrainedM..."
          ],
          [
           "```\n\nNote that, as JAX is backed by the [XLA](https://www.tensorflow.org/xla) compiler any JAX/Flax ..."
          ],
          [
           "#### Sabrina J. Mielke, PhD student at The Johns Hopkins University & Part-time research intern at H..."
          ],
          [
           "#### Siddhartha Kamalakara, Joanna Yoo, João G M Araújo, MLE at Cohere\n- Talk: Training large scale ..."
          ],
          [
           "```\n\nNext we can clone the repo:\n\n```bash\n$ git clone https://huggingface.co/flax-community/roberta-..."
          ],
          [
           "```\n\n3. Let's also make sure the correct project is set in case your email is used for multiple gclo..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Text Summarization with Pretrained Encoders\n\nThis folder contains part of the code necessary to repr..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The Intel Team Authors and HuggingFace Inc. team. All rights reserved.\n\nLicensed u..."
          ],
          [
           "def decode(container, sampling_rate, num_frames, clip_idx, num_clips, target_fps):\n    '''\n    Decod..."
          ],
          [
           "```\n\nTips:\n\n- This implementation of TVP uses [`BertTokenizer`] to generate text embeddings and Resn..."
          ],
          [
           "# Adversarial evaluation of model performances\n\nHere is an example on evaluating a model using adver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Expected speedups\n\nYou can benefit from considerable speedups for inference, especially for..."
          ],
          [
           "```\n\nYou can return the original Transformers model with the [`~PreTrainedModel.reverse_bettertransf..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nWe'll get back to the meaning of those `\"▁\"` when we look at [SentencePiece](#sentencepiece). A..."
          ],
          [
           "```\n[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"],\n```\n\n`\"hugs\"` could be tokenized both as..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThis model was contributed by [nielsr](https://github.com/nielsrogge). This model's TensorFlow ..."
          ],
          [
           "Distil*\n\nAuthor: @VictorSanh\n\nThis folder contains the original code used to train Distil* as well a..."
          ],
          [
           "## Setup\n\nThis part of the library has only be tested with Python3.6+. There are few specific depend..."
          ],
          [
           "```\n\nSimilarly, using the other Distil* models simply consists in calling the base classes with a di..."
          ],
          [
           "How to propose a Flax/JAX + Transformers project \n\nGreat that you've opened this document! \nWhile we..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nTo apply the preprocessing function over the entire dataset, use 🤗 Datasets [`~datasets.Dataset..."
          ],
          [
           "```\n\n<Tip>\n\nThe transcription is decent, but it could be better! Try finetuning your model on more e..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n8. Once you are satisfied, go to the webpage of your fork on GitHub. Click on “Pull request”. M..."
          ],
          [
           "### 5. Add model tests\n\nHurray, you've implemented a TensorFlow model! Now it's time to add tests to..."
          ],
          [
           "```\n\nThe most likely outcome is that you'll see a bunch of errors. Don't worry, this is expected! De..."
          ],
          [
           "Image Captioning (vision-encoder-text-decoder model) training example\n\nThe following example showcas..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nHere we set:\n- `mask_ratio` to 0.75 (to mask 75% of the patches for each image)\n- `norm_pix_los..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "### PyTorch Examples\n\n#### Natural Language Processing[[pytorch-nlp]]\n\n| Notebook     |      Descrip..."
          ],
          [
           "#### Computer Vision[[pytorch-cv]]\n\n| Notebook                                                      ..."
          ],
          [
           "#### Audio[[pytorch-audio]]\n\n| Notebook     |      Description      |   |   |\n|:----------|:--------..."
          ],
          [
           "### TensorFlow Examples\n\n#### Natural Language Processing[[tensorflow-nlp]]\n\n| Notebook     |      D..."
          ],
          [
           "#### Biological Sequences[[tensorflow-bio]]\n\n| Notebook     |      Description      |   |   |\n|:----..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Simple VQGAN CLIP\n\nAuthor: @ErwannMillon \n\nThis is a very simple VQGAN-CLIP implementation that was ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "🤗 ట్రాన్స్‌ఫార్మర్‌లకు మూడు అత్యంత ప్రజాదరణ పొందిన డీప్ లెర్నింగ్ లైబ్రరీలు ఉన్నాయి — [Jax](https://..."
          ],
          [
           "```\n\nరెండవ లైన్ కోడ్ డౌన్‌లోడ్ మరియు పైప్‌లైన్ ఉపయోగించే ప్రీట్రైన్డ్ మోడల్‌ను కాష్ చేస్తుంది, మూడవద..."
          ],
          [
           "```\n\nFlax, PyTorch లేదా TensorFlow యొక్క ఇన్‌స్టాలేషన్ పేజీలను కొండాతో ఎలా ఇన్‌స్టాల్ చేయాలో చూడటాని..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (fr..."
          ],
          [
           "1. **[LeViT](https://huggingface.co/docs/transformers/model_doc/levit)** (from Meta AI) released wit..."
          ],
          [
           "1. **[MEGA](https://huggingface.co/docs/transformers/model_doc/mega)** (from Meta/USC/CMU/SJTU) rele..."
          ],
          [
           "1. **[OneFormer](https://huggingface.co/docs/transformers/model_doc/oneformer)** (from SHI Labs) rel..."
          ],
          [
           "1. **[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)** (from Facebook), releas..."
          ],
          [
           "1. **[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)** (fr..."
          ],
          [
           "1. **[ViTMSN](https://huggingface.co/docs/transformers/model_doc/vit_msn)** (from Meta AI) released ..."
          ],
          [
           "ప్రతి మోడల్ ఫ్లాక్స్, పైటార్చ్ లేదా టెన్సర్‌ఫ్లోలో అమలు చేయబడిందా లేదా 🤗 Tokenizers లైబ్రరీ ద్వారా అ..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "**[Write With Transformer](https://transformer.huggingface.co)**，由 Hugging Face 團隊所打造，是一個文本生成的官方 dem..."
          ],
          [
           "```\n\n第二行程式碼下載並快取 pipeline 使用的預訓練模型，而第三行程式碼則在給定的文本上進行了評估。這裡的答案“正面” (positive) 具有 99.97% 的信賴度。\n\n許多的 NL..."
          ],
          [
           "```\n\n要藉由 conda 安裝 Flax、PyTorch 或 TensorFlow 其中之一，請參閱它們各自安裝頁面的說明。\n\n## 模型架構\n\n**🤗 Transformers 支援的[所有的模..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and..."
          ],
          [
           "1. **[BridgeTower](https://huggingface.co/docs/transformers/model_doc/bridgetower)** (from Harbin In..."
          ],
          [
           "1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) ..."
          ],
          [
           "1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with ..."
          ],
          [
           "1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (fr..."
          ],
          [
           "1. **[LED](https://huggingface.co/docs/transformers/model_doc/led)** (from AllenAI) released with th..."
          ],
          [
           "1. **[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from Facebook) released..."
          ],
          [
           "1. **[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta) released with the..."
          ],
          [
           "1. **[PVT](https://huggingface.co/docs/transformers/model_doc/pvt)** (from Nanjing University, The U..."
          ],
          [
           "1. **[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)** (from Berkeley)..."
          ],
          [
           "1. **[UPerNet](https://huggingface.co/docs/transformers/model_doc/upernet)** (from Peking University..."
          ],
          [
           "1. **[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook) released togeth..."
          ],
          [
           "要檢查某個模型是否已有 Flax、PyTorch 或 TensorFlow 的實作，或其是否在🤗 Tokenizers 函式庫中有對應的 tokenizer，敬請參閱[此表](https://hugg..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Wav2Vec2 Contrastive Loss PreTraining examples\n\nThe following example showcases how to pretrain a wa..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nLet's initialize the `Trainer` with the training arguments we defined. We will also initialize ..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nOn 4 V100 GPUs, this script should run in *ca.* 3h 31min and yield a CTC loss of **0.35** and w..."
          ],
          [
           "#### Common Voice CTC\n\n- [Common Voice](https://huggingface.co/datasets/common_voice)\n\n| Dataset | D..."
          ],
          [
           "```\nhuggingface-cli login\n```\n\nNow, let's run an example and upload it to the Hub under `wav2vec2-co..."
          ],
          [
           "```\n\nNext, run the following script **inside** the just cloned repo:\n\n```python\nfrom transformers im..."
          ],
          [
           "```\n\nOn 8 V100 GPUs, this script should run in *ca.* 45 minutes and yield a cross-entropy loss of **..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "LXMERT DEMO\n\n1. make a virtualenv: ``virtualenv venv`` and activate ``source venv/bin/activate``\n2. ..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nTraining should converge at a loss and perplexity \nof 3.24 and 25.72 respectively after 20 epoc..."
          ],
          [
           "```\n\nGreat, we have set up our model repository. During training, we will automatically\npush the tra..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Robust Speech Challenge 🤗\n\nWelcome to the robust speech recognition challenge 🎙️ !\n\nThe goal of this..."
          ],
          [
           "```\n\nincludes more or less the same data as\n\n```python\nload_dataset(\"mozilla-foundation/common_voice..."
          ],
          [
           "```\n$ cd ~/\n$ git clone https://github.com/huggingface/datasets.git\n$ cd datasets\n$ pip install -e \"..."
          ],
          [
           "```\n\n4. **Start training**\n\nNow all that is left to do is to start training the model by executing t..."
          ],
          [
           "```\n\nThe training takes *ca.* 7 hours and yields a reasonable test word \nerror rate of 27% as can be..."
          ],
          [
           "```\n\nNext, we should adapt `eval.py` so that it fits our evaluation data. Here it is \nimportant to k..."
          ],
          [
           "```\n\nThe dataset `WER_REAL_AUDIO_TEST` is hidden and will only be published \nat the end of the robus..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "Testing mixed int8 quantization\n\n![HFxbitsandbytes.png](https://cdn-uploads.huggingface.co/productio..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Plug and Play Language Models: a Simple Approach to Controlled Text Generation\n\nAuthors: [Sumanth Da..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n    Args:\n        n_layers (`int`): The number of layers of the model.\n```\n\nIf the description i..."
          ],
          [
           "```\n\nIf you want to isolate a specific docstring, just add `::` after the file name then type the wh..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nHere's what this will look like without a generation prompt, using the ChatML template we saw i..."
          ],
          [
           "```\n\nNow, simply set the `tokenizer.chat_template` attribute. Next time you use [`~PreTrainedTokeniz..."
          ],
          [
           "```\n{% if loop.last and add_generation_prompt %}\n{{ bos_token + 'Assistant:\\n' }}\n{% endif %}\n```\n\n#..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "コンピュータビジョンにて:\n- [ViTによる画像分類](https://huggingface.co/google/vit-base-patch16-224)\n- [DETRによる物体検出](htt..."
          ],
          [
           "```\n\n2行目のコードでは、pipelineで使用される事前学習済みモデルをダウンロードしてキャッシュし、3行目では与えられたテキストに対してそのモデルを評価します。ここでは、答えは99.97%の信..."
          ],
          [
           "```\n\nFlax、PyTorch、TensorFlowをcondaでインストールする方法は、それぞれのインストールページに従ってください。\n\n> **_注意:_**  Windowsでは、キャッシュ..."
          ],
          [
           "1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (Google Research and the ..."
          ],
          [
           "1. **[BROS](https://huggingface.co/docs/transformers/model_doc/bros)** (NAVER CLOVA から) Teakgyu Hong..."
          ],
          [
           "1. **[Deformable DETR](https://huggingface.co/docs/transformers/model_doc/deformable_detr)** (SenseT..."
          ],
          [
           "1. **[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)** (from Technology Innovati..."
          ],
          [
           "1. **[Graphormer](https://huggingface.co/docs/transformers/model_doc/graphormer)** (Microsoft から) Ch..."
          ],
          [
           "1. **[LLaVa](https://huggingface.co/docs/transformers/model_doc/llava)** (Microsoft Research & Unive..."
          ],
          [
           "1. **[MMS](https://huggingface.co/docs/transformers/model_doc/mms)** (Facebook から) Vineel Pratap, An..."
          ],
          [
           "1. **[Pegasus](https://huggingface.co/docs/transformers/model_doc/pegasus)** (Google から) Jingqing Zh..."
          ],
          [
           "1. **[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)** (ZhuiyiTechnology から)..."
          ],
          [
           "1. **[Time Series Transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transf..."
          ],
          [
           "1. **[VITS](https://huggingface.co/docs/transformers/model_doc/vits)** (Kakao Enterprise から) Jaehyeo..."
          ],
          [
           "各モデルがFlax、PyTorch、TensorFlowで実装されているか、🤗Tokenizersライブラリに支えられた関連トークナイザを持っているかは、[この表](https://huggingfa..."
          ],
          [
           "```..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nBark can generate highly realistic, **multilingual** speech as well as other audio - including ..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nSimilar to the model, the configuration inherits basic serialization and deserialization functi..."
          ],
          [
           "```\n\n3. Set up a development environment, for instance by running the following command:\n\n```bash\npy..."
          ],
          [
           "```\n\nNext, regarding the debugging strategy, there are generally a few from which to choose from:\n\n-..."
          ],
          [
           "```\n\nIn the special case that you are adding a model whose architecture exactly matches the model ar..."
          ],
          [
           "```\n\nThe `_is_hf_initialized` flag is internally used to make sure we only initialize a submodule on..."
          ],
          [
           "```\n\n**7. Implement the forward pass**\n\nHaving managed to correctly load the pretrained weights into..."
          ],
          [
           "```\n\nYou might have to take a deeper look again into the original repository to find the correct tok..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "Self-training\n\nThis is an implementation of the self-training algorithm (without task augmentation) ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNote that if  `device_map=\"auto\"` is passed, there is no need to add the argument `device=devic..."
          ],
          [
           "```\n\n<Tip>\n\nTo run the example above you need to have [`pytesseract`](https://pypi.org/project/pytes..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Security Policy\n\n## Reporting a Vulnerability\n\n🤗 We have our bug bounty program set up with HackerOn..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n3. Create a new branch to hold your development changes:\n\n   ```bash\n   git checkout -b a-descr..."
          ],
          [
           "```\n\nSimilarly, for the `examples` directory, specify a *path to a subfolder or test file* to run th..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nBelow you can find the list of the models we benchmarked.\n\n**Image Classification** \n- [google/..."
          ],
          [
           "### T4 (batch size: 1)\n\n| **Task/Model** | **torch 2.0 - <br>no compile** | **torch 2.0 - <br>compil..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nOr you can replace the text-to-text generation snippet with the model dedicated to the T2TT tas..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nHere is the actual output of the second sequence:\n\n```py\n>>> input_ids = torch.tensor([[7592]])..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "Patience-based Early Exit\n\nPatience-based Early Exit (PABEE) is a plug-and-play inference method for..."
          ],
          [
           "Long Form Question Answering\n\nAuthor: @yjernite\n\nThis folder contains the code for the Long Form Que..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThere are several important fields here:\n\n- `answers`: the starting location of the answer toke..."
          ],
          [
           "```\n\nConfigure the model for training with [`compile`](https://keras.io/api/models/model_training_ap..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nWe can now keep the same model in memory and simply switch out the language adapters by\ncalling..."
          ],
          [
           "```\n\nNext, we load the model and processor\n\n```py\nfrom transformers import Wav2Vec2ForSequenceClassi..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace and Baidu Team. All rights reserved.\n\nLicensed under the Apache Li..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Sequence to Sequence Training and Evaluation\n\nThis directory contains examples for finetuning and ..."
          ],
          [
           "```\nThis should take < 6h/epoch on a 16GB v100 and achieve test BLEU above 26\nTo get results in line..."
          ],
          [
           "```\nor for `pegasus-xsum`\n```bash\npython make_student.py google/pegasus-xsum --save_path dpx_xsum_16..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Checkpoints\n\nThe [`Trainer`] class saves your model checkpoints to the directory specified ..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"multi-node\">\n\nAdd the `log_on_each_node 0` parameter for multi-node e..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "p align=\"center\"> <img src=\"http://sayef.tech:8082/uploads/FSNER-LOGO-2.png\" alt=\"FSNER LOGO\"> </p>\n..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contains specific syntax for our doc-builder (similar t..."
          ],
          [
           "| Notebook     |      Description      |      Author      |      |\n|:----------|:-------------|:----..."
          ],
          [
           "|[Fine-tune T5 for Summarization](https://github.com/abhimishra91/transformers-tutorials/blob/master..."
          ],
          [
           "|[Evaluate TAPAS on Table Fact Checking (TabFact)](https://github.com/NielsRogge/Transformers-Tutori..."
          ],
          [
           "| [Evaluate LUKE on TACRED, a relation extraction dataset](https://github.com/studio-ousia/luke/blob..."
          ],
          [
           "<!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ve..."
          ],
          [
           "|                                  Model                                   | PyTorch support | Tenso..."
          ],
          [
           "|                          [DETR](model_doc/detr)                          |       ✅        |       ..."
          ],
          [
           "|                         [LLaVa](model_doc/llava)                         |       ✅        |       ..."
          ],
          [
           "|                        [PLBart](model_doc/plbart)                        |       ✅        |       ..."
          ],
          [
           "|        [Vision Encoder decoder](model_doc/vision-encoder-decoder)        |       ✅        |       ..."
          ],
          [
           "<!-- End table-->..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Exporting a model for an unsupported architecture\n\nIf you wish to contribute by adding supp..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<div class=\"flex justify-center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/document..."
          ],
          [
           "An object detection head is added on top of DETR to find the class label and the coordinates of the ..."
          ],
          [
           "3. The input embeddings are passed through multiple encoder layers to output some final hidden state..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "DETR can be naturally extended to perform panoptic segmentation (which unifies semantic segmentation..."
          ],
          [
           "```\n\nOption 2: Instantiate DETR with randomly initialized weights for Transformer, but pre-trained w..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIn both cases, notice how we inherit from `PreTrainedModel` and call the superclass initializat..."
          ],
          [
           "```\n\nIt is also strongly encouraged to pass a commit hash as a `revision` to make sure the author of..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nSplit the dataset into a train and test set with the [`~datasets.Dataset.train_test_split`] met..."
          ],
          [
           "```\n\nThere are two fields that you'll want to use:\n\n- `text`: the text of the bill which'll be the i..."
          ],
          [
           "```\n\nSpecify where to push your model and tokenizer in the [`~transformers.PushToHubCallback`]:\n\n```..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\n\nLicensed under ..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nYou can then use your usual launchers to run in it in a distributed environment, but the easies..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "ere is how to convert a GPT2 model generated outside of `transformers`\n\n* [Megatron-LM](https://gith..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Documentation resources\n\n- [Text classification task guide](../tasks/sequence_classification..."
          ],
          [
           "# MM-IMDb\n\nBased on the script [`run_mmimdb.py`](https://github.com/huggingface/transformers/blob/ma..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nCall [`~evaluate.compute`] on `metric` to calculate the accuracy of your predictions. Before pa..."
          ],
          [
           "```\n\nNext, manually postprocess `tokenized_dataset` to prepare it for training.\n\n1. Remove the `text..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\nA list of official Hugging Face and community (indicated by 🌎) resources to help ..."
          ],
          [
           "Intro\n\nAuthors: @patrickvonplaten and @lhoestq\n\nAimed at tackling the knowledge-intensive NLP tasks ..."
          ],
          [
           "```\n\n2. Parse the unziped file using the `parse_dpr_relevance_data.py`\n    ```bash\n    mkdir output ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nto the normal command line arguments, or pass `debug=\"underflow_overflow\"` when creating the\n[`..."
          ],
          [
           "```\n\nSince the automatic detector only reports on inputs and outputs of full frames, once you know w..."
          ],
          [
           "# Information Gain Filtration(IGF)\n\nAuthors @Tuko @mraunak\n\nThis folder contains the code how to imp..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIf you're interested in pre-training T5 on a new corpus, check out the [run_t5_mlm_flax.py](htt..."
          ],
          [
           "```\n\nBecause T5 has been trained with the span-mask denoising objective,\nit can be used to predict t..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nwill return the tuple `(generation_output.sequences, generation_output.scores)` for instance.\n\n..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n     <img src=\"https://huggingface.co/datasets/huggingface/do..."
          ],
          [
           "```\n\nOnce examples are encoded, however, they will look like this:\n\n```py\n>>> encoding = tokenizer(e..."
          ],
          [
           "```\n\nDefine a simple data collator to batch examples together.\n\n```py\n>>> from transformers import D..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<PipelineTag pipeline=\"question-answering\"/>\n\n- [`AlbertForQuestionAnswering`] is supported by this ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nAs you saw in the example `tokens` field above, it looks like the input has already been tokeni..."
          ],
          [
           "```\n\n<frameworkcontent>\n<pt>\n<Tip>\n\nIf you aren't familiar with finetuning a model with the [`Traine..."
          ],
          [
           "```\n\nPass your inputs to the model and return the `logits`:\n\n```py\n>>> from transformers import Auto..."
          ],
          [
           "## Saved Pseudo-Labels\nThese are the generations of various large models on various large **training..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "urrently the following model proposals are available:\n\n- <s>[BigBird (Google)](./ADD_BIG_BIRD.md)</s..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Note that MiT in the above table refers to the Mix Transformer encoder backbone introduced in SegFor..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\n- [A demo notebook on how to fine-tune [`LukeForEntityPairClassification`] for re..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNext, create functions to apply appropriate transformations to a batch of images, instead of on..."
          ],
          [
           "```\n\nConfigure the model for training with `compile()`:\n\n```py\n>>> from tensorflow.keras.losses impo..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\nA list of official Hugging Face and community (indicated by 🌎) resources to help ..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nwill return the tuple `(outputs.loss, outputs.logits)` for instance.\n\nWhen considering our `out..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## DebertaForMaskedLM\n\n[[autodoc]] DebertaForMaskedLM\n    - forward\n\n## DebertaForSequenceClassifica..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "VisualBERT Demo\n\nThis demo shows usage of VisualBERT VQA model and is adapted from LXMERT demo prese..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\n\nLicense..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Testing new Hugging Face Deep Learning Container.\n\nThis document explains the testing strategy for r..."
          ],
          [
           "```\n2. In the PR comment describe what test we ran and with which framework versions. Here you can c..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<Tip>\n\nCheck out the [Padding and truncation](./pad_truncation) concept guide to learn more dif..."
          ],
          [
           "```\n\nApply the `preprocess_function` to the first few examples in the dataset:\n\n```py\n>>> processed_..."
          ],
          [
           "```\n\n## Multimodal\n\nFor tasks involving multimodal inputs, you'll need a [processor](main_classes/pr..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nAs a result, the output contains a classification label from the list we have provided in the i..."
          ],
          [
           "```\n\nCorrect! Let's increase the complexity a little and see if we can still get away with a basic p..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nOn a Tesla T4 GPU, you can expect the outputs like so:\n\n```bash\nExecution time -- 30819.6 ms\n\nE..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "```\nexamples/pytorch/token-classification/run_ner.py \\\n--max_train_samples 50 \\\n--max_eval_samples 5..."
          ],
          [
           "```\n\nThen log in the command line:\n\n```bash\nwandb login\n```\n\nIf you are in Jupyter or Colab, you sho..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "[[autodoc]] LayoutLMv3TokenizerFast\n    - __call__\n\n## LayoutLMv3Processor\n\n[[autodoc]] LayoutLMv3Pr..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe implementation is framework agnostic, and will work for PyTorch and TensorFlow models. If w..."
          ],
          [
           "Training a masked language model end-to-end from scratch on TPUs\n\nIn this example, we're going to de..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Inference\n\nTake a sample image from `test_ds` to test the model.\n\n\n```python\nfrom PIL import..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team and Microsoft. All rights reserved.\n\nLicensed under the MIT L..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\nWhat will be the name of the config class for this model?\n```\n\nThen, you will be asked for a che..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nHere, `width` and `height` correspond to the width and height of the original document in which..."
          ],
          [
           "```\n\n**Use case 3: token classification (training), apply_ocr=False**\n\nFor token classification task..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Resources\n\n- [Text classification task guide](../tasks/sequence_classification)\n- [Token cla..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\n\nLicense..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<PipelineTag pipeline=\"fill-mask\"/>\n\n- [`DistilBertForMaskedLM`] is supported by this [example scrip..."
          ],
          [
           "```\n\nMake also sure that you have a hardware that is compatible with Flash-Attention 2. Read more ab..."
          ],
          [
           "!---\nCopyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "```\n```python\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretr..."
          ],
          [
           "```\n\n```python\nflush()\n```\n\nLet's see what peak GPU memory consumption 4-bit quantization gives. Qua..."
          ],
          [
           "```\n\nOverall, we saw that running OctoCoder in 8-bit precision reduced the required GPU VRAM from 32..."
          ],
          [
           "The Starcoder models are a series of 15.5B parameter models trained on 80+ programming languages fro..."
          ],
          [
           "```\nFor demonstration purposes, we duplicate the system prompt by ten so that the input length is lo..."
          ],
          [
           "```\n\nFor more information on how to use Flash Attention, please have a look at [this doc page](https..."
          ],
          [
           "> Both RoPE and ALiBi are relative positional embeddings that are *not* learned during training, but..."
          ],
          [
           "```\n\n**Output**:\n```\nshape of input_ids torch.Size([1, 21])\nshape of input_ids torch.Size([1, 22])\ns..."
          ],
          [
           "```\n\n**Output**:\n```\n is a modified version of the function that returns Mega bytes instead.\n\ndef by..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "*NOTE**: This example is outdated and is not longer actively maintained. Please \nfollow the new inst..."
          ],
          [
           "```\n    \"zero_optimization\": {\n        ...\n        \"find_unused_parameters\": true,\n        ...\n    }..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "ow to add BigBird to 🤗 Transformers?\n=====================================\n\nMentor: [Patrick](https:..."
          ],
          [
           "```\n\nSimilar to the model, the configuration inherits basic serialization and\ndeserialization functi..."
          ],
          [
           "If any of the mentioned aspects above are **not** clear to you, now is a great time to talk to Patri..."
          ],
          [
           "```\n\n3.  Set up a development environment, for instance by running the\n    following command:\n\n    `..."
          ],
          [
           "```\n\nNext, regarding the debugging strategy, there are generally a few from\nwhich to choose from:\n\n-..."
          ],
          [
           "```\n\nWe expect that every model added to 🤗 Transformers passes a couple of\nintegration tests, meanin..."
          ],
          [
           "```\n    git checkout -b add_big_bird\n```\n\n2.  Commit the automatically generated code:\n\n```\n    git ..."
          ],
          [
           "```\n\nNow we can create an instance of this model definition which will fill\nall weights: `dense`, `i..."
          ],
          [
           "```\n\nIt is very likely that the 🤗 Transformers implementation and the\noriginal model implementation ..."
          ],
          [
           "```\n\nYou might have to take a deeper look again into the original repository\nto find the correct tok..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Examples\nIn this folder we showcase some examples to use code models for downstream tasks.\n\n## Compl..."
          ],
          [
           "!--Copyright 2021 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nwill create a model that is an instance of [`BertModel`].\n\nThere is one class of `AutoModel` fo..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Token classification\n\nBased on the scripts [`run_ner.py`](https://github.com/huggingface/transform..."
          ],
          [
           "```\n\n### Emerging and Rare Entities task: WNUT’17 (English NER) dataset\n\nDescription of the WNUT’17 ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen create a function that passes your predictions and labels to [`~evaluate.EvaluationModule...."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nYou can also store several generation configurations in a single directory, making use of the `..."
          ],
          [
           "```\n\n### Beam-search multinomial sampling\n\nAs the name implies, this decoding strategy combines beam..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThere are no good (general) solutions for this problem, and your mileage may vary depending on ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<PipelineTag pipeline=\"fill-mask\"/>\n\n- [`BertForMaskedLM`] is supported by this [example script](htt..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Loading a model\n\nNow you can load the previously saved `BertModel`, `traced_bert.pt`, from ..."
          ]
         ],
         "hovertemplate": "source=transformers<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "transformers, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "transformers, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          2.7428825,
          -3.359914,
          0.2722824,
          -2.6674454,
          3.8949254,
          -1.8539138,
          -1.1747677,
          -1.7604616,
          -1.2388836,
          -1.2785147,
          2.9919376,
          3.6197395,
          -2.648037,
          -2.8048122,
          -4.47787,
          4.6253166,
          0.9334681,
          -3.2287238,
          -3.3409312,
          0.011616348,
          -3.1657996,
          -2.401198,
          10.321739,
          0.08935249,
          0.77209103,
          -0.54512984,
          1.6770526,
          1.6109829,
          0.5788012,
          1.5264267,
          -3.7982807,
          3.5939202,
          1.0233619,
          -4.4852953,
          -4.9098325,
          -1.8532194,
          0.071866415,
          -1.4682068,
          0.52439183,
          1.2042251,
          1.2544897,
          4.225499,
          3.8617594,
          0.2139861,
          2.3588164,
          2.107832,
          0.31105277,
          2.848961,
          -2.738609,
          -0.4157387,
          -2.6457982,
          -1.4618555,
          -1.1148181,
          0.531304,
          -1.3621538,
          -0.43411484,
          -3.6707458,
          -3.0095084,
          2.017903,
          2.0916278,
          1.0265944,
          -2.931921,
          1.4752172,
          -3.7607155,
          -4.379432,
          0.9474229,
          3.5218365,
          -0.49483684,
          -2.19416,
          3.882366,
          2.296957,
          -3.5099022,
          0.43029737,
          10.322307,
          1.4248371,
          1.6561517,
          1.8430277,
          -2.7696357,
          -3.0656397,
          -3.0036504,
          -1.6545515,
          1.043525,
          -1.7207286,
          -2.8112473,
          2.8538184,
          -2.256051,
          1.4530548,
          2.4953127,
          2.191835,
          -1.7825891,
          -1.3005046,
          -4.1312613,
          1.1515988,
          -3.5139089,
          0.7315121,
          -1.2727127,
          -3.3233037,
          1.3805335,
          -1.4797363,
          -1.117483,
          -4.067721,
          -2.1361718,
          1.0421122,
          1.1201411,
          -3.1866999,
          0.5603435,
          -4.094031,
          -3.3475447,
          2.628006,
          3.2382023,
          4.4303484,
          -1.2588071,
          1.0403277,
          1.8148261,
          -2.3824403,
          -1.6993392,
          3.4422028,
          -1.0668312,
          1.8398271,
          -1.1590992,
          0.010898665,
          2.1729252,
          2.569935,
          -0.28852755,
          3.5799003,
          1.6811174,
          -2.5250823,
          4.5263066,
          2.8721256,
          3.132759,
          -2.1198964,
          -0.9321085,
          0.42593834,
          0.08898747,
          3.559399,
          -0.97127855,
          1.1930187,
          -3.9671576,
          1.4740678,
          -4.132302,
          4.7339225,
          -3.5423224,
          -4.5559826,
          -1.3117018,
          -1.6235412,
          10.321872,
          2.0011954,
          0.5589936,
          2.6646035,
          -2.7221344,
          -3.5426197,
          -0.52563727,
          1.235523,
          -1.9429699,
          0.32750875,
          -1.3461293,
          2.4858406,
          3.1725845,
          -3.0568185,
          4.0760117,
          3.4732282,
          -2.8608723,
          -2.8795278,
          -2.4137092,
          1.7698274,
          -2.9245245,
          0.5020404,
          -1.7949911,
          1.6765407,
          -1.7934933,
          -0.20921595,
          3.0905511,
          10.322455,
          0.51752627,
          -2.4539235,
          1.1492065,
          -3.6710386,
          4.4752965,
          -0.83808595,
          4.7813287,
          -2.2388055,
          -0.5124802,
          4.2967806,
          -1.104897,
          3.9490602,
          -2.6957722,
          3.537581,
          4.9676647,
          -3.5138288,
          4.2429266,
          4.093692,
          -1.9518957,
          -4.7535243,
          -1.2126195,
          -0.49498764,
          -2.1933153,
          -1.6491624,
          0.003048061,
          -1.1016599,
          3.4788089,
          1.0407215,
          1.2470467,
          -3.2310796,
          4.439246,
          -1.6468233,
          -0.9844327,
          3.900895,
          3.2980783,
          2.809564,
          -2.6461787,
          -2.043103,
          0.7201172,
          -1.1750845,
          1.1170273,
          2.5101364,
          -3.976005,
          -1.5766306,
          3.372662,
          -2.2729428,
          -0.90039927,
          2.9916892,
          3.4825037,
          4.434461,
          -1.1266342,
          -0.7981264,
          3.5851116,
          -4.005342,
          -4.0624804,
          -2.0057893,
          -3.2728121,
          -0.2874923,
          0.74240035,
          1.9455963,
          -1.2760724,
          2.9317174,
          -2.7090824,
          2.7632558,
          -1.9347949,
          -2.7468164,
          4.9539027,
          4.7280555,
          4.2777343,
          -1.6708102,
          5.076107,
          -1.8006339,
          -1.5799583,
          -1.1545771,
          1.5248623,
          1.4295053,
          2.0871294,
          2.3950083,
          2.409877,
          -1.7380719,
          -1.2649863,
          0.8742574,
          -3.5586402,
          -1.9119151,
          0.64383596,
          -3.390981,
          -2.2562428,
          4.442756,
          -2.697174,
          -1.559876,
          -2.3519251,
          4.939753,
          -2.6122284,
          0.9359643,
          -4.576429,
          -4.1557536,
          -0.11038504,
          1.9914716,
          4.17893,
          3.661524,
          -3.020245,
          -3.2884753,
          -3.205742,
          3.2707946,
          1.399356,
          0.370617,
          -0.95214903,
          1.652677,
          -1.6876868,
          -3.7794626,
          2.4206867,
          10.322017,
          2.610037,
          -1.580493,
          -1.1724123,
          1.6865072,
          1.8802898,
          4.497969,
          -3.0487714,
          1.6606952,
          3.6404784,
          1.4458196,
          2.51481,
          -1.8740568,
          1.1877909,
          -2.7555068,
          1.5521988,
          -1.1017337,
          -2.1966302,
          -2.0903068,
          4.0234246,
          -2.0531447,
          -2.446846,
          -3.529151,
          1.9174564,
          -4.2824697,
          1.299832,
          -1.9060345,
          0.3674882,
          -1.1912583,
          -4.7040815,
          0.8092134,
          0.84592414,
          -1.55071,
          -1.3364397,
          -3.499895,
          3.8738143,
          -2.4455411,
          -3.4240487,
          -3.3748684,
          1.1932323,
          -0.795027,
          -1.1860878,
          10.321845,
          2.131512,
          3.2570283,
          -2.9014275,
          -2.0376663,
          3.3560674,
          -3.5196698,
          0.78637594,
          -1.2685474,
          4.506309,
          -0.7110546,
          2.4004874,
          2.2793362,
          -3.173329,
          -2.8446455,
          -2.384348,
          4.4011188,
          -4.4554453,
          0.13843161,
          4.8584304,
          -1.611921,
          -0.666059,
          -2.8818128,
          0.3070097,
          3.0860543,
          1.7197233,
          0.72308207,
          5.191712,
          1.4970084,
          0.102408595,
          -3.5718045,
          -2.014816,
          -4.2035623,
          -1.3144654,
          -1.96881,
          -3.8711772,
          0.3044965,
          -2.0711477,
          -2.841559,
          3.7812917,
          0.98308265,
          -2.565873,
          -1.942535,
          0.1702184,
          -1.1598085,
          1.1727811,
          2.4879801,
          1.0526127,
          -4.1572328,
          -3.410802,
          4.1406016,
          1.4126332,
          -1.5939418,
          -1.404295,
          -2.9179,
          0.09837585,
          4.2953672,
          -1.008732,
          -2.12012,
          -2.7786968,
          -0.7630194,
          3.1309538,
          1.073946,
          -1.3509732,
          0.71686333,
          -3.1116543,
          3.8228548,
          2.0963218,
          3.4192042,
          1.4390496,
          4.982609,
          3.2933824,
          3.7850757,
          -2.799927,
          -3.297056,
          -1.5551261,
          -1.8979878,
          1.1622074,
          2.1232176,
          -1.1147785,
          -1.7390106,
          -4.3616695,
          -3.1615963,
          10.323092,
          3.124183,
          0.8928178,
          1.625227,
          -2.3024108,
          1.3770467,
          2.6943147,
          2.93832,
          2.891739,
          -1.9587493,
          2.6524794,
          -3.552062,
          3.0629618,
          4.6004014,
          3.3662617,
          1.9009969,
          -4.6349535,
          -1.5579376,
          -3.9723282,
          -1.8840488,
          -0.8605629,
          -0.5396805,
          -0.64656854,
          1.4923568,
          -2.7679706,
          4.730935,
          0.644226,
          -0.6303482,
          0.48232675,
          -2.728562,
          -0.5344188,
          -1.7494078,
          -3.772024,
          -4.4336576,
          -3.4327648,
          2.7992883,
          -3.6705265,
          4.1217375,
          2.3195467,
          -0.1958683,
          0.42372432,
          3.1600325,
          -2.8263326,
          -2.0518055,
          -0.2812652,
          -4.508392,
          -0.98482555,
          -3.83362,
          3.2917974,
          -1.0876683,
          -2.643396,
          -0.8003126,
          0.6784093,
          2.589335,
          0.9981532,
          3.1856532,
          0.1831844,
          2.6750703,
          0.62072074,
          -2.927641,
          1.9900289,
          1.5336636,
          0.20133495,
          -2.85423,
          3.2719767,
          -2.8576171,
          -2.2361906,
          -1.6100295,
          -1.6217998,
          1.660235,
          -0.024608904,
          -0.3630968,
          1.5572325,
          3.8486252,
          -2.2475579,
          -1.6113541,
          -2.35203,
          3.332278,
          -0.8324951,
          1.2171165,
          3.4616559,
          3.6693861,
          1.0234884,
          -2.8460422,
          2.9273012,
          -4.518383,
          -0.09327893,
          -2.991047,
          1.5039783,
          0.9540878,
          -1.2092067,
          3.4329698,
          -3.6276302,
          -1.9192324,
          -1.4480186,
          -1.735167,
          -3.4522064,
          4.107524,
          -3.1513524,
          -0.73359466,
          3.6297307,
          0.63841176,
          -4.2244697,
          0.86262137,
          0.08283382,
          0.7641585,
          -0.2084015,
          -0.53199625,
          -3.246578,
          -2.9693449,
          -1.4974225,
          -2.671624,
          -0.5362772,
          0.39169016,
          -0.29187825,
          1.4422525,
          -4.451729,
          -2.5468493,
          -0.9711264,
          3.7736182,
          3.507617,
          -3.907763,
          5.2393713,
          3.8022366,
          -1.7964871,
          4.1310763,
          -2.0594451,
          0.20280872,
          0.5859135,
          1.887153,
          3.8239233,
          -2.5513792,
          2.5123985,
          0.15379822,
          1.3389778,
          2.2541237,
          3.3513317,
          2.6330383,
          3.5017111,
          1.804681,
          0.7941886,
          -4.5461965,
          0.19727923,
          -1.1854075,
          -4.119349,
          3.4114535,
          0.33564347,
          -4.345163,
          -4.759228,
          -2.0123005,
          0.39316967,
          4.8507333,
          4.1884317,
          -2.224558,
          4.516713,
          2.8315916,
          2.5983071,
          -3.2570045,
          -3.5051253,
          -3.4342756,
          -2.4648015,
          3.773265,
          0.34664357,
          0.36098364,
          3.8816974,
          3.7753875,
          -2.6715074,
          -2.9782755,
          -2.399361,
          3.9120443,
          -3.8464258,
          -0.53829056,
          3.4405754,
          -1.8013709,
          -3.8700593,
          -3.6510952,
          10.320402,
          2.911683,
          -2.8982732,
          -4.026211,
          -0.00013195783,
          1.0315486,
          1.4911479,
          -1.2851862,
          3.688165,
          1.0515425,
          -2.9768338,
          3.1442487,
          3.8875127,
          -2.346236,
          -1.2106036,
          -1.107354,
          4.0105996,
          -0.52920586,
          -3.2923105,
          -0.42028847,
          10.32213,
          1.9303429,
          -3.0881915,
          -1.815586,
          0.90359104,
          3.622076,
          -1.9844702,
          3.7553642,
          -4.8889437,
          -4.8142757,
          -3.1363533,
          -2.4426105,
          -4.3841405,
          -3.3272536,
          -2.0356524,
          -1.4579364,
          2.7217171,
          1.0398734,
          0.8971639,
          -3.3169465,
          3.9960942,
          3.0883737,
          -4.4471583,
          0.87836367,
          -0.19731225,
          4.4602776,
          2.4389017,
          4.883626,
          -2.708409,
          -0.028461324,
          3.4927473,
          -2.2010643,
          0.6465066,
          -1.1157473,
          -3.95411,
          -4.0828342,
          2.27332,
          -3.1796677,
          1.8834236,
          -1.401284,
          -0.5593059,
          1.0868788,
          1.3136556,
          -2.853438,
          -3.8311234,
          4.8839016,
          0.4176092,
          -0.8880921,
          -3.647804,
          2.8821652,
          2.784045,
          4.592174,
          2.7348459,
          3.385173,
          -1.339776,
          -1.15334,
          -2.342302,
          -2.8573527,
          -3.539573,
          2.1739545,
          2.5517712,
          -1.7400497,
          -4.44956,
          -0.68202704,
          5.2570167,
          3.778466,
          -1.8953112,
          -3.4906166,
          -1.1441232,
          10.322031,
          4.9216194,
          -1.0633305,
          2.3522153,
          2.0630536,
          2.511318,
          4.224932,
          1.589237,
          -3.5105863,
          2.3462746,
          2.0796506,
          3.0229907,
          -1.9992925,
          -3.921523,
          2.364924,
          4.0326214,
          1.601761,
          1.0922128,
          -0.54678184,
          -2.1058388,
          1.870488,
          -2.6716573,
          4.371428,
          -0.5396452,
          -2.5825403,
          -2.8016956,
          0.8804444,
          -2.1868725,
          3.196225,
          2.6126885,
          -1.9805219,
          -2.5016105,
          4.1055846,
          -0.25925115,
          2.8055112,
          -3.0700002,
          1.3093915,
          -2.3813868,
          -0.4829308,
          -3.3878324,
          4.7739997,
          0.14436388,
          -2.644221,
          -2.343781,
          -2.8953092,
          0.7515018,
          3.1149855,
          -3.3671672,
          -0.28118303,
          -0.50813454,
          1.0724634,
          0.3539691,
          2.060072,
          2.2523928,
          -0.6188953,
          1.197378,
          0.7965388,
          3.9430296,
          3.0525644,
          5.0893874,
          2.5195417,
          0.90008754,
          -0.9302472,
          3.7367013,
          3.4260073,
          0.5909491,
          -3.3993657,
          -0.44208148,
          -2.93945,
          2.9148767,
          -4.5156317,
          -0.5574293,
          4.346534,
          -2.7677364,
          -0.9494902,
          -1.517454,
          1.8398777,
          3.5814095,
          -4.2331276,
          -2.4236205,
          -4.2789993,
          -4.5908823,
          4.7823133,
          -2.462851,
          -4.129066,
          0.17457958,
          -2.7281694,
          -2.2210112,
          0.42045888,
          -0.48303038,
          -1.638715,
          -1.4247473,
          0.70040077,
          -1.3479717,
          -0.32232732,
          -1.2252864,
          3.0588412,
          -4.242181,
          2.7174747,
          2.1972263,
          3.1864073,
          -2.7106984,
          1.5932006,
          -1.6067216,
          3.8932848,
          3.3392265,
          -2.7866256,
          1.3480752,
          4.31694,
          1.5680805,
          -3.573662,
          0.120715104,
          -3.3423965,
          -0.54917634,
          -3.2226875,
          -2.1419353,
          -1.863473,
          -2.3934274,
          -4.2788105,
          2.159797,
          -2.6524727,
          -1.0170674,
          1.2567601,
          0.08892329,
          -1.8373973,
          -4.2844644,
          -3.7178614,
          -3.841046,
          2.716248,
          1.0293878,
          -3.5013492,
          -2.5509562,
          -2.5488822,
          1.8639644,
          -1.8995023,
          -0.3406971,
          -1.9687337,
          -2.6356165,
          1.4633555,
          -3.776414,
          1.7252727,
          -0.9278474,
          -0.32785857,
          -4.147763,
          0.270986,
          2.7647738,
          -1.631295,
          4.3106675,
          -2.6572316,
          -1.6729957,
          -3.0591753,
          -1.1218225,
          -0.03935805,
          -1.2761298,
          -1.1821094,
          0.56629276,
          -1.7665218,
          3.1901407,
          1.27325,
          4.886614,
          2.5955818,
          0.9511683,
          -2.8121827,
          -3.1242487,
          0.122577265,
          -2.0932605,
          -1.9294192,
          3.1223934,
          -3.2432842,
          4.1752715,
          -3.1346874,
          -2.9807723,
          -4.721882,
          -2.0606437,
          -3.0907445,
          -1.0289451,
          -1.3631791,
          1.8159353,
          -1.968892,
          3.5099597,
          -0.10482445,
          2.186512,
          3.6532307,
          0.5993535,
          1.3709502,
          -2.5390348,
          2.48744,
          -2.2977884,
          -0.35053733,
          2.651386,
          0.45054072,
          0.34944564,
          3.4850612,
          -2.4177144,
          0.6520748,
          2.3091788,
          3.4545527,
          0.3003375,
          -2.4880521,
          1.1521482,
          -4.0312247,
          -1.4194759,
          -4.022114,
          -1.7393909,
          3.7311676,
          4.262698,
          -0.014951054,
          -0.13654992,
          -1.7807549,
          -0.5979695,
          -0.34777382,
          2.716444,
          0.55305904,
          -1.9294837,
          -1.7382253,
          -4.064936,
          -1.387039,
          4.312448,
          3.1016073,
          3.9273942,
          -0.03978548,
          1.9712086,
          4.926157,
          3.0200543,
          0.7059443,
          3.3058362,
          2.5483046,
          0.15089074,
          -1.8430121,
          -2.5575178,
          3.2006865,
          -1.962893,
          2.9894118,
          -0.47942856,
          0.9010925,
          0.7454613,
          -1.8784038,
          1.6784524,
          -2.8056047,
          2.2906475,
          -3.576438,
          -0.9840747,
          0.86199385,
          3.302462,
          0.8395892,
          -2.0112348,
          1.690657,
          -2.2300544,
          4.1677756,
          2.8625848,
          -0.50612676,
          0.31408554,
          3.9914274,
          3.351072,
          1.3413706,
          -2.0522676,
          0.84894335,
          -0.47098595,
          -1.259562,
          4.4887476,
          1.9363928,
          -2.3331382,
          -1.2119532,
          -1.6636192,
          -1.1088017,
          0.8760057,
          0.7629576,
          3.7862308,
          2.6204832,
          -2.0607078,
          1.6545892,
          2.6917584,
          2.1200116,
          -2.8077726,
          5.2141633,
          -1.7177418,
          -3.5336208,
          2.2218354,
          0.52322495,
          -3.6348069,
          0.2955283,
          -4.3204365,
          -0.30907857,
          0.23742029,
          2.4409022,
          2.861961,
          -2.164373,
          3.754359,
          -2.5386617,
          -1.5818509,
          -3.3795416,
          -2.1422904,
          0.76372933,
          -1.4159851,
          2.3022373
         ],
         "xaxis": "x",
         "y": [
          1.6696092,
          -0.88800526,
          3.770983,
          -0.015928328,
          -0.4465225,
          -3.8258624,
          -5.7318277,
          -4.641332,
          -3.3107047,
          -4.880058,
          3.5769799,
          3.5673203,
          4.4984565,
          3.438963,
          2.02443,
          2.1456501,
          2.9196012,
          4.127016,
          1.9033624,
          4.616488,
          1.9210333,
          -5.264879,
          19.58332,
          -2.3240073,
          -1.0616599,
          4.877115,
          1.9251647,
          -0.21794985,
          0.6999913,
          4.1017013,
          -3.4429255,
          0.47482103,
          -3.1899962,
          3.4246914,
          1.6339501,
          4.52443,
          1.9965652,
          -1.8322066,
          -3.0378876,
          1.3600265,
          2.5432875,
          0.25213996,
          2.015021,
          3.5792136,
          -1.3503548,
          1.5670274,
          2.1560645,
          2.275697,
          3.4311643,
          3.4147623,
          -2.6983466,
          -5.7499638,
          -3.6185422,
          -2.3966248,
          -1.3426886,
          1.9569309,
          -0.7168968,
          -0.5838051,
          0.76405776,
          -4.652413,
          -3.6143901,
          4.1061115,
          3.1999457,
          2.2115335,
          2.7679605,
          2.8687615,
          -0.36799663,
          3.917525,
          -0.64959973,
          2.0682354,
          3.0778818,
          1.4392141,
          -2.325558,
          19.584583,
          -1.5992749,
          -2.0767887,
          1.3629673,
          -0.613206,
          -1.1400256,
          -1.7353754,
          -5.7166457,
          2.2206583,
          -1.6562474,
          -3.7819676,
          3.895541,
          -3.5868392,
          2.2436745,
          -0.15490986,
          2.1136405,
          -6.033872,
          -5.237689,
          1.671531,
          2.0992439,
          -3.7608938,
          -2.7216442,
          4.5200195,
          -2.5000205,
          0.5162356,
          -4.8147135,
          -4.688357,
          0.30936083,
          -1.8948507,
          -0.9108003,
          -1.215658,
          2.5317426,
          1.8662239,
          1.98863,
          -2.3841226,
          -1.7626086,
          1.8324943,
          -0.9093228,
          0.57283926,
          -2.5419075,
          -2.4432402,
          -2.6546445,
          -4.734172,
          0.99224395,
          3.2432985,
          -4.1880393,
          -4.7968793,
          -5.1030083,
          -2.6909027,
          -3.5203147,
          3.2746067,
          1.3064616,
          -1.1803532,
          -0.62946165,
          -0.7350986,
          -0.23117676,
          2.3207846,
          -6.083136,
          -3.91728,
          2.5162091,
          2.4886355,
          2.690434,
          3.694507,
          -1.8380111,
          1.0254263,
          3.4415355,
          2.2208495,
          0.7185598,
          4.2426715,
          1.228557,
          -5.140352,
          -5.7184196,
          19.582045,
          2.049109,
          -2.4956253,
          1.9424405,
          1.5309132,
          3.2387543,
          1.3776509,
          -2.4919894,
          -1.5417114,
          -3.4432702,
          -1.1488005,
          -1.3832461,
          -1.9202902,
          -3.781225,
          2.8883595,
          3.5724964,
          4.6317782,
          3.5084462,
          4.457809,
          2.997213,
          2.6041234,
          4.8588395,
          0.0015343834,
          3.242481,
          4.6261163,
          2.6238418,
          2.1469092,
          19.58537,
          -4.8037763,
          1.6827112,
          2.6599588,
          -1.1520803,
          0.45455086,
          -1.4064265,
          1.1618679,
          -1.2964724,
          -5.290602,
          -1.0650594,
          3.279454,
          -1.6612674,
          2.2086465,
          0.9796448,
          0.41563892,
          0.4521293,
          -1.0725496,
          0.5823425,
          -0.15240698,
          2.0103757,
          -3.6556113,
          1.478389,
          -3.1212227,
          -5.210616,
          1.6797166,
          -4.1746016,
          -0.6917006,
          2.5825043,
          -1.899897,
          -0.11877416,
          0.992981,
          3.4090865,
          -5.1318707,
          -1.1034526,
          0.1654255,
          0.6774166,
          2.8523288,
          -0.72078365,
          -0.7100305,
          -3.5292742,
          -1.859168,
          -1.0192678,
          2.5358627,
          1.7331166,
          1.1803982,
          1.8561038,
          -5.4607425,
          1.9586905,
          -1.3377962,
          -0.1465079,
          -2.9312031,
          -0.41457322,
          -1.0786395,
          -1.8233899,
          2.7274036,
          -4.5305796,
          -4.7218995,
          -5.2533317,
          -0.66636854,
          -2.401743,
          -0.6719484,
          1.3410738,
          4.3216486,
          1.2172759,
          -1.422455,
          -3.168464,
          -0.6484672,
          1.3671826,
          0.22500607,
          -4.2700505,
          0.9642625,
          -3.445562,
          -4.046587,
          -1.433093,
          -2.3475966,
          -3.7232237,
          1.6244932,
          -4.235794,
          3.3736322,
          -4.2194643,
          -3.4265924,
          1.0480055,
          0.067625485,
          -6.155981,
          -3.2201877,
          -0.5109218,
          3.0530174,
          0.01747566,
          -3.985353,
          -1.6725603,
          -2.2974749,
          1.2954744,
          -2.10885,
          -0.97661376,
          2.6428437,
          -1.7458673,
          4.8110695,
          -4.3366756,
          0.8956192,
          3.747046,
          4.475439,
          3.6242208,
          3.8545685,
          2.739817,
          1.823849,
          4.3995075,
          -0.7265988,
          2.8686163,
          4.536147,
          3.5684307,
          -3.058584,
          19.583092,
          -1.3168727,
          -2.3385398,
          2.8782482,
          -0.049569197,
          0.41361716,
          -0.6277561,
          -2.5326161,
          -1.7088534,
          0.82835007,
          0.8112797,
          2.983447,
          -1.1368058,
          3.8429673,
          -3.4636786,
          -1.0911134,
          2.4535582,
          -2.348362,
          -1.9445769,
          0.61744934,
          -5.804693,
          -0.23192029,
          2.608924,
          -1.0468404,
          1.6825051,
          -4.7385545,
          -3.610965,
          -3.6816075,
          -5.1254544,
          2.002526,
          -5.568552,
          -5.3559136,
          -4.6898546,
          2.3035302,
          -4.1088324,
          0.8294589,
          -2.456068,
          3.990322,
          -0.03222303,
          -5.0272307,
          -4.893204,
          -4.932396,
          19.583406,
          -2.3668504,
          -1.6357149,
          -1.0695599,
          3.5773776,
          -0.78163666,
          -2.642379,
          4.428079,
          4.6231527,
          -0.6281023,
          -2.492038,
          -2.4819205,
          0.34476334,
          0.9893286,
          -3.2844172,
          -2.3491356,
          2.0401385,
          1.8964942,
          -1.7037487,
          -0.16115984,
          -1.9380344,
          0.4398949,
          -0.022011317,
          -1.947625,
          -0.07071355,
          -1.3689231,
          -0.022419754,
          1.2062867,
          -3.1288319,
          1.7312021,
          -0.30170894,
          -1.2941122,
          3.3458583,
          -5.0510683,
          -4.6153116,
          -1.5827074,
          -3.992005,
          -4.7423306,
          1.2041961,
          0.028118245,
          -1.5991925,
          0.80220175,
          -2.8389997,
          -2.5454068,
          -2.054878,
          0.33934543,
          0.23941344,
          3.4672723,
          -2.6232948,
          -2.321435,
          -0.33006012,
          -0.10058347,
          -4.1647034,
          1.9938698,
          0.9219095,
          -4.2905064,
          1.9137335,
          -0.22630493,
          0.24248612,
          1.3667337,
          -1.3009477,
          2.0653646,
          0.40584183,
          3.6715448,
          4.239685,
          0.17305453,
          1.905621,
          -4.346952,
          2.0417454,
          -2.9986777,
          0.43630794,
          3.1267421,
          3.4766114,
          4.63367,
          2.9820325,
          4.366778,
          1.192651,
          2.677096,
          -2.4723487,
          4.204773,
          3.8983166,
          3.2016997,
          2.8776774,
          19.585415,
          0.4857495,
          2.5354824,
          3.5539904,
          -1.368377,
          -4.038017,
          -0.89891857,
          2.8071365,
          1.0864496,
          -1.6060785,
          -2.9459498,
          2.1616359,
          0.4516052,
          1.940135,
          -0.834629,
          1.979287,
          -1.7016284,
          -3.8846948,
          -0.85703933,
          -2.0691712,
          -4.319661,
          -5.9451175,
          -0.22156157,
          -1.790992,
          -5.435769,
          -0.48524734,
          3.1016526,
          3.927384,
          1.2980306,
          -3.7454982,
          1.9554313,
          -4.9277763,
          2.5652637,
          2.1784863,
          -2.5425193,
          -1.9228511,
          -2.6361642,
          -2.0481894,
          -3.1625187,
          0.16670416,
          -1.6592678,
          -1.0603287,
          -0.08548387,
          2.7225976,
          -3.5597672,
          2.0538204,
          0.5579652,
          -0.8079922,
          -0.63940907,
          1.2025555,
          -2.237541,
          -4.729927,
          -3.4743128,
          1.112005,
          -0.13689913,
          0.087727405,
          2.378491,
          -3.6147091,
          -2.150069,
          -1.2662979,
          -1.9955015,
          -2.4385192,
          -1.8695561,
          -1.4136225,
          1.6150341,
          -0.4667055,
          -2.9721277,
          -0.6433874,
          -3.7704542,
          -2.9697053,
          3.6116233,
          3.0198739,
          2.6670446,
          1.7145674,
          -1.8515435,
          -6.2622952,
          -3.726993,
          -1.1165798,
          -3.5757174,
          -3.519576,
          -1.2191591,
          -2.0499098,
          0.42444387,
          3.2096057,
          2.7799904,
          1.2236552,
          3.8318756,
          2.0141962,
          -1.9391313,
          1.0600382,
          3.7387285,
          1.083189,
          0.72050077,
          -0.42592824,
          1.6821544,
          0.96992993,
          3.9975462,
          -0.34377846,
          -3.1591198,
          0.24886742,
          0.27629063,
          -3.2299318,
          1.1477334,
          3.507779,
          4.242674,
          -1.8066664,
          2.6179419,
          -0.33536446,
          0.14392291,
          -1.170371,
          0.19815314,
          2.5116942,
          -2.9417098,
          -4.708938,
          -1.0038095,
          3.4999263,
          0.63666046,
          -0.79633814,
          0.37158728,
          1.6388643,
          2.754894,
          -1.9432482,
          0.3271745,
          2.2560902,
          -3.7083242,
          -1.5865657,
          0.39710188,
          -2.6092694,
          -2.24451,
          -1.37487,
          0.040632684,
          -1.5087419,
          -2.914172,
          -2.642501,
          2.628886,
          1.4301901,
          -1.3825049,
          3.7083702,
          -1.5977092,
          -4.1795,
          3.2681656,
          2.5298457,
          -5.351695,
          -2.3005683,
          2.6677186,
          0.044342604,
          -2.9847174,
          3.4335682,
          1.4144976,
          4.574249,
          2.4462228,
          0.11015701,
          -1.3792979,
          -0.48634925,
          2.2233958,
          -1.0087416,
          0.99634534,
          -1.3078905,
          3.9557054,
          0.5828171,
          -1.4275763,
          0.5999657,
          -4.9990997,
          -4.6091547,
          2.6393285,
          3.372291,
          4.396188,
          3.7751405,
          0.010310122,
          2.7376614,
          2.9116604,
          4.357125,
          2.7511413,
          3.9227273,
          3.562754,
          -2.392066,
          19.579138,
          2.882268,
          -1.843394,
          3.0152357,
          -5.257199,
          -4.58077,
          -3.6990495,
          4.2776804,
          3.654411,
          2.8712378,
          2.9102488,
          2.2937999,
          2.4756045,
          1.9293152,
          4.467765,
          -0.9426702,
          1.9638183,
          4.576345,
          3.7390172,
          -3.414466,
          19.584007,
          1.1496894,
          -2.5290718,
          3.1934671,
          -0.85779965,
          1.0607233,
          -1.2527506,
          -0.86683697,
          0.57372314,
          2.3969975,
          -2.9982443,
          3.800054,
          3.4601603,
          -2.7108266,
          -3.3034663,
          4.815619,
          -1.6428915,
          -5.4301534,
          1.5573941,
          -2.5675645,
          2.7283576,
          0.506334,
          0.19250715,
          2.3574305,
          -1.6921234,
          1.5722222,
          -1.1326834,
          1.7255747,
          4.277913,
          2.5647163,
          -1.4464345,
          -1.5078087,
          -2.481525,
          2.6955614,
          -0.87043834,
          -0.8884839,
          1.6881167,
          -2.861374,
          2.8544564,
          -1.6949985,
          0.25368848,
          -3.5311394,
          3.8885078,
          2.3185773,
          -0.037587944,
          -0.7827878,
          -3.9374213,
          3.5913532,
          -2.2656553,
          2.2992911,
          -2.9437613,
          -0.683023,
          -2.3580549,
          0.37165648,
          -5.308192,
          -5.3493,
          -5.3742313,
          4.2961144,
          3.6869278,
          0.6008695,
          3.1828985,
          0.07097354,
          2.7782338,
          4.42385,
          0.78654224,
          1.5319006,
          4.1176724,
          3.1533813,
          -5.278814,
          19.583504,
          1.2153888,
          1.3650854,
          1.165876,
          1.9255571,
          -2.2760386,
          2.227574,
          0.7007442,
          1.5129956,
          3.4192505,
          -2.024795,
          2.3044844,
          0.5615733,
          1.1987655,
          3.9910336,
          -0.518985,
          -1.2940341,
          0.75316954,
          -0.44806677,
          0.13799182,
          -2.773677,
          -5.2201653,
          -0.49282703,
          -0.3652267,
          2.9539926,
          0.15817104,
          -2.0024462,
          0.24767451,
          2.205313,
          1.280346,
          -1.6303855,
          -3.3818839,
          0.8713777,
          -1.3803991,
          3.5230217,
          -2.7998626,
          3.0586138,
          -3.5337272,
          0.44115946,
          0.0759134,
          2.2415602,
          -0.53119594,
          -1.2152113,
          -4.0750427,
          -3.2063103,
          -5.813684,
          3.0316517,
          -2.7873752,
          2.2336423,
          -3.410363,
          1.4622715,
          -2.1745641,
          2.9033809,
          -3.4060178,
          -4.032913,
          4.1314654,
          -2.4076712,
          -1.5271882,
          -3.5767908,
          0.19045651,
          2.603121,
          -2.5868812,
          -4.0028276,
          2.0622485,
          -0.53420997,
          -2.8348782,
          0.037150223,
          2.346996,
          -3.7707403,
          -2.3393178,
          1.6015624,
          -4.712607,
          -0.24328658,
          2.2324553,
          -2.051112,
          2.6333487,
          0.016602911,
          0.4092018,
          3.424113,
          3.993433,
          3.3524714,
          3.9228177,
          0.07764621,
          4.485556,
          3.6154752,
          2.228427,
          4.311898,
          4.69728,
          4.5903273,
          -2.1987498,
          -2.3659039,
          -1.1265907,
          0.25326753,
          -0.57403135,
          -2.397621,
          -3.0264883,
          -2.8200796,
          1.847754,
          -1.6599082,
          1.132914,
          -1.592284,
          -0.8978384,
          0.62377816,
          -0.97663873,
          0.49716562,
          -1.4361281,
          -2.5114489,
          -2.3741949,
          -0.9190743,
          0.29832312,
          -2.763478,
          -1.2582729,
          -1.5792556,
          -4.6873817,
          -2.5235665,
          -6.054132,
          -4.261169,
          -1.2480944,
          0.67698747,
          -1.1778971,
          -3.304582,
          -1.103573,
          -2.627749,
          -3.7307355,
          -0.16813788,
          1.8993417,
          -2.1809113,
          -1.9477593,
          3.4458418,
          1.6870823,
          0.40682665,
          -3.3322532,
          -1.4295803,
          -2.2626169,
          -1.0431503,
          -2.6642208,
          -2.6252933,
          -1.3889453,
          -5.035844,
          -1.3366374,
          -2.9521968,
          3.1139154,
          0.72339517,
          -0.7953877,
          4.681848,
          1.950442,
          -5.9701037,
          -0.7301267,
          2.4542408,
          0.6057505,
          -2.7571268,
          2.735402,
          -1.8175905,
          -1.710382,
          3.2271273,
          0.4808477,
          -4.01523,
          1.7335277,
          -3.400874,
          0.31174022,
          0.66914016,
          -2.1213613,
          -2.88003,
          -3.913476,
          -0.92994,
          -2.1550877,
          -5.0533466,
          -1.4687018,
          1.0046544,
          2.9814517,
          2.3344316,
          -5.0547204,
          0.8496112,
          -5.843293,
          -0.6133623,
          -1.0778763,
          -5.8754306,
          2.4499636,
          1.804748,
          -0.4459816,
          -1.6682956,
          -1.616495,
          -0.68432695,
          -3.98987,
          -1.3906435,
          -4.4361477,
          2.9572077,
          -1.9989655,
          -0.338268,
          2.6856568,
          2.870138,
          -0.9223132,
          -1.2065524,
          0.5208815,
          -3.2547019,
          -0.55092525,
          -0.16453648,
          1.8209946,
          2.980356,
          -3.3481681,
          2.4898582,
          4.4103594,
          1.7192214,
          -4.740496,
          -1.222924,
          1.5037813,
          3.6821268,
          3.5762107,
          -5.9711905,
          -2.115475,
          4.6818624,
          1.3736606,
          -2.150748,
          -3.5122073,
          -3.0305462,
          0.6177056,
          -5.1880913,
          2.4321282,
          1.6118003,
          1.2881548,
          0.87895244,
          2.7683852,
          -0.6027307,
          -1.5729032,
          -2.6092687,
          -0.6847981,
          -0.9189026,
          -2.819558,
          -4.7229238,
          -3.2504199,
          0.5656392,
          2.926571,
          1.3113216,
          1.9379278,
          -0.89067215,
          -3.7184672,
          -1.1793003,
          -2.8608112,
          -1.1675389,
          -1.3603382,
          3.0375779,
          -6.0408025,
          -2.1500957,
          2.4344828,
          -1.8977273,
          -4.133846,
          1.0741906,
          4.3152895,
          -1.6222107,
          1.0555384,
          -2.4929497,
          -3.3598726,
          -0.4923224,
          -0.0843197,
          0.9560721,
          -2.726088,
          -5.017641,
          3.77026,
          -1.1680039,
          -0.3134034,
          0.91542184,
          0.36896175,
          3.974896,
          0.18505202,
          2.2762218,
          -1.0850364,
          0.81738675,
          0.3882956,
          -1.741116,
          1.6834395,
          -1.6503965,
          -3.4867432,
          2.5974944,
          1.7943503,
          0.41622177,
          -0.927067,
          0.14817382,
          -1.0643812,
          3.4869678,
          -2.3233364,
          3.438721,
          1.0835774,
          1.263053,
          -4.0186734,
          -2.0907888,
          -0.78637326,
          1.3272969,
          1.2985107,
          -3.741529,
          2.0759718,
          -0.9173292,
          0.6633573,
          3.209875,
          -1.6131407,
          2.880695
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Git over SSH\n\nYou can access and write data in repositories on huggingface.co using SSH (Secure Shel..."
          ],
          [
           "Using Flair at Hugging Face\n\n[Flair](https://github.com/flairNLP/flair) is a very simple framework f..."
          ],
          [
           "Widget Examples\n\nNote that each widget example can also optionally describe the corresponding model ..."
          ],
          [
           "```\n\n### Visual Question Answering\n\n```yaml\nwidget:\n- text: \"What animal is it?\"\n  src: \"https://hug..."
          ],
          [
           "Configure the Dataset Viewer\n\nThe Dataset Viewer supports many [data files formats](./datasets-addin..."
          ],
          [
           "Adding a Sign-In with HF button to your Space\n\nYou can enable a built-in sign-in flow in your Space ..."
          ],
          [
           "User access tokens\n\n## What are User Access Tokens?\n\nUser Access Tokens are the preferred way to aut..."
          ],
          [
           "ZenML on Spaces\n\n[ZenML](https://github.com/zenml-io/zenml) is an extensible, open-source MLOps fram..."
          ],
          [
           "```\n\nYou can also use the Direct URL in your browser to use the ZenML dashboard as a\nfullscreen appl..."
          ],
          [
           "Using Spaces for Organization Cards\n\nOrganization cards are a way to describe your organization to o..."
          ],
          [
           "Repository Settings \n\n## Private repositories\n\nYou can choose a repository's visibility when you cre..."
          ],
          [
           "--\n# Example metadata to be added to a dataset card.  \n# Full dataset card template at https://githu..."
          ],
          [
           "Repository limitations and recommendations\n\nThere are some limitations to be aware of when dealing w..."
          ],
          [
           "Dask\n\n[Dask](https://github.com/dask/dask) is a parallel and distributed computing library that scal..."
          ],
          [
           "Access control in organizations\n\n<Tip>\n\nYou can set up [Single Sign-On (SSO)](./security-sso) to be ..."
          ],
          [
           "Billing\n\nAt Hugging Face, we build a collaboration platform for the ML community (i.e., the Hub), an..."
          ],
          [
           "Streamlit Spaces\n\n**Streamlit** gives users freedom to build a full-featured web app with Python in ..."
          ],
          [
           "Next Steps\n\nThese next sections highlight features and additional information that you may find usef..."
          ],
          [
           "Run with Docker\n\nYou can use Docker to run most Spaces locally.\nTo view instructions to download and..."
          ],
          [
           "Advanced Topics\n\n## Contents\n\n- [Using OpenCV in Spaces](./spaces-using-opencv)\n- [More ways to crea..."
          ],
          [
           "Using spaCy at Hugging Face\n\n`spaCy` is a popular library for advanced Natural Language Processing u..."
          ],
          [
           "Audit Logs\n\n<Tip warning={true}>\nThis feature is part of the <a href=\"https://huggingface.co/enterpr..."
          ],
          [
           "Spaces Overview\n\nHugging Face Spaces make it easy for you to create and deploy ML-powered demos in m..."
          ],
          [
           "* Owner: The duplicated Space can be under your account or any organization in which you have write ..."
          ],
          [
           "```\ntitle: My lovely space\nemoji: 🤗\ncolorFrom: blue\ncolorTo: green\nsdk: docker\npinned: false\nmodels:..."
          ],
          [
           "Search\n\nYou can now easily search anything on the Hub with **Full-text search**. We index model card..."
          ],
          [
           "[paddlenlp-banner](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub..."
          ],
          [
           "Reference\n\n## Deep Learning Container\n\nBelow you can find a version table of currently available Hug..."
          ],
          [
           "## Hugging Face Transformers Amazon SageMaker Examples\n\nExample Jupyter notebooks that demonstrate h..."
          ],
          [
           "```\n\n**`sentiment-analysis`**\n\n```json\n{\n  \"inputs\": \"Don't waste your time.  We had two different p..."
          ],
          [
           "Pandas\n\n[Pandas](https://github.com/pandas-dev/pandas) is a widely used Python data analysis toolkit..."
          ],
          [
           "Datasets without language challenge\n\nRelated to https://github.com/huggingface/hub-docs/issues/986.\n..."
          ],
          [
           "```\n\n## Datasets without language field filled in..."
          ],
          [
           "| status | pr_url                                                                                   ..."
          ],
          [
           "|        |                                                                                          ..."
          ],
          [
           "|        |                                                                                          ..."
          ],
          [
           "| Merged | [here](https://huggingface.co/datasets/kmkarakaya/turkishReviews-ds/discussions/1#651ae84..."
          ],
          [
           "|        | [here](https://huggingface.co/datasets/afkfatih/turkishdataset/discussions/1#651ae795fa4b..."
          ],
          [
           "| Merged | [here](https://huggingface.co/datasets/TigerResearch/tigerbot-wiki-qa-bart-en-10k/discuss..."
          ],
          [
           "| Merged | [here](https://huggingface.co/datasets/thesistranslation/distilled-ccmatrix-en-es/discuss..."
          ],
          [
           "|        | [here](https://huggingface.co/datasets/dipteshkanojia/llama-2-qe-2023-enmr-da-sys-test/di..."
          ],
          [
           "| Merged | [here](https://huggingface.co/datasets/kaleinaNyan/wmt19_ru-en/discussions/1#651ac6d09777..."
          ],
          [
           "|        | [here](https://huggingface.co/datasets/yezhengli9/wmt20-en-de/discussions/1#651ac4326e33b..."
          ],
          [
           "| Merged | [here](https://huggingface.co/datasets/BramVanroy/stackoverflow-chat-dutch-llamav2-format..."
          ],
          [
           "|        | [here](https://huggingface.co/datasets/philschmid/prompted-germanquad/discussions/1)     ..."
          ],
          [
           "|        | [here](https://huggingface.co/datasets/kaaniince/turkishReviews-project/discussions/1#651..."
          ],
          [
           "Advanced Topics\n\n## Contents\n\n- [Integrate your library with the Hub](./models-adding-libraries)\n- [..."
          ],
          [
           "Storage Regions on the Hub\n\nRegions let you decide where your org's models and datasets will be stor..."
          ],
          [
           "Managing Spaces with Github Actions\n\nYou can keep your app in sync with your GitHub repository with ..."
          ],
          [
           "Webhook guide: Setup an automatic metadata quality review for models and datasets \n\n<Tip>\n\nWebhooks ..."
          ],
          [
           "```\n\n\n## How to post the review automatically?\n\nWe now have a markdown formatted metadata review rep..."
          ],
          [
           "🟧 Label Studio on Spaces\n\n[Label Studio](https://labelstud.io) is an [open-source data labeling\nplat..."
          ],
          [
           "Webhooks\n\n<Tip>\n\nWebhooks are now publicly available!\n\n</Tip>\n\nWebhooks are a foundation for MLOps-r..."
          ],
          [
           "```\n\n### Comment\n\nThe top level property `comment` is specified when a comment is created (including..."
          ],
          [
           "Dataset viewer\n\nThe dataset page includes a table with the contents of the dataset, arranged by page..."
          ],
          [
           "The Model Hub\n\n## What is the Model Hub?\n\nThe Model Hub is where the members of the Hugging Face com..."
          ],
          [
           "Signing commits with GPG\n\n`git` has an authentication layer to control who can push commits to a rep..."
          ],
          [
           "Spaces Changelog\n\n## [2023-07-28] - Upstream Streamlit frontend for `>=1.23.0`\n\n- Streamlit SDK uses..."
          ],
          [
           "Licenses\n\nYou are able to add a license to any repo that you create on the Hugging Face Hub to let o..."
          ],
          [
           "Hugging Face Hub documentation\n\nThe Hugging Face Hub is a platform with over 350k models, 75k datase..."
          ],
          [
           "<div class=\"group flex flex-col space-y-2 rounded-xl border border-red-100 bg-gradient-to-br from-re..."
          ],
          [
           "<div class=\"group flex flex-col space-y-2 rounded-xl border border-green-100 bg-gradient-to-br from-..."
          ],
          [
           "We currently support two awesome Python SDKs (**[Gradio](https://gradio.app/)** and **[Streamlit](ht..."
          ],
          [
           "Using ESPnet at Hugging Face\n\n`espnet` is an end-to-end toolkit for speech processing, including aut..."
          ],
          [
           "Model Card components\n\n**Model Card Components** are special elements that you can inject directly i..."
          ],
          [
           "Annotated Model Card Template\n\n\n## Template\n\n[modelcard_template.md file](https://github.com/hugging..."
          ],
          [
           "## Testing Data, Factors & Metrics\n\n### Testing Data\n\n`testing_data`\n\n_Ideally this links to a Datas..."
          ],
          [
           "Organizations\n\nThe Hugging Face Hub offers **Organizations**, which can be used to group accounts an..."
          ],
          [
           "Using 🤗 Datasets\n\nOnce you've found an interesting dataset on the Hugging Face Hub, you can load the..."
          ],
          [
           "Appendix\n\n## Appendix A: User Study\n_Full text responses to key questions_\n\n### How would you define..."
          ],
          [
           "### MODEL CARDS FOR LARGE LANGUAGE MODELS\nLarge language models are often released with associated d..."
          ],
          [
           "Notifications\n\nNotifications allow you to know when new activities (Pull Requests or discussions) ha..."
          ],
          [
           "How to configure SAML SSO with Azure\n\nIn this guide, we will use Azure as the SSO provider and with ..."
          ],
          [
           "Gradio Spaces\n\n**Gradio** provides an easy and intuitive interface for running a model from a list o..."
          ],
          [
           "Cookie limitations in Spaces\n\nIn Hugging Face Spaces, applications have certain limitations when usi..."
          ],
          [
           "Argilla on Spaces\n\n**Argilla** is an open-source, data labelling tool, for highly efficient human-in..."
          ],
          [
           "For uploading Argilla datasets, there are two options:\n\n1. You can use the **argilla Python library*..."
          ],
          [
           "```\n\nThird, you need to read the dataset using the `datasets` library. For reading other file types,..."
          ],
          [
           "Using Stable-Baselines3 at Hugging Face\n\n`stable-baselines3` is a set of reliable implementations of..."
          ],
          [
           "File names and splits\n\nTo host and share your dataset, create a dataset repository on the Hugging Fa..."
          ],
          [
           "Integrate your library with the Hub\n\nThe Hugging Face Hub aims to facilitate sharing machine learnin..."
          ],
          [
           "```\n\nWhen you check your Hugging Face account, you should now see a `test-model` repository under yo..."
          ],
          [
           "Aim on Spaces\n\n**Aim** is an easy-to-use & supercharged open-source experiment tracker. Aim logs you..."
          ],
          [
           "# Model `license:other` challenge\n\nRelated to https://github.com/huggingface/hub-docs/issues/985.\n\n#..."
          ],
          [
           "```\n\n## How to contribute?\n\nHow to do it in practice? That's simple! We have listed models below tha..."
          ],
          [
           "|status|pr_url                                                                      |model_id|nb_dow..."
          ],
          [
           "|      |                                                                            |[aipicasso/pica..."
          ],
          [
           "|      |                                                                            |[TheBloke/Llama..."
          ],
          [
           "|      |                                                                            |[jondurbin/airo..."
          ],
          [
           "|      |                                                                            |[decapoda-resea..."
          ],
          [
           "|      |                                                                            |[aipicasso/cool..."
          ],
          [
           "|      |                                                                            |[TheBloke/airob..."
          ],
          [
           "|      |                                                                            |[TheBloke/Airob..."
          ],
          [
           "|      |                                                                            |[valurank/disti..."
          ],
          [
           "|      |                                                                            |[TheBloke/Kuchi..."
          ],
          [
           "|      |                                                                            |[TheBloke/llama..."
          ],
          [
           "|      |                                                                            |[TheBloke/Herme..."
          ],
          [
           "|      |                                                                            |[Mitsua/vroid-d..."
          ],
          [
           "|      |                                                                            |[TheBloke/Zaraf..."
          ],
          [
           "|      |                                                                            |[TheBloke/LLaMA..."
          ],
          [
           "|      |                                                                            |[TheBloke/CodeF..."
          ],
          [
           "|      |                                                                            |[TheBloke/OpenO..."
          ],
          [
           "|      |                                                                            |[gsaivinay/Llam..."
          ],
          [
           "|      |                                                                            |[TheBloke/Llama..."
          ],
          [
           "|      |                                                                            |[TheBloke/orca_..."
          ],
          [
           "|      |                                                                            |[Jsevisal/rober..."
          ],
          [
           "|      |                                                                            |[TheBloke/qCamm..."
          ],
          [
           "|      |                                                                            |[shekharchatter..."
          ],
          [
           "|      |                                                                            |[4bit/Redmond-P..."
          ],
          [
           "|      |                                                                            |[amdnsr/llama-7..."
          ],
          [
           "|      |                                                                            |[camelids/alpac..."
          ],
          [
           "|      |                                                                            |[camelids/llama..."
          ],
          [
           "|      |                                                                            |[decapoda-resea..."
          ],
          [
           "|      |                                                                            |[fragro/llama-7..."
          ],
          [
           "|      |                                                                            |[Jsevisal/balan..."
          ],
          [
           "|      |                                                                            |[Mithilss/llama..."
          ],
          [
           "|      |                                                                            |[prodm93/llama_..."
          ],
          [
           "|      |                                                                            |[TheBloke/airob..."
          ],
          [
           "|      |                                                                            |[TheBloke/LLaMA..."
          ],
          [
           "|      |                                                                            |[TheBloke/tulu-..."
          ],
          [
           "|      |                                                                            |[usamakenway/ll..."
          ],
          [
           "ChatUI on Spaces\n\n**Hugging Chat** is an open-source interface enabling everyone to try open-source ..."
          ],
          [
           "Model Cards\n\n<Tip>\n\n[New! Try our experimental Model Card Creator App](https://huggingface.co/spaces..."
          ],
          [
           "```\n\n### Specifying a task (`pipeline_tag`)\n\nYou can specify the `pipeline_tag` in the model card me..."
          ],
          [
           "Uploading datasets\n\nThe [Hub](https://huggingface.co/datasets) is home to an extensive collection of..."
          ],
          [
           "WebDataset\n\n[WebDataset](https://github.com/webdataset/webdataset) is a library to write I/O pipelin..."
          ],
          [
           "Pull requests and Discussions\n\nHub Pull requests and Discussions allow users to do community contrib..."
          ],
          [
           "```\n\n### Draft mode\n\nDraft mode is the default status when opening a new Pull request from scratch i..."
          ],
          [
           "Using fastai at Hugging Face\n\n`fastai` is an open-source Deep Learning library that leverages PyTorc..."
          ],
          [
           "Using SpeechBrain at Hugging Face\n\n`speechbrain` is an open-source and all-in-one conversational too..."
          ],
          [
           "Model Card Guidebook \n\nModel cards are an important documentation and transparency framework for mac..."
          ],
          [
           "Models Frequently Asked Questions\n\n## How can I see what dataset was used to train the model?\n\nIt's ..."
          ],
          [
           "Using OpenCLIP at Hugging Face\n\n[OpenCLIP](https://github.com/mlfoundations/open_clip) is an open-so..."
          ],
          [
           "Libraries\n\nThe Datasets Hub has support for several libraries in the Open Source ecosystem.\nThanks t..."
          ],
          [
           "Using Stanza at Hugging Face\n\n`stanza` is a collection of accurate and efficient tools for the lingu..."
          ],
          [
           "Panel on Spaces\n\n[Panel](https://panel.holoviz.org/) is an open-source Python library that lets you ..."
          ],
          [
           "User Studies\n## Model Card Audiences and Use Cases\n\nDuring our investigation into the landscape of m..."
          ],
          [
           "**Insights:** \n* When writing model cards, respondents generally said they would write a model card ..."
          ],
          [
           "Docker Spaces Examples\n\nWe gathered some example demos in the [Spaces Examples](https://huggingface...."
          ],
          [
           "Datasets\n\nThe Hugging Face Hub is home to a growing collection of datasets that span a variety of do..."
          ],
          [
           "Using GPU Spaces\n\nYou can upgrade your Space to use a GPU accelerator using the _Settings_ button in..."
          ],
          [
           "```\n\nAfter that, you can verify the installation by printing the output from the following code and ..."
          ],
          [
           "How to Add a Space to ArXiv\n\nDemos on Hugging Face Spaces allow a wide audience to try out state-of-..."
          ],
          [
           "Datasets Overview\n\n## Datasets on the Hub\n\nThe Hugging Face Hub hosts a [large number of community-c..."
          ],
          [
           "Using AllenNLP at Hugging Face\n\n`allennlp` is a NLP library for developing state-of-the-art models o..."
          ],
          [
           "Webhook guide: Setup an automatic system to re-train a model when a dataset changes\n\n<Tip>\n\nWebhooks..."
          ],
          [
           "Downloading models\n\n## Integrated libraries\n\nIf a model on the Hub is tied to a [supported library](..."
          ],
          [
           "Getting Started with Repositories\n\nThis beginner-friendly guide will help you get the basic skills y..."
          ],
          [
           "```\n\nAnd you're done! You can check your repository on Hugging Face with all the recently added file..."
          ],
          [
           "Embed your Space in another website\n\nOnce your Space is up and running you might wish to embed it in..."
          ],
          [
           "Tabby on Spaces\n\n[Tabby](https://tabby.tabbyml.com) is an open-source, self-hosted AI coding assista..."
          ],
          [
           "Data files Configuration\n\nThere are no constraints on how to structure dataset repositories.\n\nHoweve..."
          ],
          [
           "Single Sign-On (SSO)\n\n<Tip warning={true}>\nThis feature is part of the <a href=\"https://huggingface...."
          ],
          [
           "Models\n\nThe Hugging Face Hub hosts many models for a [variety of machine learning tasks](https://hug..."
          ],
          [
           "Using Asteroid at Hugging Face\n\n`asteroid` is a Pytorch toolkit for audio source separation. It enab..."
          ],
          [
           "Models Download Stats\n\n## How are download stats generated for models?\n\nCounting the number of downl..."
          ],
          [
           "Using RL-Baselines3-Zoo at Hugging Face\n\n`rl-baselines3-zoo` is a training framework for Reinforceme..."
          ],
          [
           "Using OpenCV in Spaces\n\nIn order to use OpenCV in your Gradio or Streamlit Spaces, you'll need to ma..."
          ],
          [
           "Uploading models\n\nTo upload models to the Hub, you'll need to create an account at [Hugging Face](ht..."
          ],
          [
           "Digital Object Identifier (DOI)\n\nThe Hugging Face Hub offers the possibility to generate DOI for you..."
          ],
          [
           "Secrets Scanning\n\nIt is important to manage [your secrets (env variables) properly](./spaces-overvie..."
          ],
          [
           "Downloading datasets\n\n## Integrated libraries\n\nIf a dataset on the Hub is tied to a [supported libra..."
          ],
          [
           "Handling Spaces Dependencies\n\n## Default dependencies\n\nThe default Spaces environment comes with sev..."
          ],
          [
           "Inference API\n\nPlease refer to [Inference API Documentation](https://huggingface.co/docs/api-inferen..."
          ],
          [
           "Enterprise Hub\n\nEnterprise Hub adds advanced capabilities to organizations, enabling safe, compliant..."
          ],
          [
           "How to configure SAML SSO with Okta\n\nIn this guide, we will use Okta as the SSO provider and with th..."
          ],
          [
           "Using 🧨 `diffusers` at Hugging Face\n\nDiffusers is the go-to library for state-of-the-art pretrained ..."
          ],
          [
           "Security\n\nThe Hugging Face Hub offers several security features to ensure that your code and data ar..."
          ],
          [
           "Using SpanMarker at Hugging Face\n\n[SpanMarker](https://github.com/tomaarsen/SpanMarkerNER) is a fram..."
          ],
          [
           "Disk usage on Spaces\n\nEvery Space comes with a small amount of disk storage. This disk space is ephe..."
          ],
          [
           "Hugging Face on Amazon SageMaker\n\n![cover](https://huggingface.co/datasets/huggingface/documentation..."
          ],
          [
           "### Sample notebooks\n\n- [All notebooks](https://github.com/huggingface/notebooks/tree/master/sagemak..."
          ],
          [
           "Hub API Endpoints\n\nWe have open endpoints that you can use to retrieve information from the Hub as w..."
          ],
          [
           "```\n\nThis is equivalent to `huggingface_hub.delete_repo()`.\n\n### PUT /api/repos/{repo_type}/{repo_id..."
          ],
          [
           "Displaying carbon emissions for your model\n\n## Why is it beneficial to calculate the carbon emission..."
          ],
          [
           "Train and deploy Hugging Face on Amazon SageMaker\n\nThe get started guide will show you how to quickl..."
          ],
          [
           "Dataset Cards\n\n## What are Dataset Cards?\n\nEach dataset may be documented by the `README.md` file in..."
          ],
          [
           "Using sample-factory at Hugging Face\n\n[`sample-factory`](https://github.com/alex-petrenko/sample-fac..."
          ],
          [
           "hub-docs\n\nThis repository regroups documentation and information that is hosted on the Hugging Face ..."
          ],
          [
           "Datasets Download Stats\n\n## How are download stats generated for datasets?\n\nThe Hub provides downloa..."
          ],
          [
           "Using TensorBoard\n\nTensorBoard provides tooling for tracking and visualizing metrics as well as visu..."
          ],
          [
           "Organizations, Security, and the Hub API\n\n## Contents\n\n- [Organizations](./organizations)\n  - [Manag..."
          ],
          [
           "Using timm at Hugging Face\n\n`timm`, also known as [pytorch-image-models](https://github.com/rwightma..."
          ],
          [
           "Image Dataset\n\nThis guide will show you how to configure your dataset repository with image files. Y..."
          ],
          [
           "Deploy models to Amazon SageMaker\n\nDeploying a 🤗 Transformers models in SageMaker for inference is a..."
          ],
          [
           "```\n\n### Create a model artifact for deployment\n\nFor later deployment, you can create a `model.tar.g..."
          ],
          [
           "```\n\n📓 Open the [sagemaker-notebook.ipynb notebook](https://github.com/huggingface/notebooks/blob/ma..."
          ],
          [
           "Single Sign-On (SSO)\n\nThe Hugging Face Hub gives you the ability to implement mandatory Single Sign-..."
          ],
          [
           "Spaces Configuration Reference\n\nSpaces are configured through the `YAML` block at the top of the **R..."
          ],
          [
           "Spaces Settings\n\nYou can configure your Space's appearance and other settings inside the `YAML` bloc..."
          ],
          [
           "Your First Docker Space: Text Generation with T5\n\nIn the following sections, you'll learn the basics..."
          ],
          [
           "```\n\n4. In the `script.js` file, make it handle the request\n\n```javascript\nconst textGenForm = docum..."
          ],
          [
           "Using Sentence Transformers at Hugging Face\n\n`sentence-transformers` is a library that provides easy..."
          ],
          [
           "How to configure OIDC SSO with Okta\n\nIn this guide, we will use Okta as the SSO provider and with th..."
          ],
          [
           "Repositories\n\nModels, Spaces, and Datasets are hosted on the Hugging Face Hub as [Git repositories](..."
          ],
          [
           "Malware Scanning\n\nWe run every file of your repositories through a [malware scanner](https://www.cla..."
          ],
          [
           "Managing Spaces with CircleCI Workflows\n\nYou can keep your app in sync with your GitHub repository w..."
          ],
          [
           "Docker Spaces\n\nSpaces accommodate custom [Docker containers](https://docs.docker.com/get-started/) f..."
          ],
          [
           "Webhook guide: build a Discussion bot based on BLOOM\n\n<Tip>\n\nWebhooks are now publicly available!\n\n<..."
          ],
          [
           "Sign in with Hugging Face\n\nYou can use the HF OAuth / OpenID connect flow to create a **\"Sign in wit..."
          ],
          [
           "Using `Transformers.js` at Hugging Face\n\nTransformers.js is a JavaScript library for running 🤗 Trans..."
          ],
          [
           "Using SetFit with Hugging Face\n\nSetFit is an efficient and prompt-free framework for few-shot fine-t..."
          ],
          [
           "Spaces\n\n[Hugging Face Spaces](https://huggingface.co/spaces) offer a simple way to host ML demo apps..."
          ],
          [
           "Using Adapter Transformers at Hugging Face\n\n`adapter-transformers` is a library that extends 🤗 `tran..."
          ],
          [
           "Using PEFT at Hugging Face\n\n🤗 [Parameter-Efficient Fine-Tuning (PEFT)](https://huggingface.co/docs/p..."
          ],
          [
           "Organization cards\n\nYou can create an organization card to help users learn more about what your org..."
          ],
          [
           "Libraries\n\nThe Hub has support for dozens of libraries in the Open Source ecosystem. Thanks to the `..."
          ],
          [
           "Gated models\n\nTo give more control over how models are used, the Hub allows model authors to enable ..."
          ],
          [
           "If you want to collect more user information, you can configure additional fields. This information ..."
          ],
          [
           "```\n\n\nIn some cases, you might also want to modify the text in the gate heading and the text in the ..."
          ],
          [
           "Gated datasets\n\nTo give more control over how datasets are used, the Hub allows datasets authors to ..."
          ],
          [
           "If you want to collect more user information, you can configure additional fields. This information ..."
          ],
          [
           "```\n\n\nIn some cases, you might also want to modify the text in the gate heading and the text in the ..."
          ],
          [
           "Custom Python Spaces\n\n<Tip>\n\nSpaces now support arbitrary Dockerfiles so you can host any Python app..."
          ],
          [
           "Paper Pages\n\nPaper pages allow people to find artifacts related to a paper such as models, datasets ..."
          ],
          [
           "DuckDB\n\n[DuckDB](https://github.com/duckdb/duckdb) is an in-process SQL [OLAP](https://en.wikipedia...."
          ],
          [
           "More ways to create Spaces\n\n## Duplicating a Space\n\nYou can duplicate a Space by clicking the three ..."
          ],
          [
           "Shiny on Spaces\n\n[Shiny](https://shiny.posit.co/) is an open-source framework for building simple, b..."
          ],
          [
           "Using ML-Agents at Hugging Face\n\n`ml-agents` is an open-source toolkit that enables games and simula..."
          ],
          [
           "--\n# Example metadata to be added to a model card.  \n# Full model card template at https://github.co..."
          ],
          [
           "Using 🤗 `transformers` at Hugging Face\n\n🤗 `transformers` is a library maintained by Hugging Face and..."
          ],
          [
           "THE LANDSCAPE OF ML DOCUMENTATION TOOLS\nThe development of the model cards framework in 2018 was ins..."
          ],
          [
           "| **Stage of ML System Lifecycle** \t|  **Tool**                                                     ..."
          ],
          [
           "| MODELS AND METHODS               \t| ***Value Cards*** [Shen et al. (2021)](https://dl.acm.org/doi/..."
          ],
          [
           "### DATA-FOCUSED DOCUMENTATION TOOLS\n\nSeveral proposed documentation tools focus on datasets used in..."
          ],
          [
           "Since the proposal for model cards by Mitchell et al. in 2018, model cards have been adopted and ada..."
          ],
          [
           "Using Keras at Hugging Face\n\n`keras` is an open-source machine learning library that uses a consiste..."
          ],
          [
           "Widgets\n\n## What's a widget?\n\nMany model repos have a widget that allows anyone to run inferences di..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n<img class=\"block dark:hidden\" width=\"450\" src=\"https://huggi..."
          ],
          [
           "No-license models challenge\n\n## Context\n\nThe Hugging Face Hub hosts hundreds of thousands of public ..."
          ],
          [
           "```\n\nThis challenge aims to improve the completeness of this metadata on the Hub, which will ultimat..."
          ],
          [
           "|status|pr_url|model_id                                                                             ..."
          ],
          [
           "|      |      |[meta-llama/Llama-2-70b-chat-hf](https://huggingface.co/meta-llama/Llama-2-70b-chat-h..."
          ],
          [
           "|      |      |[decapoda-research/llama-13b-hf](https://huggingface.co/decapoda-research/llama-13b-h..."
          ],
          [
           "|      |      |[THUDM/chatglm-6b-int4](https://huggingface.co/THUDM/chatglm-6b-int4)                ..."
          ],
          [
           "|      |      |[Voicelab/trurl-2-13b](https://huggingface.co/Voicelab/trurl-2-13b)                  ..."
          ],
          [
           "|      |      |[shibing624/chinese-llama-plus-13b-hf](https://huggingface.co/shibing624/chinese-llam..."
          ],
          [
           "|      |      |[uklfr/gottbert-base](https://huggingface.co/uklfr/gottbert-base)                    ..."
          ],
          [
           "|      |      |[TheBloke/orca_mini_v3_13B-GPTQ](https://huggingface.co/TheBloke/orca_mini_v3_13B-GPT..."
          ],
          [
           "|      |      |[4bit/Llama-2-13b-chat-hf](https://huggingface.co/4bit/Llama-2-13b-chat-hf)          ..."
          ],
          [
           "|      |      |[TheBloke/Airoboros-L2-70B-GPT4-m2.0-GPTQ](https://huggingface.co/TheBloke/Airoboros-..."
          ],
          [
           "|      |      |[TheBloke/llama2_7b_chat_uncensored-GGML](https://huggingface.co/TheBloke/llama2_7b_c..."
          ],
          [
           "|      |      |[localmodels/Llama-2-7B-Chat-GPTQ](https://huggingface.co/localmodels/Llama-2-7B-Chat..."
          ],
          [
           "|      |      |[TheBloke/LLaMA-13b-GPTQ](https://huggingface.co/TheBloke/LLaMA-13b-GPTQ)            ..."
          ],
          [
           "|      |      |[RicardoLee/Llama2-chat-13B-Chinese-50W](https://huggingface.co/RicardoLee/Llama2-cha..."
          ],
          [
           "|      |      |[FreedomIntelligence/AceGPT-7b-chat-GPTQ](https://huggingface.co/FreedomIntelligence/..."
          ],
          [
           "|      |      |[symanto/sn-mpnet-base-snli-mnli](https://huggingface.co/symanto/sn-mpnet-base-snli-m..."
          ],
          [
           "|      |      |[griffin/clinical-summary-fact-corrector](https://huggingface.co/griffin/clinical-sum..."
          ],
          [
           "|      |      |[TheBloke/Chronohermes-Grad-L2-13B-GPTQ](https://huggingface.co/TheBloke/Chronohermes..."
          ],
          [
           "|      |      |[CONCISE/LLaMa_V2-13B-Chat-Uncensored-GGML](https://huggingface.co/CONCISE/LLaMa_V2-1..."
          ],
          [
           "|      |      |[TheBloke/airoboros-l2-70B-GPT4-2.0-GGUF](https://huggingface.co/TheBloke/airoboros-l..."
          ],
          [
           "|      |      |[TheBloke/LLaMA-13b-AWQ](https://huggingface.co/TheBloke/LLaMA-13b-AWQ)              ..."
          ],
          [
           "Manual Configuration\n\nThis guide will show you how to configure a custom structure for your dataset ..."
          ],
          [
           "Static HTML Spaces\n\nSpaces also accommodate custom HTML for your app instead of using Streamlit or G..."
          ],
          [
           "Tasks\n\n## What's a task?\n\nTasks, or pipeline types, describe the \"shape\" of each model's API (inputs..."
          ],
          [
           "Collections\n\nUse Collections to group repositories from the Hub (Models, Datasets, Spaces and Papers..."
          ],
          [
           "Run training on Amazon SageMaker\n\n<iframe width=\"700\" height=\"394\" src=\"https://www.youtube.com/embe..."
          ],
          [
           "```\n\n_Note that SageMaker doesn’t support argparse actions. For example, if you want to use a boolea..."
          ],
          [
           "```\n\n📓 Open the [sagemaker-notebook.ipynb notebook](https://github.com/huggingface/notebooks/blob/ma..."
          ],
          [
           "Managing organizations\n\n## Creating an organization\n\nVisit the [New Organization](https://hf.co/orga..."
          ],
          [
           "Pickle Scanning\n\nPickle is a widely used serialization format in ML. Most notably, it is the default..."
          ],
          [
           "```\n\n### Use your own serialization format\n\n- [MsgPack](https://msgpack.org/index.html)\n- [Protobuf]..."
          ],
          [
           "Moderation\n\n<Tip>\n\nCheck out the [Code of Conduct](https://huggingface.co/code-of-conduct) and the [..."
          ],
          [
           "Livebook on Spaces\n\n**Livebook** is an open-source tool for writing interactive code notebooks in [E..."
          ]
         ],
         "hovertemplate": "source=hub-docs<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "hub-docs, circle",
         "marker": {
          "color": "#19d3f3",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hub-docs, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -1.7306653,
          2.7553647,
          -2.506422,
          -1.6412193,
          2.3111653,
          -3.994596,
          -4.5649824,
          -3.7175498,
          0.4722523,
          -1.8900152,
          -2.2658603,
          -3.0397658,
          -3.3465128,
          2.497067,
          -2.4534035,
          -1.8269585,
          3.3080454,
          -0.9567138,
          0.9673044,
          -3.377595,
          -2.0535572,
          1.9009749,
          -3.926347,
          -1.8221837,
          -4.6428576,
          -4.4200478,
          -0.4782284,
          -0.55316144,
          -1.5394782,
          -1.6960409,
          -0.6722022,
          -2.1263273,
          -2.3777347,
          -1.6797955,
          1.8025768,
          -1.8549978,
          -1.9375478,
          -4.583274,
          -0.1660711,
          -3.0908782,
          -4.198836,
          -3.0665345,
          -3.7392237,
          -2.275464,
          -1.5483865,
          5.3094583,
          -1.2381419,
          0.7167982,
          -2.4548867,
          -0.39370587,
          0.11332566,
          -3.0930603,
          -1.8389839,
          -2.320259,
          2.2683504,
          0.96029854,
          -2.7842693,
          -1.4750558,
          -0.95368457,
          2.0076241,
          -2.779873,
          -3.6908371,
          1.6211436,
          -3.5951471,
          -3.2670777,
          -3.5724723,
          1.9247744,
          -4.453645,
          -1.3735534,
          3.5151272,
          0.84561044,
          3.7706394,
          -1.2112418,
          -1.8887006,
          0.7159555,
          2.370125,
          -2.2718713,
          -1.7911996,
          1.4839997,
          -0.1022243,
          -2.9450362,
          3.2807178,
          -1.7680429,
          -3.0934753,
          -1.76053,
          -0.61732835,
          -2.0015745,
          -1.445447,
          -3.181821,
          1.196022,
          -4.280483,
          2.7556198,
          0.12690184,
          -0.45992175,
          -2.563883,
          -1.120854,
          -0.39360943,
          1.0273234,
          -1.280714,
          1.2650753,
          2.130259,
          -1.1464161,
          1.3786545,
          2.9961236,
          -0.18770933,
          -0.37381437,
          -0.49908575,
          -1.4475267,
          -2.4253626,
          4.2309275,
          -4.4317703,
          2.9627311,
          -0.2480612,
          -1.7230788,
          1.408028,
          -3.2506173,
          2.8367615,
          -1.7359803,
          -1.248265,
          3.9253492,
          1.0785414,
          4.324654,
          0.9906612,
          -1.6353748,
          1.9956287,
          1.3539481,
          2.6582391,
          -2.494481,
          -4.0935135,
          -4.0096197,
          -1.4875827,
          1.2685612,
          1.9510221,
          -1.4162471,
          -3.2166739,
          -1.5944804,
          1.0134497,
          4.17737,
          -2.2944598,
          -3.4944603,
          -1.4746403,
          -1.222817,
          1.5151069,
          1.5432383,
          -3.9924052,
          2.7867532,
          -1.9776591,
          3.9547896,
          -1.1411526,
          -3.346418,
          -1.3360114,
          -1.6669846,
          0.2530508,
          -1.4717486,
          -3.2078207,
          1.7896081,
          4.7485385,
          0.20240296,
          -4.6436095,
          -3.97226,
          0.6016,
          0.64823014,
          1.3155,
          -3.301323,
          1.86544,
          -2.266498,
          1.0674595,
          2.7171617,
          -3.227217,
          0.14189054,
          -1.4637617,
          -1.5103432,
          -2.1861308,
          -4.8052926,
          3.906417,
          3.138116,
          -2.4134111,
          -0.88102347,
          -0.5825695,
          -3.3927298,
          1.7898651,
          -2.2821023,
          1.1423751,
          -1.2823999,
          -2.5628633,
          2.3693967,
          -3.5813794,
          -1.5757163,
          1.0501947,
          1.689648,
          1.8937849,
          -3.5086038,
          -3.167514,
          -2.811542,
          1.9120113,
          -4.5907674,
          -0.6243807,
          -2.4121842,
          3.0108604,
          1.7256274,
          2.044138,
          -3.536224,
          -4.419367,
          -3.114975,
          1.520122,
          1.3464195,
          -1.5516409,
          -1.2610767,
          0.91319716,
          2.4615219,
          -2.8936596,
          -0.9484393,
          3.5648386,
          3.8425071,
          -4.567074,
          -1.4612107,
          2.4380684,
          -0.20496602,
          -3.2425306,
          -3.4338546,
          -0.39468175,
          5.0870557,
          -1.9889488,
          2.1025999,
          1.0238497,
          2.650639,
          0.7528991,
          3.8086038,
          -4.04782,
          2.212727,
          3.7674375,
          -2.835638,
          -4.5048656,
          3.523541,
          -4.6465816,
          -1.4227325,
          -1.2947322,
          -1.3558357,
          -0.752377,
          -4.1200156,
          3.4003034,
          1.2374672,
          0.46781182,
          -0.0013981123,
          2.1267598,
          2.3490608,
          2.2444954,
          3.0937686,
          3.902695,
          -3.8126404,
          3.9993715,
          2.0088496,
          -1.4997364,
          2.9320376,
          3.1910245,
          -1.6228343,
          -1.4960115,
          2.4921145,
          2.6774528,
          -4.034343,
          1.9052563,
          -1.8107212,
          1.0604969,
          -1.7563319
         ],
         "xaxis": "x",
         "y": [
          -1.5640364,
          0.14177601,
          -1.0817841,
          -6.260941,
          -3.810921,
          0.85986626,
          0.8002744,
          2.3148978,
          1.5698224,
          2.242737,
          3.0899358,
          -3.9928374,
          1.2921872,
          0.5813762,
          -0.013852755,
          2.5035315,
          -1.0943502,
          0.041798342,
          -0.36151844,
          1.0188682,
          0.092123,
          1.4964161,
          -0.56690204,
          1.3956656,
          0.5382956,
          0.98378354,
          -2.214355,
          2.952131,
          4.1376853,
          -2.1450438,
          -2.9966147,
          1.5327384,
          -6.1470227,
          3.9150245,
          3.4561696,
          3.4717848,
          0.29224938,
          0.26960838,
          -4.278893,
          4.280072,
          -1.1067343,
          -2.9247916,
          -0.1678979,
          -0.9765181,
          3.955486,
          0.58207285,
          3.293471,
          0.4041104,
          0.34865245,
          -1.4719764,
          -1.7554955,
          2.0847266,
          -3.3193862,
          3.9634972,
          -2.7092402,
          4.253825,
          -0.89364475,
          -2.114774,
          2.9758897,
          2.7751088,
          -0.38844085,
          1.7069057,
          -1.4659656,
          -0.19795719,
          -3.9550753,
          2.85254,
          -4.0289726,
          2.511452,
          -4.4740734,
          2.4467669,
          4.6471076,
          2.3141186,
          -1.9008616,
          -2.2565122,
          1.0311648,
          -0.36009014,
          3.2163393,
          -4.48734,
          -2.6623929,
          -5.4954658,
          -0.52112985,
          -1.7060882,
          -1.459008,
          -0.4703516,
          -0.22602607,
          2.5171523,
          -3.8463497,
          3.4822667,
          0.8304564,
          3.0992956,
          1.6004425,
          0.0074240547,
          3.7381074,
          0.32536152,
          -4.513557,
          -4.8072915,
          -4.628617,
          -3.4135292,
          -4.474646,
          1.1686126,
          -3.344136,
          -4.031725,
          2.2048316,
          -2.0065525,
          3.104032,
          3.1954212,
          3.7418218,
          -1.3667079,
          1.8331224,
          -0.5766632,
          -0.856002,
          0.38009918,
          2.8774908,
          4.3571143,
          -5.150217,
          -1.2210945,
          -0.09536095,
          -3.860118,
          -4.5019946,
          1.8061074,
          4.1316113,
          1.7408434,
          -2.8592474,
          -1.1905402,
          1.5300851,
          -4.3008037,
          -0.92280746,
          -4.1337433,
          1.0880048,
          -1.0289665,
          3.3947728,
          -1.1756847,
          -1.729437,
          3.6547139,
          3.1727967,
          0.9329872,
          0.43992782,
          1.624196,
          3.2749336,
          -1.5140415,
          2.303834,
          0.34728715,
          3.645958,
          2.5810192,
          3.0577652,
          0.032141242,
          -1.0271645,
          -1.1275113,
          -3.391638,
          -1.8428285,
          0.27521446,
          0.9563481,
          -0.80544597,
          -2.7573445,
          4.613541,
          -4.619443,
          -0.9800307,
          -1.7880584,
          0.8193156,
          -0.991511,
          -1.6028423,
          -4.0712867,
          -0.44933897,
          1.6995815,
          3.3246188,
          0.29259995,
          0.74780655,
          2.4603457,
          4.302227,
          -0.19374724,
          3.5589101,
          -5.742752,
          -0.84117067,
          1.362565,
          2.0526357,
          -1.6517524,
          -1.6094989,
          -3.1535022,
          4.6412106,
          3.297967,
          -0.6088455,
          2.0280356,
          -1.0759755,
          -4.325671,
          -3.8766716,
          -3.0849311,
          -0.5371943,
          1.8737379,
          -3.6793067,
          1.340806,
          -1.8328186,
          -2.5297678,
          -4.617932,
          0.38998064,
          0.9025149,
          2.2184575,
          -4.353831,
          0.67807347,
          2.804687,
          4.0725226,
          -3.314388,
          1.759004,
          -1.1886132,
          -2.6481528,
          3.5508869,
          1.3631482,
          3.0932615,
          0.13709852,
          4.2687745,
          2.12542,
          -0.61146986,
          -4.5369725,
          -2.1605816,
          -1.8642287,
          0.6752686,
          -4.86773,
          2.6493666,
          1.2392019,
          -0.079700656,
          -3.2782736,
          -0.99669236,
          1.4972256,
          4.534759,
          2.8882535,
          4.0723767,
          3.1754088,
          0.965619,
          2.1249647,
          -2.6796572,
          2.184416,
          -0.05805295,
          2.2220552,
          0.62046397,
          1.2571577,
          1.672668,
          2.520919,
          2.997227,
          4.3118825,
          -3.4180195,
          -2.331867,
          -2.7612145,
          2.9646142,
          2.731337,
          2.8190622,
          -1.4070851,
          -0.344006,
          1.149393,
          0.6043948,
          -2.5449638,
          3.1869948,
          2.0687332,
          -0.8996035,
          -5.4612727,
          -3.0142221,
          3.227164,
          2.7949448,
          0.51172775,
          0.32222438,
          -2.9793825,
          2.8830671,
          3.4793274,
          1.210161,
          3.952718,
          -1.7929158
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "SE-ResNet\n\n**SE ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/resnet) th..."
          ],
          [
           "Res2Net\n\n**Res2Net** is an image model that employs a variation on bottleneck residual blocks, [Res2..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: Res2Net\n  Paper:\n    Title: 'Res2Net: A New Multi-s..."
          ],
          [
           "# Ensemble Adversarial Inception ResNet v2\n\n**Inception-ResNet-v2** is a convolutional neural archit..."
          ],
          [
           "TResNet\n\nA **TResNet** is a variant on a [ResNet](https://paperswithcode.com/method/resnet) that aim..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "SE-ResNet\n\n**SE ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/resnet) th..."
          ],
          [
           "CSP-ResNeXt\n\n**CSPResNeXt** is a convolutional neural network where we apply the Cross Stage Partial..."
          ],
          [
           "RexNet\n\n**Rank Expansion Networks** (ReXNets) follow a set of new design principles for designing bo..."
          ],
          [
           "RegNetY\n\n**RegNetY** is a convolutional network design space with simple, regular models with parame..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: RegNetY\n  Paper:\n    Title: Designing Network Design Spa..."
          ],
          [
           "Momentum: 0.9\n    Batch Size: 512\n    Image Size: '224'\n    Weight Decay: 5.0e-05\n    Interpolation:..."
          ],
          [
           "Feature Extraction\n\nAll of the models in `timm` have consistent mechanisms for obtaining various typ..."
          ],
          [
           "Wide ResNet\n\n**Wide Residual Networks** are a variant on [ResNets](https://paperswithcode.com/method..."
          ],
          [
           "Res2NeXt\n\n**Res2NeXt** is an image model that employs a variation on [ResNeXt](https://paperswithcod..."
          ],
          [
           "RegNetY\n\n**RegNetY** is a convolutional network design space with simple, regular models with parame..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: RegNetY\n  Paper:\n    Title: Designing Network Design Spa..."
          ],
          [
           "Momentum: 0.9\n    Batch Size: 512\n    Image Size: '224'\n    Weight Decay: 5.0e-05\n    Interpolation:..."
          ],
          [
           "Archived Changes\n\n### Nov 22, 2021\n* A number of updated weights anew new model defs\n  * `eca_halone..."
          ],
          [
           "### June 8, 2021\n* Add first ResMLP weights, trained in PyTorch XLA on TPU-VM w/ my XLA branch. 24 b..."
          ],
          [
           "### Jan 30, 2021\n* Add initial \"Normalization Free\" NF-RegNet-B* and NF-ResNet model definitions bas..."
          ],
          [
           "### May 3, 2020\n* Pruned EfficientNet B1, B2, and B3 (https://arxiv.org/abs/2002.08258) contributed ..."
          ],
          [
           "(Tensorflow) EfficientNet CondConv\n\n**EfficientNet** is a convolutional neural network architecture ..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: TF EfficientNet CondConv\n  Paper:\n    Title: 'CondC..."
          ],
          [
           "SWSL ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-blo..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: SWSL ResNext\n  Paper:\n    Title: Billion-scale semi..."
          ],
          [
           "Model Summaries\n\nThe model architectures included come from a wide variety of sources. Sources, incl..."
          ],
          [
           "## RegNet [[regnet.py](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/reg..."
          ],
          [
           "(Tensorflow) MobileNet v3\n\n**MobileNetV3** is a convolutional neural network that is designed for mo..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: TF MobileNet V3\n  Paper:\n    Title: Searching for M..."
          ],
          [
           "Sharing and Loading Models From the Hugging Face Hub\n\nThe `timm` library has a built-in integration ..."
          ],
          [
           "Big Transfer (BiT)\n\n**Big Transfer (BiT)** is a type of pretraining recipe that pre-trains  on a lar..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "MobileNet v2\n\n**MobileNetV2** is a convolutional neural network architecture that seeks to perform w..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: MobileNet V2\n  Paper:\n    Title: 'MobileNetV2: Inve..."
          ],
          [
           "EfficientNet (Knapsack Pruned)\n\n**EfficientNet** is a convolutional neural network architecture and ..."
          ],
          [
           "(Tensorflow) Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the ..."
          ],
          [
           "DenseNet\n\n**DenseNet** is a type of convolutional neural network that utilises dense connections bet..."
          ],
          [
           "```\n\n```\n@misc{rw2019timm,\n  author = {Ross Wightman},\n  title = {PyTorch Image Models},\n  year = {2..."
          ],
          [
           "Training Examples\n\n## EfficientNet-B2 with RandAugment - 80.4 top-1, 95.1 top-5\nThese params are for..."
          ],
          [
           "MnasNet\n\n**MnasNet** is a type of convolutional neural network optimized for mobile devices that is ..."
          ],
          [
           "SK-ResNet\n\n**SK ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/resnet) th..."
          ],
          [
           "Inception v4\n\n**Inception-v4** is a convolutional neural network architecture that builds on previou..."
          ],
          [
           "CSP-ResNeXt\n\n**CSPResNeXt** is a convolutional neural network where we apply the Cross Stage Partial..."
          ],
          [
           "MnasNet\n\n**MnasNet** is a type of convolutional neural network optimized for mobile devices that is ..."
          ],
          [
           "NASNet\n\n**NASNet** is a type of convolutional neural network discovered through neural architecture ..."
          ],
          [
           "SelecSLS\n\n**SelecSLS** uses novel selective long and short range skip connections to improve the inf..."
          ],
          [
           "MixNet\n\n**MixNet** is a type of convolutional neural network discovered via AutoML that utilises [Mi..."
          ],
          [
           "DenseNet\n\n**DenseNet** is a type of convolutional neural network that utilises dense connections bet..."
          ],
          [
           "```\n\n```\n@misc{rw2019timm,\n  author = {Ross Wightman},\n  title = {PyTorch Image Models},\n  year = {2..."
          ],
          [
           "SK-ResNeXt\n\n**SK ResNeXt** is a variant of a [ResNeXt](https://www.paperswithcode.com/method/resnext..."
          ],
          [
           "Recent Changes\n\n### Aug 29, 2022\n* MaxVit window size scales with img_size by default. Add new RelPo..."
          ],
          [
           "### April 22, 2022\n* `timm` models are now officially supported in [fast.ai](https://www.fast.ai/)! ..."
          ],
          [
           "### Dec 6, 2022\n* Add 'EVA g', BEiT style ViT-g/14 model weights w/ both MIM pretrain and CLIP pretr..."
          ],
          [
           "* Port of MaxViT Tensorflow Weights from official impl at https://github.com/google-research/maxvit\n..."
          ],
          [
           "### Aug 15, 2022\n* ConvNeXt atto weights added\n  * `convnext_atto` - 75.7 @ 224, 77.0 @ 288\n  * `con..."
          ],
          [
           "### March 23, 2022\n* Add `ParallelBlock` and `LayerScale` option to base vit models to support model..."
          ],
          [
           "Hugging Face Timm Docs\n\n## Getting Started\n\n```\npip install git+https://github.com/huggingface/doc-b..."
          ],
          [
           "ResNeSt\n\nA **ResNeSt** is a variant on a [ResNet](https://paperswithcode.com/method/resnet), which i..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: ResNeSt\n  Paper:\n    Title: 'ResNeSt: Split-Attention Ne..."
          ],
          [
           "Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.96%\n      Top 5 Accuracy: 95.38%\n- Name: res..."
          ],
          [
           "FBNet\n\n**FBNet** is a type of convolutional neural architectures discovered through [DNAS](https://p..."
          ],
          [
           "HRNet\n\n**HRNet**, or **High-Resolution Net**, is a general purpose convolutional neural network for ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: HRNet\n  Paper:\n    Title: Deep High-Resolution Represent..."
          ],
          [
           "Top 5 Accuracy: 94.37%\n- Name: hrnet_w48\n  In Collection: HRNet\n  Metadata:\n    FLOPs: 22285865760\n ..."
          ],
          [
           "Learning Rate Schedulers\n\nThis page contains the API reference documentation for learning rate sched..."
          ],
          [
           "MobileNet v3\n\n**MobileNetV3** is a convolutional neural network that is designed for mobile phone CP..."
          ],
          [
           "ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the layer ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: ResNet\n  Paper:\n    Title: Deep Residual Learning for Im..."
          ],
          [
           "Tasks:\n    - Image Classification\n    Training Techniques:\n    - SGD with Momentum\n    - Weight Deca..."
          ],
          [
           "SK-ResNet\n\n**SK ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/resnet) th..."
          ],
          [
           "SelecSLS\n\n**SelecSLS** uses novel selective long and short range skip connections to improve the inf..."
          ],
          [
           "PNASNet\n\n**Progressive Neural Architecture Search**, or **PNAS**, is a method for learning the struc..."
          ],
          [
           "(Tensorflow) EfficientNet CondConv\n\n**EfficientNet** is a convolutional neural network architecture ..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: TF EfficientNet CondConv\n  Paper:\n    Title: 'CondC..."
          ],
          [
           "ECA-ResNet\n\nAn **ECA ResNet** is a variant on a [ResNet](https://paperswithcode.com/method/resnet) t..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Validation and Benchmark Results\n\nThis folder contains validation and benchmark results for the mode..."
          ],
          [
           "Results\n\nCSV files containing an ImageNet-1K and out-of-distribution (OOD) test set validation resul..."
          ],
          [
           "Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the Inception fam..."
          ],
          [
           "CSP-DarkNet\n\n**CSPDarknet53** is a convolutional neural network and backbone for object detection th..."
          ],
          [
           "SPNASNet\n\n**Single-Path NAS** is a novel differentiable NAS method for designing hardware-efficient ..."
          ],
          [
           "Wide ResNet\n\n**Wide Residual Networks** are a variant on [ResNets](https://paperswithcode.com/method..."
          ],
          [
           "SSL ResNeXT\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-bloc..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: SSL ResNext\n  Paper:\n    Title: Billion-scale semi-..."
          ],
          [
           "RegNetX\n\n**RegNetX** is a convolutional network design space with simple, regular models with parame..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: RegNetX\n  Paper:\n    Title: Designing Network Design Spa..."
          ],
          [
           "Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_040..."
          ],
          [
           "Installation\n\nBefore you start, you'll need to setup your environment and install the appropriate pa..."
          ],
          [
           "Results\n\nCSV files containing an ImageNet-1K and out-of-distribution (OOD) test set validation resul..."
          ],
          [
           "(Tensorflow) MobileNet v3\n\n**MobileNetV3** is a convolutional neural network that is designed for mo..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: TF MobileNet V3\n  Paper:\n    Title: Searching for M..."
          ],
          [
           "Big Transfer (BiT)\n\n**Big Transfer (BiT)** is a type of pretraining recipe that pre-trains  on a lar..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Instagram ResNeXt WSL\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/re..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "(Gluon) Xception\n\n**Xception** is a convolutional neural network architecture that relies solely on ..."
          ],
          [
           "This guideline is very much a work-in-progress.*\n\nContributions to `timm` for code, documentation, t..."
          ],
          [
           "Deep Layer Aggregation\n\nExtending  “shallow” skip connections, **Dense Layer Aggregation (DLA)** inc..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: DLA\n  Paper:\n    Title: Deep Layer Aggregation\n    URL: ..."
          ],
          [
           "Momentum: 0.9\n    Batch Size: 256\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: ..."
          ],
          [
           "Data\n\n[[autodoc]] timm.data.create_dataset\n\n[[autodoc]] timm.data.create_loader\n\n[[autodoc]] timm.da..."
          ],
          [
           "CSP-ResNet\n\n**CSPResNet** is a convolutional neural network where we apply the Cross Stage Partial N..."
          ],
          [
           "Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the Inception fam..."
          ],
          [
           "Getting Started\n\n## Welcome\n\nWelcome to the `timm` documentation, a lean set of docs that covers the..."
          ],
          [
           "Model Summaries\n\nThe model architectures included come from a wide variety of sources. Sources, incl..."
          ],
          [
           "## RegNet\n\n* Implementation: [regnet.py](https://github.com/rwightman/pytorch-image-models/blob/mast..."
          ],
          [
           "Deep Layer Aggregation\n\nExtending  “shallow” skip connections, **Dense Layer Aggregation (DLA)** inc..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: DLA\n  Paper:\n    Title: Deep Layer Aggregation\n    URL: ..."
          ],
          [
           "Momentum: 0.9\n    Batch Size: 256\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: ..."
          ],
          [
           "Feature Extraction\n\nAll of the models in `timm` have consistent mechanisms for obtaining various typ..."
          ],
          [
           "(Gluon) ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to th..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: Gloun ResNet\n  Paper:\n    Title: Deep Residual Learning ..."
          ],
          [
           "- Residual Connection\n    - Softmax\n    Tasks:\n    - Image Classification\n    Training Data:\n    - I..."
          ],
          [
           "Adversarial Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the I..."
          ],
          [
           "ResNet-D\n\n**ResNet-D** is a modification on the [ResNet](https://paperswithcode.com/method/resnet) a..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "(Tensorflow) EfficientNet Lite\n\n**EfficientNet** is a convolutional neural network architecture and ..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "CSP-DarkNet\n\n**CSPDarknet53** is a convolutional neural network and backbone for object detection th..."
          ],
          [
           "EfficientNet\n\n**EfficientNet** is a convolutional neural network architecture and scaling method tha..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: EfficientNet\n  Paper:\n    Title: 'EfficientNet: Rethinki..."
          ],
          [
           "Interpolation: bicubic\n  Code: https://github.com/rwightman/pytorch-image-models/blob/a7f95818e44b28..."
          ],
          [
           "timm\n\n<img class=\"float-left !m-0 !border-0 !dark:border-0 !shadow-none !max-w-lg w-[150px]\" src=\"ht..."
          ],
          [
           "Scripts\nA train, validation, inference, and checkpoint cleaning script included in the github root f..."
          ],
          [
           "(Legacy) SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNeXt](https://www.paperswithcode.com/metho..."
          ],
          [
           "RexNet\n\n**Rank Expansion Networks** (ReXNets) follow a set of new design principles for designing bo..."
          ],
          [
           "MixNet\n\n**MixNet** is a type of convolutional neural network discovered via AutoML that utilises [Mi..."
          ],
          [
           "(Gluon) SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNext](https://www.paperswithcode.com/method..."
          ],
          [
           "RegNetX\n\n**RegNetX** is a convolutional network design space with simple, regular models with parame..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: RegNetX\n  Paper:\n    Title: Designing Network Design Spa..."
          ],
          [
           "Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_040..."
          ],
          [
           "(Tensorflow) EfficientNet\n\n**EfficientNet** is a convolutional neural network architecture and scali..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: TF EfficientNet\n  Paper:\n    Title: 'EfficientNet: Rethi..."
          ],
          [
           "Interpolation: bicubic\n    RMSProp Decay: 0.9\n    Label Smoothing: 0.1\n    BatchNorm Momentum: 0.99\n..."
          ],
          [
           "- Average Pooling\n    - Batch Normalization\n    - Convolution\n    - Dense Connections\n    - Dropout\n..."
          ],
          [
           "(Legacy) SE-ResNet\n\n**SE ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/r..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Inception ResNet v2\n\n**Inception-ResNet-v2** is a convolutional neural architecture that builds on t..."
          ],
          [
           "(Gluon) Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the Incep..."
          ],
          [
           "(Legacy) SENet\n\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and..."
          ],
          [
           "Quickstart\n\nThis quickstart is intended for developers who are ready to dive into the code and see a..."
          ],
          [
           "Optimization\n\nThis page contains the API reference documentation for learning rate optimizers includ..."
          ],
          [
           "SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNext](https://www.paperswithcode.com/method/resneXt..."
          ],
          [
           "SWSL ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the l..."
          ],
          [
           "FBNet\n\n**FBNet** is a type of convolutional neural architectures discovered through [DNAS](https://p..."
          ],
          [
           "Dual Path Network (DPN)\n\nA **Dual Path Network (DPN)** is a convolutional neural network which prese..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "(Tensorflow) MixNet\n\n**MixNet** is a type of convolutional neural network discovered via AutoML that..."
          ],
          [
           "Inception ResNet v2\n\n**Inception-ResNet-v2** is a convolutional neural architecture that builds on t..."
          ],
          [
           "(Gluon) SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNext](https://www.paperswithcode.com/method..."
          ],
          [
           "(Tensorflow) Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the ..."
          ],
          [
           "SK-ResNeXt\n\n**SK ResNeXt** is a variant of a [ResNeXt](https://www.paperswithcode.com/method/resnext..."
          ],
          [
           "HRNet\n\n**HRNet**, or **High-Resolution Net**, is a general purpose convolutional neural network for ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: HRNet\n  Paper:\n    Title: Deep High-Resolution Represent..."
          ],
          [
           "Top 5 Accuracy: 94.37%\n- Name: hrnet_w48\n  In Collection: HRNet\n  Metadata:\n    FLOPs: 22285865760\n ..."
          ],
          [
           "(Legacy) SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNeXt](https://www.paperswithcode.com/metho..."
          ],
          [
           "SE-ResNeXt\n\n**SE ResNeXt** is a variant of a [ResNext](https://www.paperswithcode.com/method/resneXt..."
          ],
          [
           "(Legacy) SE-ResNet\n\n**SE ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/r..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "EfficientNet\n\n**EfficientNet** is a convolutional neural network architecture and scaling method tha..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: EfficientNet\n  Paper:\n    Title: 'EfficientNet: Rethinki..."
          ],
          [
           "Interpolation: bicubic\n  Code: https://github.com/rwightman/pytorch-image-models/blob/a7f95818e44b28..."
          ],
          [
           "Res2NeXt\n\n**Res2NeXt** is an image model that employs a variation on [ResNeXt](https://paperswithcod..."
          ],
          [
           "ECA-ResNet\n\nAn **ECA ResNet** is a variant on a [ResNet](https://paperswithcode.com/method/resnet) t..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Instagram ResNeXt WSL\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/re..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Res2Net\n\n**Res2Net** is an image model that employs a variation on bottleneck residual blocks, [Res2..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: Res2Net\n  Paper:\n    Title: 'Res2Net: A New Multi-s..."
          ],
          [
           "Scripts\n\nA train, validation, inference, and checkpoint cleaning script included in the github root ..."
          ],
          [
           "ResNeSt\n\nA **ResNeSt** is a variant on a [ResNet](https://paperswithcode.com/method/resnet), which i..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: ResNeSt\n  Paper:\n    Title: 'ResNeSt: Split-Attention Ne..."
          ],
          [
           "Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.96%\n      Top 5 Accuracy: 95.38%\n- Name: res..."
          ],
          [
           "ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the layer ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: ResNet\n  Paper:\n    Title: Deep Residual Learning for Im..."
          ],
          [
           "Tasks:\n    - Image Classification\n    Training Techniques:\n    - SGD with Momentum\n    - Weight Deca..."
          ],
          [
           "NASNet\n\n**NASNet** is a type of convolutional neural network discovered through neural architecture ..."
          ],
          [
           "(Gluon) Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the Incep..."
          ],
          [
           "(Gluon) SENet\n\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and-..."
          ],
          [
           "Vision Transformer (ViT)\n\nThe **Vision Transformer** is a model for image classification that employ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: Vision Transformer\n  Paper:\n    Title: 'An Image is Wort..."
          ],
          [
           "In Collection: Vision Transformer\n  Metadata:\n    FLOPs: 28236450816\n    Parameters: 48750000\n    Fi..."
          ],
          [
           "ResNet-D\n\n**ResNet-D** is a modification on the [ResNet](https://paperswithcode.com/method/resnet) a..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "PNASNet\n\n**Progressive Neural Architecture Search**, or **PNAS**, is a method for learning the struc..."
          ],
          [
           "AdvProp (EfficientNet)\n\n**AdvProp** is an adversarial training scheme which treats adversarial examp..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: AdvProp\n  Paper:\n    Title: Adversarial Examples Improve..."
          ],
          [
           "BatchNorm Momentum: 0.99\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad04..."
          ],
          [
           "MobileNet v2\n\n**MobileNetV2** is a convolutional neural network architecture that seeks to perform w..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: MobileNet V2\n  Paper:\n    Title: 'MobileNetV2: Inve..."
          ],
          [
           "TResNet\n\nA **TResNet** is a variant on a [ResNet](https://paperswithcode.com/method/resnet) that aim..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "ESE-VoVNet\n\n**VoVNet** is a convolutional neural network that seeks to make [DenseNet](https://paper..."
          ],
          [
           "CSP-ResNet\n\n**CSPResNet** is a convolutional neural network where we apply the Cross Stage Partial N..."
          ],
          [
           "AdvProp (EfficientNet)\n\n**AdvProp** is an adversarial training scheme which treats adversarial examp..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: AdvProp\n  Paper:\n    Title: Adversarial Examples Improve..."
          ],
          [
           "BatchNorm Momentum: 0.99\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad04..."
          ],
          [
           "(Legacy) SENet\n\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and..."
          ],
          [
           "(Gluon) SENet\n\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and-..."
          ],
          [
           "SWSL ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-blo..."
          ],
          [
           "```\n\n<!--\nType: model-index\nCollections:\n- Name: SWSL ResNext\n  Paper:\n    Title: Billion-scale semi..."
          ],
          [
           "ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-block) t..."
          ],
          [
           "PyTorch Image Models\n- [What's New](#whats-new)\n- [Introduction](#introduction)\n- [Models](#models)\n..."
          ],
          [
           "### July 27, 2023\n* Added timm trained `seresnextaa201d_32x8d.sw_in12k_ft_in1k_384` weights (and `.s..."
          ],
          [
           "* Multi-weight and HF hub for DeiT and MLP-Mixer based models\n\n### March 22, 2023\n* More weights pus..."
          ],
          [
           "|model                                                                                              ..."
          ],
          [
           "|[coatnet_bn_0_rw_224.sw_in1k](https://huggingface.co/timm/coatnet_bn_0_rw_224.sw_in1k)             ..."
          ],
          [
           "### Jan 11, 2023\n* Update ConvNeXt ImageNet-12k pretrain series w/ two new fine-tuned weights (and p..."
          ],
          [
           "| model                                            |   top1 |   param_count |   gmac |   macts | hub..."
          ],
          [
           "* Port of MaxViT Tensorflow Weights from official impl at https://github.com/google-research/maxvit\n..."
          ],
          [
           "## Introduction\n\nPy**T**orch **Im**age **M**odels (`timm`) is a collection of image models, layers, ..."
          ],
          [
           "## Features\n\nSeveral (less common) features that I often utilize in my projects are included. Many o..."
          ],
          [
           "One of the greatest assets of PyTorch is the community and their contributions. A few of my favourit..."
          ],
          [
           "```\n\n### Latest DOI\n\n[![DOI](https://zenodo.org/badge/168799526.svg)](https://zenodo.org/badge/lates..."
          ],
          [
           "ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-block) t..."
          ],
          [
           "Xception\n\n**Xception** is a convolutional neural network architecture that relies solely on [depthwi..."
          ],
          [
           "Dual Path Network (DPN)\n\nA **Dual Path Network (DPN)** is a convolutional neural network which prese..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "(Gluon) ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-..."
          ],
          [
           "# Ensemble Adversarial Inception ResNet v2\n\n**Inception-ResNet-v2** is a convolutional neural archit..."
          ],
          [
           "(Gluon) ResNeXt\n\nA **ResNeXt** repeats a [building block](https://paperswithcode.com/method/resnext-..."
          ],
          [
           "SSL ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the la..."
          ],
          [
           "Xception\n\n**Xception** is a convolutional neural network architecture that relies solely on [depthwi..."
          ],
          [
           "(Gluon) ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to th..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: Gloun ResNet\n  Paper:\n    Title: Deep Residual Learning ..."
          ],
          [
           "- Residual Connection\n    - Softmax\n    Tasks:\n    - Image Classification\n    Training Data:\n    - I..."
          ],
          [
           "(Tensorflow) EfficientNet Lite\n\n**EfficientNet** is a convolutional neural network architecture and ..."
          ],
          [
           "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscr..."
          ],
          [
           "Models\n\n[[autodoc]] timm.create_model\n\n[[autodoc]] timm.list_models..."
          ],
          [
           "SPNASNet\n\n**Single-Path NAS** is a novel differentiable NAS method for designing hardware-efficient ..."
          ],
          [
           "MobileNet v3\n\n**MobileNetV3** is a convolutional neural network that is designed for mobile phone CP..."
          ],
          [
           "EfficientNet (Knapsack Pruned)\n\n**EfficientNet** is a convolutional neural network architecture and ..."
          ],
          [
           "Inception v4\n\n**Inception-v4** is a convolutional neural network architecture that builds on previou..."
          ],
          [
           "Noisy Student (EfficientNet)\n\n**Noisy Student Training** is a semi-supervised learning approach. It ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: Noisy Student\n  Paper:\n    Title: Self-training with Noi..."
          ],
          [
           "Architecture:\n    - 1x1 Convolution\n    - Average Pooling\n    - Batch Normalization\n    - Convolutio..."
          ],
          [
           "Noisy Student (EfficientNet)\n\n**Noisy Student Training** is a semi-supervised learning approach. It ..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: Noisy Student\n  Paper:\n    Title: Self-training with Noi..."
          ],
          [
           "Architecture:\n    - 1x1 Convolution\n    - Average Pooling\n    - Batch Normalization\n    - Convolutio..."
          ],
          [
           "(Tensorflow) MixNet\n\n**MixNet** is a type of convolutional neural network discovered via AutoML that..."
          ],
          [
           "SSL ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the la..."
          ],
          [
           "Adversarial Inception v3\n\n**Inception v3** is a convolutional neural network architecture from the I..."
          ],
          [
           "SWSL ResNet\n\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the l..."
          ],
          [
           "(Tensorflow) EfficientNet\n\n**EfficientNet** is a convolutional neural network architecture and scali..."
          ],
          [
           "```..."
          ],
          [
           "<!--\nType: model-index\nCollections:\n- Name: TF EfficientNet\n  Paper:\n    Title: 'EfficientNet: Rethi..."
          ],
          [
           "Interpolation: bicubic\n    RMSProp Decay: 0.9\n    Label Smoothing: 0.1\n    BatchNorm Momentum: 0.99\n..."
          ],
          [
           "- Average Pooling\n    - Batch Normalization\n    - Convolution\n    - Dense Connections\n    - Dropout\n..."
          ],
          [
           "ESE-VoVNet\n\n**VoVNet** is a convolutional neural network that seeks to make [DenseNet](https://paper..."
          ],
          [
           "(Gluon) Xception\n\n**Xception** is a convolutional neural network architecture that relies solely on ..."
          ]
         ],
         "hovertemplate": "source=pytorch-image-models<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "pytorch-image-models, circle",
         "marker": {
          "color": "#FF6692",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "pytorch-image-models, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -3.260175,
          -3.7395637,
          -1.4764823,
          -4.0623045,
          -2.8112276,
          2.2898755,
          -0.06322597,
          -3.9768522,
          1.045928,
          1.9669842,
          1.1016767,
          -4.1889625,
          -2.5888991,
          -3.3122523,
          1.5072619,
          3.595967,
          2.89242,
          10.3229885,
          -4.2091084,
          -1.957434,
          -0.81731784,
          -3.073776,
          -1.8118223,
          2.7340615,
          2.1304345,
          0.99773324,
          -0.17565474,
          -3.2070773,
          -2.4940875,
          -1.058885,
          -3.2284887,
          -2.6512265,
          1.36063,
          2.1931229,
          0.1320402,
          -2.6655407,
          -2.7992315,
          -2.2870083,
          2.0121498,
          3.3672574,
          1.7502375,
          0.47294527,
          -3.2827244,
          -4.3439775,
          -2.0091684,
          -3.9024482,
          -1.617091,
          -1.6077981,
          2.0451262,
          1.4282582,
          -2.7688663,
          2.0210335,
          -4.0518966,
          4.5956182,
          2.575787,
          0.57139975,
          -1.7964762,
          1.1277636,
          3.912448,
          1.1382687,
          -0.28290924,
          10.3221655,
          -2.7532153,
          -2.8958647,
          2.922429,
          -3.0451066,
          10.322,
          -4.9353156,
          -2.4491343,
          4.591237,
          -4.273053,
          2.6352947,
          10.322357,
          2.9538023,
          -3.1213133,
          -0.10331212,
          -2.4407897,
          3.7980678,
          -1.6177247,
          1.2208219,
          -3.751934,
          -1.7675827,
          -0.99269783,
          -0.3935655,
          2.2186391,
          1.2424961,
          -4.3148212,
          1.0883162,
          -1.3234707,
          -2.7885284,
          -0.8255208,
          10.322663,
          -0.077165276,
          -2.4483693,
          -2.597115,
          -0.5861181,
          -1.6350747,
          -2.7410994,
          -0.9867821,
          1.3309655,
          0.5683828,
          -4.1172667,
          -2.9619067,
          4.2810173,
          2.2108455,
          10.322043,
          -0.7377839,
          5.6397233,
          1.7952117,
          0.29359555,
          -2.6340635,
          0.30128697,
          -1.0862182,
          1.3862089,
          -2.7782931,
          10.322312,
          -0.9375276,
          5.6870537,
          1.970884,
          3.6575472,
          10.322168,
          -3.5817592,
          -2.0737286,
          1.2091005,
          -0.06662724,
          -2.4333372,
          -2.564955,
          -0.6897894,
          -2.646464,
          2.9386272,
          10.322796,
          -2.6133046,
          -0.77688515,
          -0.5908222,
          3.551785,
          -0.51148623,
          0.24121062,
          -2.0966637,
          0.9459167,
          -0.4164745,
          10.321504,
          -0.048158556,
          -2.5890071,
          -4.27783,
          10.322047,
          -2.9190512,
          -3.2358909,
          -4.100962,
          1.6032876,
          -4.2332764,
          -2.643007,
          1.959238,
          2.0950286,
          -3.7063882,
          -4.359278,
          -0.3678113,
          -4.6064916,
          -1.4059404,
          0.7573657,
          -2.5811932,
          -1.836172,
          -1.4156673,
          -4.0622644,
          -2.9565299,
          0.3260339,
          -0.7867872,
          10.321068,
          -4.5851564,
          -2.5185852,
          -0.4945653,
          0.65021574,
          -3.4050221,
          1.8363742,
          -0.53178626,
          10.322056,
          -2.5384362,
          -0.68836206,
          -0.5637593,
          -1.2192775,
          -0.17302413,
          0.31101122,
          -3.3729048,
          -2.5218058,
          -1.2697802,
          3.5401368,
          -1.8059349,
          10.321244,
          -2.793582,
          -2.8707356,
          2.1689966,
          10.322346,
          3.0353398,
          -3.1553383,
          -3.0672512,
          -2.5391698,
          1.2085904,
          -0.64177305,
          10.321752,
          -2.3526685,
          -2.6974545,
          -3.5835474,
          -2.3120253,
          3.4232168,
          -3.6249185,
          10.321879,
          5.6845756,
          0.76901627,
          2.338097,
          -2.844326,
          -3.9452229,
          4.528799,
          4.7071857,
          -3.9702828,
          1.5007868,
          10.322339,
          5.630538,
          0.8555359,
          -3.7018118,
          -0.72926974,
          1.4080476,
          -3.636867,
          -3.9718354,
          -2.2396834,
          -2.642435,
          -4.1005692,
          1.8317343,
          -4.6755514,
          -0.04209566,
          2.9657922,
          1.3698784,
          0.38890025,
          -2.3591344,
          -3.9582894,
          2.7523975,
          -2.68164,
          3.6974313,
          1.8529719,
          0.052559927,
          -1.4159037,
          0.8198854,
          -4.0023,
          -1.5510297,
          -2.9817088,
          -1.4455155,
          10.322406,
          -3.383568,
          -2.0094557,
          0.29741183,
          -1.3507578,
          -0.4339515,
          -3.5308437,
          -3.2913775,
          -3.1961107,
          -3.0619388,
          -1.7636138,
          10.321945,
          -1.0249522,
          -4.0936503,
          1.0657908,
          10.330931,
          -0.86953735,
          -4.2048545,
          -1.1792177,
          -4.95407,
          4.229633,
          -3.06348,
          -0.94710547,
          10.322618,
          -3.0970888,
          -3.0870268,
          -4.155443,
          -2.5172067,
          -3.402613
         ],
         "xaxis": "x",
         "y": [
          2.2737803,
          -1.0851719,
          -5.662209,
          -1.3091518,
          0.9151626,
          -0.13123332,
          -1.7646272,
          -1.4213772,
          0.9959077,
          1.189397,
          4.830465,
          3.2005248,
          4.9671865,
          -2.2473722,
          -3.293493,
          -0.47260633,
          2.9814978,
          19.585299,
          2.9568877,
          4.517973,
          2.9053261,
          3.3275542,
          0.2904457,
          -1.830783,
          -2.1665921,
          -6.1303415,
          -1.3204694,
          -4.7934027,
          2.3040714,
          -5.5525374,
          -1.4322311,
          5.3140135,
          -3.9219947,
          -2.0396798,
          2.677579,
          -1.8198819,
          5.036584,
          -0.0028939191,
          2.8907716,
          -1.7747451,
          0.82557416,
          2.1410794,
          0.762814,
          -0.471032,
          0.53366035,
          -0.79715323,
          -1.5859063,
          2.7591653,
          -2.234401,
          -3.5804117,
          -1.7806472,
          1.0103655,
          0.27154586,
          -1.2427727,
          2.8517468,
          2.01526,
          0.96740764,
          1.7539414,
          -2.825635,
          2.1776052,
          -1.8201796,
          19.58438,
          -5.175398,
          -5.0531783,
          -2.1232262,
          2.1005642,
          19.583317,
          2.0367086,
          4.7352524,
          2.047849,
          1.5889738,
          0.89715844,
          19.58425,
          -3.021129,
          -4.7529364,
          -2.4284666,
          -1.1888683,
          -1.5901011,
          -3.2083728,
          -6.0865126,
          1.9561878,
          -4.0122075,
          1.9336152,
          2.7475407,
          3.2814813,
          -3.6350172,
          0.18711807,
          -3.3257177,
          -0.9888377,
          5.109681,
          -1.9099275,
          19.584558,
          -5.94926,
          4.809702,
          -4.0015583,
          2.6258702,
          -3.391788,
          5.3706784,
          -0.3944943,
          -5.7828364,
          -1.94687,
          -0.37258625,
          4.0471487,
          -0.6189854,
          -1.9027157,
          19.582666,
          3.5737429,
          1.8665674,
          -4.719155,
          -2.2571146,
          -0.4896441,
          -2.5572329,
          -3.537515,
          -6.0288367,
          -0.3980587,
          19.584421,
          3.6405551,
          1.7651272,
          1.0391668,
          -1.9229931,
          19.582499,
          3.1675732,
          4.4463954,
          -1.2361484,
          -2.383316,
          4.8176236,
          -1.4643878,
          2.5854812,
          1.7037811,
          -1.3338726,
          19.5853,
          5.751862,
          -5.6499166,
          -1.3937676,
          -1.2585251,
          3.809149,
          3.965141,
          0.92852217,
          -5.0493455,
          3.643148,
          19.580458,
          -5.9984193,
          4.8714256,
          0.22001576,
          19.583855,
          5.262323,
          4.491147,
          -3.9427395,
          0.5487615,
          1.9279113,
          0.21224663,
          -2.4857714,
          -1.324743,
          -1.9573721,
          2.9234707,
          -2.2231412,
          -0.49692416,
          0.47054893,
          -3.8558102,
          -2.9011984,
          -2.159122,
          0.012588009,
          -0.5221001,
          2.8583908,
          -2.3407538,
          -1.0445544,
          19.583448,
          2.0232978,
          4.7065086,
          -1.2235576,
          -3.4914196,
          2.381826,
          0.6198996,
          -2.003784,
          19.583815,
          5.6841784,
          -5.735868,
          2.7179,
          1.0053588,
          -4.7045293,
          -1.985091,
          -5.042055,
          1.621691,
          -5.6416764,
          1.7839674,
          -0.50609744,
          19.580013,
          -4.9898977,
          -4.724376,
          -1.1452657,
          19.583857,
          -3.383826,
          -4.5207906,
          1.127058,
          -2.4108825,
          -1.3850291,
          -3.579312,
          19.584063,
          5.639606,
          4.417421,
          2.1640995,
          4.606534,
          1.582065,
          0.12291486,
          19.583242,
          2.0676346,
          -6.026209,
          -2.9306066,
          5.016347,
          3.570735,
          1.6395372,
          -0.5710061,
          0.03331484,
          -1.8697395,
          19.584356,
          2.1706455,
          -5.9732866,
          0.28127593,
          -0.979419,
          -3.8183217,
          -5.001655,
          1.9393047,
          2.8539112,
          -1.5582689,
          -0.34182274,
          3.3550642,
          2.414501,
          2.795768,
          -3.4687788,
          3.6351192,
          2.3693612,
          0.85511076,
          3.363396,
          0.566425,
          -0.10571732,
          -2.6729577,
          -1.1939296,
          -4.0714107,
          -3.3779635,
          2.8172328,
          2.2899733,
          -2.6464753,
          -0.015671851,
          -1.818757,
          19.584587,
          2.8817954,
          4.6145124,
          -2.2276044,
          -5.3484373,
          4.7979474,
          -0.23867214,
          1.5241141,
          -0.91027635,
          1.4568862,
          0.027613038,
          19.582447,
          3.6904545,
          2.2423434,
          -2.9003038,
          19.623043,
          3.6298,
          2.5057006,
          3.432999,
          0.73607653,
          -0.13898896,
          2.1312807,
          -1.997124,
          19.585012,
          5.26061,
          4.519094,
          -3.886167,
          -2.9201589,
          2.8387806
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "--\ntitle: \"Large Language Models: A New Moore's Law?\"\nthumbnail: /blog/assets/33_large_language_mode..."
          ],
          [
           "### Use Cloud-Based Infrastructure\n\nLike them or not, cloud companies know how to build efficient in..."
          ],
          [
           "--\ntitle: \"Why we’re switching to Hugging Face Inference Endpoints, and maybe you should too\"\nthumbn..."
          ],
          [
           "```\n\nFor me, what’s lacking is a [custom terraform provider](https://www.hashicorp.com/blog/writing-..."
          ],
          [
           "--\ntitle: \"DuckDB: analyze 50,000+ datasets stored on the Hugging Face Hub\" \nthumbnail: /blog/assets..."
          ],
          [
           "--\ntitle: \"Building an AI WebTV\"\nthumbnail: /blog/assets/156_ai_webtv/thumbnail.gif\nauthors:\n- user:..."
          ],
          [
           "```\n\nThere are many different configuration options for FFmpeg, for more information in the [officia..."
          ],
          [
           "<figure class=\"image flex flex-col items-center text-center m-0 w-full\">\n   <video\n      alt=\"demo1...."
          ],
          [
           "--\ntitle: Fine tuning CLIP with Remote Sensing (Satellite) images and captions\nthumbnail: /blog/asse..."
          ],
          [
           "We augmented the text with backtranslation to generate captions for images with less than 5 unique c..."
          ],
          [
           "--\ntitle: \"Multivariate Probabilistic Time Series Forecasting with Informer\" \nthumbnail: /blog/asset..."
          ],
          [
           "In practice, the measurement is defined as:\n\n$$\nM(q_i, K) = \\max_j \\frac{q_ik_j^T}{\\sqrt{d}}-\\frac{1..."
          ],
          [
           "```\nNote that in the implementation, \\\\(U_{part}\\\\) contain \\\\(L_Q\\\\) in the calculation, for stabil..."
          ],
          [
           "```\n\nNow, let's convert the dataset into a multivariate time series using the `MultivariateGrouper` ..."
          ],
          [
           "```\n\nThe transformations below are annotated with comments, to explain what they do. At a high level..."
          ],
          [
           "```\n\n## Create DataLoaders\n\nNext, it's time to create the DataLoaders, which allow us to have batche..."
          ],
          [
           "```\n\n\n```python\nprint(\"Loss:\", outputs.loss.item())\n\n>>> Loss: -1071.5718994140625\n```\n\nNote that th..."
          ],
          [
           "```\n\nFor example:\n\n\n```python\nplot(0, 344)\n```\n\n![png](https://huggingface.co/datasets/huggingface/d..."
          ],
          [
           "--\ntitle: \"Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub\"..."
          ],
          [
           "```\n\nHowever, for some of the datasets on the Hub, we might be keen not to download the whole datase..."
          ],
          [
           "--\ntitle: \"Generating Human-level Text with Contrastive Search in Transformers 🤗\"\nthumbnail: /blog/a..."
          ],
          [
           "```\n</details>\n\n**[Remark]** While nucleus sampling can generate text free of repetitions, the seman..."
          ],
          [
           "```\n</details>\n\n**[Remark]** We see that the generated text is of exceptionally high quality. The en..."
          ],
          [
           "```\n</details>\n\n<span id='gpt2_nucleus_example_one'/>\n\n##### 6.1.2. Generating Text with Nucleus Sam..."
          ],
          [
           "```\n</details>\n\n\n\n<span id='opt_greedy_example_two'/>\n\n##### 6.2.1. Generating Text with Greedy Sear..."
          ],
          [
           "--\ntitle: \"AMD + 🤗: Large Language Models Out-of-the-Box Acceleration with AMD GPU\"\nthumbnail: /blog..."
          ],
          [
           "```\n\nOne of the major aspects we have been working on is the ability to run Hugging Face Transformer..."
          ],
          [
           "<br>\n<figure class=\"image table text-center m-0 w-full\">\n  <img alt=\"\" src=\"assets/optimum_amd/tgi_3..."
          ],
          [
           "--\ntitle: \"Machine Learning Experts - Lewis Tunstall\"\nthumbnail: /blog/assets/60_lewis_tunstall_inte..."
          ],
          [
           "OpenAI actually provided in their blog posts some examples of the essays that this model had created..."
          ],
          [
           "Well, that's the aim but it turns out that many of these transformer models are really good at takin..."
          ],
          [
           "One podcast that really stands out recently is actually the [DeepMind podcast](https://www.deepmind...."
          ],
          [
           "### So glad you got that one in there. Well done! Look forward to many more in the next edition. Tha..."
          ],
          [
           "--\ntitle: 'Welcome fastai to the Hugging Face Hub'\nthumbnail: /blog/assets/64_fastai/fastai_hf_blog...."
          ],
          [
           "```\n\n3. Use the `token` argument of the `push_to_hub_fastai` function.\n\nYou can input `push_to_hub_f..."
          ],
          [
           "--\ntitle: \"StackLLaMA: A hands-on guide to train LLaMA with RLHF\" \nthumbnail: /blog/assets/138_stack..."
          ],
          [
           "```\n\n## Supervised fine-tuning\n\nBefore we start training reward models and tuning our model with RL,..."
          ],
          [
           "```\n\nThe same template was used for SFT, RM and RLHF stages.\n\nA common issue with training the langu..."
          ],
          [
           "```\n\nWe train for 20 hours on 3x8 A100-80GB GPUs, using the 🤗 research cluster, but you can also get..."
          ],
          [
           "--\ntitle:  Deploy LLMs with Hugging Face Inference Endpoints\nthumbnail: /blog/assets/155_inference_e..."
          ],
          [
           "```\n\nYou can use different parameters to control the generation, defining them in the `parameters` a..."
          ],
          [
           "--\ntitle: \"2D Asset Generation: AI for Game Development #4\"\nthumbnail: /blog/assets/124_ml-for-games..."
          ],
          [
           "--\ntitle: \"Supercharged Customer Service with Machine Learning\"\nthumbnail: /blog/assets/61_superchar..."
          ],
          [
           "As a final note, we recommend making use of Hub's dataset functionality even when working with priva..."
          ],
          [
           "```\n\nAlso, we install the 🤗 Transformers and 🤗 Datasets libraries to run this notebook. Since we wil..."
          ],
          [
           "```\n\n\n\nWe can see that the outer layer of the structure stayed the same but the naming of the column..."
          ],
          [
           "```\n\n\nThe trainer is ready to go 🚀 You can start training by calling `trainer.train()`.\n\n\n```python\n..."
          ],
          [
           "```\n\n\nWe again instantiate the `Trainer` to easily run the evaluation.\n\n\n```python\ntrainer = Trainer..."
          ],
          [
           "--\ntitle: \"Accelerating Document AI\" \nthumbnail: /blog/assets/112_document-ai/thumbnail.png\nauthors:..."
          ],
          [
           "<html itemscope itemtype=\"https://schema.org/FAQPage\">\n  <div itemscope itemprop=\"mainEntity\" itemty..."
          ],
          [
           "<html itemscope itemtype=\"https://schema.org/FAQPage\">\n  <div itemscope itemprop=\"mainEntity\" itemty..."
          ],
          [
           "Notebooks and tutorials for many Document AI models can be found at: \n- Niels' [Transformers-Tutoria..."
          ],
          [
           "--\ntitle: \"How we sped up transformer inference 100x for 🤗 API customers\"\nthumbnail: /blog/assets/09..."
          ],
          [
           "--\ntitle: \"Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chine..."
          ],
          [
           "--\ntitle: \"How to generate text: using different decoding methods for language generation with Trans..."
          ],
          [
           "```\n\n```\nOutput:\n-----------------------------------------------------------------------------------..."
          ],
          [
           "```\n\n```\nOutput:\n-----------------------------------------------------------------------------------..."
          ],
          [
           "```\n\n```\nOutput:\n-----------------------------------------------------------------------------------..."
          ],
          [
           "--\ntitle: \"Accelerate your models with 🤗 Optimum Intel and OpenVINO\"\nthumbnail: /blog/assets/113_ope..."
          ],
          [
           "```\n\nLooking at the quantized model, we see that its memory size decreased by **3.8x** from 344MB to..."
          ],
          [
           "--\ntitle: Guiding Text Generation with Constrained Beam Search in 🤗 Transformers\nthumbnail: /blog/as..."
          ],
          [
           "```\n\n    Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n    Output:\n    -..."
          ],
          [
           "```\n\n    Output:\n    -------------------------------------------------------------------------------..."
          ],
          [
           "--\ntitle: \"Making a web app generator with open ML models\"\nthumbnail: /blog/assets/153_text_to_webap..."
          ],
          [
           "```\n\nStart your web server:\n\n```bash\nnpm run start\n```\n\nand open `https://localhost:3000?prompt=some..."
          ],
          [
           "--\ntitle: 'Liftoff! How to get started with your first ML project 🚀'\nthumbnail: /blog/assets/84_firs..."
          ],
          [
           "On top of it all, it’s also supported with a ton of [Hugging Face integrations](https://huggingface...."
          ],
          [
           "--\ntitle: \"Fit More and Train Faster With ZeRO via DeepSpeed and FairScale\"\nthumbnail: /blog/assets/..."
          ],
          [
           "```\n\nNote, as earlier I'm showing only the important parts and the full command line arguments can b..."
          ],
          [
           "```\nRuntimeError: CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 23.65 GiB total capacity;\n1..."
          ],
          [
           "--\ntitle: \"Ethics and Society Newsletter #1\" \nthumbnail: /blog/assets/103_ethics-soc-1/thumbnail.png..."
          ],
          [
           "--\ntitle: \"Open LLM Leaderboard: DROP deep dive\"\nthumbnail: /blog/assets/evaluating-mmlu-leaderboard..."
          ],
          [
           "## Changing the end of generation token\nSo we gave it a try! We investigated using `\\n` as the end o..."
          ],
          [
           "--\ntitle: \"Evaluating Language Model Bias with 🤗 Evaluate\"\nthumbnail: /blog/assets/112_evaluating-ll..."
          ],
          [
           "```\n\nAnd as before, we use GPT-2 to generate completions:\n```python\n>>> profession1_completions = [\"..."
          ],
          [
           "--\ntitle: \"Can foundation models label data like humans?\"\nthumbnail: /blog/assets/llm-leaderboard/le..."
          ],
          [
           "In this blog, we show the bootstrapped Elo estimates along with error estimates. Here are the rankin..."
          ],
          [
           "```\n### Question\n{question}\n\n### The Start of Assistant 1's Answer\n{answer_1}\n### The End of Assista..."
          ],
          [
           "```\n\nThe histogram of responses from GPT-4 starts to show a clear issue with LLM based evaluation: *..."
          ],
          [
           "**Human response:**\n\nrelevant\n\n**GPT-4 rating: 5** (model slightly better)\n\nBoth assistants provided..."
          ],
          [
           "```\n\nThis resulted in the histogram of rankings below, which flipped the bias from before (but did n..."
          ],
          [
           "--\ntitle: \"Student Ambassador Program’s call for applications is open!\"\nthumbnail: /blog/assets/67_a..."
          ],
          [
           "--\ntitle: \"Training a language model with 🤗 Transformers using TensorFlow and TPUs\"\nthumbnail: /blog..."
          ],
          [
           "We then take these tokenized samples in batches and serialize those batches as multiple TFRecord sha..."
          ],
          [
           "```\n\nBut since we’re in the TPU territory, we need to perform this initialization under a strategy s..."
          ],
          [
           "--\ntitle: \"A Dive into Vision-Language Models\"\nthumbnail: /blog//assets/128_vision_language_pretrain..."
          ],
          [
           "For CLIP, the distance is simply the cosine distance between the text and image embeddings, whereas ..."
          ],
          [
           "### 4) Masked-Language Modeling / Image-Text Matching\n\nAnother line of vision-language models uses a..."
          ],
          [
           "Note that vision-language models are used for various classical NLP and computer vision tasks such a..."
          ],
          [
           "```\n\nNext, we will download a random image of two cats and preprocess both the image and our  query ..."
          ],
          [
           "```\n\nLet’s visualize the results to see how well CLIPSeg performed (code is adapted from [this post]..."
          ],
          [
           "--\ntitle: \"Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Dis..."
          ],
          [
           "```\n\n## Data preparation\n### Data loading\n\nWe will load the dataset from Hugging Face:\n```python\nfro..."
          ],
          [
           "```\n\n- Llama 2:\n```python\n# Load Llama 2 Tokenizer\nfrom transformers import AutoTokenizer, DataColla..."
          ],
          [
           "```\n\n\n### Trainer Setup\n\nLet's set the training arguments and the trainer for the three models.\n\n###..."
          ],
          [
           "--\ntitle: \"Introducing DOI: the Digital Object Identifier to Datasets and Models\"\nthumbnail: /blog/a..."
          ],
          [
           "--\ntitle: \"Accelerating PyTorch Transformers with Intel Sapphire Rapids - part 1\"\nthumbnail: /blog/a..."
          ],
          [
           "```\n\nNext, we create a new ssh key pair called 'cluster' with `ssh-keygen` and store it at the defau..."
          ],
          [
           "--\ntitle: Introducing our new pricing\nthumbnail: /blog/assets/114_pricing-update/thumbnail.png\nautho..."
          ],
          [
           "--\ntitle: Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac\nthumbnail: /blog/assets/149_..."
          ],
          [
           "<br>\n<div style=\"background-color: #f0fcf0; padding: 8px 32px 1px; outline: 1px solid; border-radius..."
          ],
          [
           "```\n\n## Converting and Optimizing Custom Models\n\nIf you want to use a personalized Stable Diffusion ..."
          ],
          [
           "his notebook shows how to deploy a vision model from 🤗 Transformers (written in TensorFlow) to [Vert..."
          ],
          [
           "```\n\n## Make a prediction request\n\n\n```python\n# Generate sample data. \nimport base64\n\nimage_path = t..."
          ],
          [
           "--\ntitle: \"Retrieval Augmented Generation with Huggingface Transformers and Ray\"\nthumbnail: /blog/as..."
          ],
          [
           "```\n\n\nThen, you can specify your data paths and other configurations and run [finetune-rag-ray.sh](h..."
          ],
          [
           "--\ntitle: Introducing Pull Requests and Discussions 🥳\nthumbnail: /blog/assets/76_community_update/th..."
          ],
          [
           "--\ntitle: \"Introducing Agents.js: Give tools to your LLMs using JavaScript\"\nthumbnail: /blog/assets/..."
          ],
          [
           "--\ntitle: \"Using Machine Learning to Aid Survivors and Race through Time\" \nthumbnail: /blog/assets/u..."
          ],
          [
           "We wanted our NER model to be evaluated and crowd-sourced the effort because the data labelers were ..."
          ],
          [
           "--\ntitle: \"Accelerating PyTorch Transformers with Intel Sapphire Rapids - part 2\"\nthumbnail: /blog/a..."
          ],
          [
           "```\n\nOn the r7iz (Sapphire Rapids) instance, we use both a vanilla pipeline and an Optimum pipeline...."
          ],
          [
           "--\ntitle: Getting Started with Hugging Face Inference Endpoints\nthumbnail: /blog/assets/109_inferenc..."
          ],
          [
           "```\n\nNow, let's increase our security level and deploy a private endpoint.\n \n### Deploying a Private..."
          ],
          [
           "--\ntitle: \"Non-engineers guide: Train a LLaMA 2 chatbot\"\nthumbnail: /blog/assets/78_ml_director_insi..."
          ],
          [
           "2.7 Similarly you can configure the training parameters in “Parameter Choice” but for now let’s use ..."
          ],
          [
           "--\ntitle: \"Ethical Guidelines for developing the Diffusers library\" \nthumbnail: /blog/assets/ethics-..."
          ],
          [
           "--\ntitle: \"Introducing BERTopic Integration with the Hugging Face Hub\"\nthumbnail: /blog/assets/145_b..."
          ],
          [
           "```\n\nBy leveraging the power of the Hugging Face Hub, BERTopic users can effortlessly share, version..."
          ],
          [
           "<details>\n  <summary>Click here for an overview of all topics.</summary>\n  \n  | Topic ID | Topic Key..."
          ],
          [
           "| 58 | agreement - syntactic - verb - grammatical - subject verb | 85 | 58_agreement_syntactic_verb_..."
          ],
          [
           "Due to the improved saving procedure, training on large datasets generates small model sizes. In the..."
          ],
          [
           "```\n\nWe can predict on a single example text: \n\n```python\nexample = \"Stalemate is a drawn position. ..."
          ],
          [
           "--\ntitle: \"OpenRAIL: Towards open and responsible AI licensing frameworks\"\nthumbnail: /blog/assets/1..."
          ],
          [
           "And even before thinking about enforcement, use-based restriction clauses might act as a deterrent f..."
          ],
          [
           "--\ntitle: Using LoRA for Efficient Stable Diffusion Fine-Tuning\nthumbnail: /blog/assets/lora/thumbna..."
          ],
          [
           "```\n\nOne thing of notice is that the learning rate is `1e-4`, much larger than the usual learning ra..."
          ],
          [
           "--\ntitle: \"Graph Classification with Transformers\" \nthumbnail: /blog/assets/125_intro-to-graphml/thu..."
          ],
          [
           "```\nLet's look at this in more detail. \n\nCalling the `from_pretrained` method on our model downloads..."
          ],
          [
           "--\ntitle: Fine-Tune a Semantic Segmentation Model with a Custom Dataset\nthumbnail: /blog/assets/56_f..."
          ],
          [
           "```\n\n# 1. Create/choose a dataset\n\nThe first step in any ML project is assembling a good dataset. In..."
          ],
          [
           "```\n\nWe can now push the transformed dataset to the Hugging Face Hub. That way, your team and the Hu..."
          ],
          [
           "```\n\nFinally, we can instantiate a `Trainer` object.\n\n\n```python\nfrom transformers import Trainer\n\nt..."
          ],
          [
           "--\ntitle: \"Efficient Controllable Generation for SDXL with T2I-Adapters\"\nthumbnail: /blog/assets/t2i..."
          ],
          [
           "```\n\n![Lineart Dragon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main..."
          ],
          [
           "--\ntitle: \"Introduction to Graph Machine Learning\" \nthumbnail: /blog/assets/125_intro-to-graphml/thu..."
          ],
          [
           "Note: *In the following sections, we will focus on generating node representations. \nOnce you have n..."
          ],
          [
           "If your network has too many layers, there is a risk that each node becomes an aggregation of the fu..."
          ],
          [
           "--\ntitle: \"Transformer-based Encoder-Decoder Models\"\nthumbnail: /blog/assets/05_encoder_decoder/thum..."
          ],
          [
           "```\n\nThe *transformer-based* encoder-decoder model was introduced by Vaswani\net al. in the famous [A..."
          ],
          [
           "For more detail on the logit vector and the resulting probability\ndistribution, please see footnote ..."
          ],
          [
           "------------------------------------------------------------------------\n\n\\\\({}^1\\\\) The original qu..."
          ],
          [
           "To begin with, the encoder processes the complete input sequence\n\\\\(\\mathbf{X}_{1:7}\\\\) = \\\"I want t..."
          ],
          [
           "```\n\n_Output:_\n\n```\n    <pad> Ich will ein Auto kaufen..."
          ],
          [
           "```\n\nCalling `.generate()` does many things under-the-hood. First, it passes\nthe `input_ids` to the ..."
          ],
          [
           "Alright, this sounds quite complicated. Let\\'s illustrate the\nbi-directional self-attention layer fo..."
          ],
          [
           "```\n\n_Outputs:_\n```\n    Length of input embeddings 7. Length of encoder_hidden_states 7\n    Is encod..."
          ],
          [
           "```\n\nWe compare the length of the input word embeddings, *i.e.*\n`embeddings(input_ids)` correspondin..."
          ],
          [
           "Applying a softmax operation on each\n\\\\(\\mathbf{l}_1, \\mathbf{l}_2, \\ldots, \\mathbf{l}_5\\\\) can thus..."
          ],
          [
           "So intuitively, what happens here exactly? Each output vector\n\\\\(\\mathbf{y'''}_i\\\\) is a weighted su..."
          ],
          [
           "```\n\n_Output:_\n\n```\n    Shape of decoder input vectors torch.Size([1, 5, 512]). Shape of decoder log..."
          ],
          [
           "--\ntitle: Block Sparse Matrices for Smaller and Faster Language Models\nthumbnail: /blog/assets/04_py..."
          ],
          [
           "--\ntitle: \"Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)\"\nthumbnail: /b..."
          ],
          [
           "For an input series \\\\(\\mathcal{X} \\in \\mathbb{R}^{L \\times d}\\\\) with length \\\\(L\\\\), the decomposi..."
          ],
          [
           "```\n\nAs you can see, the implementation is quite simple and can be used in other models, as we will ..."
          ],
          [
           "```\n\nWe did it! The Autoformer model is [now available](https://huggingface.co/docs/transformers/mai..."
          ],
          [
           "```\n\nLet's visualize a time series in the dataset and plot the train/test split:\n\n```python\nimport m..."
          ],
          [
           "```\n\n## Create PyTorch DataLoaders\n\nNext, it's time to create PyTorch DataLoaders, which allow us to..."
          ],
          [
           "```\n\nSo the result for the Autoformer model is:\n\n```python\nprint(f\"Autoformer univariate MASE: {np.m..."
          ],
          [
           "--\ntitle: \"Image search with 🤗 datasets\"\nthumbnail: /blog/assets/54_image_search_datasets/spaces_ima..."
          ],
          [
           "```..."
          ],
          [
           "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',..."
          ],
          [
           "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; t..."
          ],
          [
           "We can see there a few different ways in which we can pass in our images. We'll come back to this in..."
          ],
          [
           "```\n\nLet's see what we get back.\n\n```python\ndataset\n```\n\n```\nDatasetDict({\n    train: Dataset({\n    ..."
          ],
          [
           "```\n\n## Image search\n\n> **Note** that these examples were generated from the full version of the dat..."
          ],
          [
           "--\ntitle: \"Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Langage Model\"\nthumb..."
          ],
          [
           "# We feed to the model an arbitrary sequence of text strings and images. Images can be either URLs o..."
          ],
          [
           "```..."
          ],
          [
           "--\ntitle: \"Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers\"\nthumbnail: /blog/..."
          ],
          [
           "Developers can now use Graphcore systems to train 10 different types of state-of-the-art transformer..."
          ],
          [
           "--\ntitle: \"Showcase Your Projects in Spaces using Gradio\"\nthumbnail: /blog/assets/28_gradio-spaces/t..."
          ],
          [
           "Some Notes on Pros of Open Science and Open Source\n- **Pooling Resources**: Building off of one anot..."
          ],
          [
           "--\ntitle: \"We are hiring interns!\"\nthumbnail: /blog/assets/interns-2023/thumbnail.png\nauthors:\n- use..."
          ],
          [
           "--\ntitle: \"Announcing the Open Source AI Game Jam 🎮\"\nthumbnail: /blog/assets/145_gamejam/thumbnail.p..."
          ],
          [
           "--\ntitle: \"Ethics and Society Newsletter #3: Ethical Openness at Hugging Face\" \nthumbnail: /blog/ass..."
          ],
          [
           "In prioritizing open science, we examine potential harm on a case-by-case basis and provide an oppor..."
          ],
          [
           "```\n@misc{hf_ethics_soc_blog_3,\n  author    = {Irene Solaiman and\n               Giada Pistilli and\n..."
          ],
          [
           "--\ntitle: \"Deep Learning over the Internet: Training Language Models Collaboratively\"\nthumbnail: /bl..."
          ],
          [
           "Because All-Reduce is decentralized, it seems like a good choice; however, we still need to take the..."
          ],
          [
           "```\n\n### Dataset\n\nThe last thing we need to cover is the training dataset. As you probably know, the..."
          ],
          [
           "```\n\n#### sahajBERT-NCC\nModel card: [https://hf.co/neuropark/sahajBERT-NER](https://hf.co/neuropark/..."
          ],
          [
           "--\ntitle: \"Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate\"\nthumbnail: /blog/assets/bl..."
          ],
          [
           "```\npip install transformers>=4.21.3 accelerate>=0.12.0\n```\n\n\n### Run\n\nThe simple execution is:\n\n```..."
          ],
          [
           "--\ntitle: \"Summer at Hugging Face\"\nthumbnail: /blog/assets/27_summer_at_huggingface/summer_intro.gif..."
          ],
          [
           "There were talks around JAX/Flax, Transformers, large-scale language modeling, and more! You can fin..."
          ],
          [
           "```\n\nThe last 4 releases introduced many new cool models!\n\n- [DETR](https://huggingface.co/transform..."
          ],
          [
           "### **NEW: Inference on SageMaker**\n\nWe launched a [new integration with AWS](https://huggingface.co..."
          ],
          [
           "--\ntitle: \"Model Cards\" \nthumbnail: /blog/assets/121_model-cards/thumbnail.png\nauthors:\n- user: Ezi\n..."
          ],
          [
           "We continue to learn more about how model cards are created and used, and the effect of cards on mod..."
          ],
          [
           "--\ntitle: \"Introducing RWKV - An RNN with the advantages of a transformer\" \nthumbnail: /blog/assets/..."
          ],
          [
           "The major drawbacks of traditional RNN models and how RWKV is different:\n\n1. Traditional RNN models ..."
          ],
          [
           "```\n\nOr you can run and start from the snippet below:\n\n```python\nimport torch\nfrom transformers impo..."
          ],
          [
           "--\ntitle: Stable Diffusion with 🧨 Diffusers\nthumbnail: /blog/assets/98_stable_diffusion/thumbnail.pn..."
          ],
          [
           "```\n\n![png](assets/98_stable_diffusion/stable_diffusion_16_1.png)\n\nNote how the structure is the sam..."
          ],
          [
           "```\n\n![png](assets/98_stable_diffusion/stable_diffusion_26_1.png)\n    \n\n## How does Stable Diffusion..."
          ],
          [
           "After this brief introduction to Latent and Stable Diffusion, let's see how to make advanced use of ..."
          ],
          [
           "```\n\nNow instead of loading the pre-defined scheduler, we load the [K-LMS scheduler](https://github...."
          ],
          [
           "--\ntitle: 'Deploy Hugging Face models easily with Amazon SageMaker'\nthumbnail: /blog/assets/17_the_p..."
          ],
          [
           "```\n\n\nTo deploy a model on SageMaker, we need to create a `sagemaker` Session and provide an IAM rol..."
          ],
          [
           "```\n\nAfter we run our request we can delete the endpoint again with.\n\n\n```python\n# delete endpoint\np..."
          ],
          [
           "--\ntitle: \"Introducing Prodigy-HF: a direct integration with Hugging Face\"\nthumbnail: /blog/assets/1..."
          ],
          [
           "--\ntitle: \"How to Install and Use the Hugging Face Unity API\"\nthumbnail: /blog/assets/124_ml-for-gam..."
          ],
          [
           "--\ntitle: \"Proximal Policy Optimization (PPO)\"\nthumbnail: /blog/assets/93_deep_rl_ppo/thumbnail.png\n..."
          ],
          [
           "This ratio **can replace the log probability we use in the policy objective function**. This gives u..."
          ],
          [
           "The final Clipped Surrogate Objective Loss for PPO Actor-Critic style looks like this, it's a combin..."
          ],
          [
           "--\ntitle: \"Very Large Language Models and How to Evaluate Them\" \nthumbnail: /blog/assets/106_zero_sh..."
          ],
          [
           "--\ntitle: Training Stable Diffusion with Dreambooth using Diffusers\nthumbnail: /blog/assets/sd_dream..."
          ],
          [
           "* High learning rates and too many training steps will lead to overfitting. The model will mostly ge..."
          ],
          [
           "--\ntitle: 'Faster Text Generation with TensorFlow and XLA'\nthumbnail: /blog/assets/91_tf_xla_generat..."
          ],
          [
           "```\n\nFinally, when running Sampling or Beam Search, you can use `num_return_sequences` to return sev..."
          ],
          [
           "```\n\nIn practice, for text generation, it simply means the input should be padded to a multiple of a..."
          ],
          [
           "--\ntitle: \"Perceiver IO: a scalable, fully-attentional model that works on any modality\"\nthumbnail: ..."
          ],
          [
           "``` python\nfrom transformers import PerceiverTokenizer\n\ntokenizer = PerceiverTokenizer.from_pretrain..."
          ],
          [
           "```\n\nIn this case, one provides `PerceiverTextPreprocessor` as preprocessor to the model, which will..."
          ],
          [
           "```\n\nOne can see that `PerceiverImagePreprocessor` is initialized with `prep_type = \"conv1x1\"` and t..."
          ],
          [
           "```\nAs one can see, `PerceiverImagePreprocessor` is used as preprocessor (i.e. to prepare the 2 imag..."
          ],
          [
           "Similarly to the preprocessor, `PerceiverMultimodalDecoder` pads the different modalities to the sam..."
          ],
          [
           "--\ntitle: \"Train a Sentence Embedding Model with 1B Training Pairs\"\nauthors:\n- user: asi\n  guest: tr..."
          ],
          [
           "As mentioned earlier, the quantity of data and the batch size directly impact the model performances..."
          ],
          [
           "--\ntitle: \"Large-scale Near-deduplication Behind BigCode\"\nthumbnail: /blog/assets/dedup/thumbnail.pn..."
          ],
          [
           "This is the one for code datasets we created for BigCode as well. Model names are used when the data..."
          ],
          [
           "```\n\nIf you are familiar with [Datasketch](https://github.com/ekzhu/datasketch), you might ask, why ..."
          ],
          [
           "```\n\nAdditionally, thanks to cloud providers, we can set up Spark clusters like a breeze with servic..."
          ],
          [
           "Huge thanks to Huu Nguyen @Huu and Hugo Laurençon @HugoLaurencon for the collaboration in BigScience..."
          ],
          [
           "--\ntitle: 'Getting Started With Embeddings'\nthumbnail: /blog/assets/80_getting_started_with_embeddin..."
          ],
          [
           "```\n\nAs a response, you get back a list of lists. Each list contains the embedding of a FAQ. The mod..."
          ],
          [
           "--\ntitle: Getting Started with Transformers on Habana Gaudi\nthumbnail: /blog/assets/61_getting_start..."
          ],
          [
           "```\n***** train metrics *****\n  epoch                    =        3.0\n  train_loss               =  ..."
          ],
          [
           "--\ntitle: \"Personal Copilot: Train Your Own Coding Assistant\" \nthumbnail: /blog/assets/170_personal_..."
          ],
          [
           "In the above calculations, we didn't consider memory required for intermediate activation checkpoint..."
          ],
          [
           "```\naccelerate launch --config_file \"configs/fsdp_config.yaml\"  train.py \\\n    --model_path \"bigcode..."
          ],
          [
           "```\n\nThe total training time was **9 Hours**. Taking the cost of $12.00 / hr based on [lambdalabs](h..."
          ],
          [
           "![vs_code_endpoint](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bl..."
          ],
          [
           "![octocoder_chat_hf](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/b..."
          ],
          [
           "```\ngit clone --recursive https://github.com/pacman100/mlc-llm.git && cd mlc-llm/\n```\n\n2. Install th..."
          ],
          [
           "--\ntitle: \"Hugging Face on PyTorch / XLA TPUs\"\nthumbnail: /blog/assets/13_pytorch_xla/pytorch_xla_th..."
          ],
          [
           "```\n\n```python\nclass Trainer:\n…\n   def train(self, *args, **kwargs):\n       ...\n       if is_torch_t..."
          ],
          [
           "```\n\nThe above should complete training in roughly less than 200 minutes with an eval perplexity of ..."
          ],
          [
           "--\ntitle: Deploying TensorFlow Vision Models in Hugging Face with TF Serving\nthumbnail: /blog/assets..."
          ],
          [
           "```\n\n**Note on making the model accept string inputs**:\n\nWhen dealing with images via REST or gRPC r..."
          ],
          [
           "```\n\n```bash\noutputs {\n  key: \"confidence\"\n  value {\n    dtype: DT_FLOAT\n    tensor_shape {\n      di..."
          ],
          [
           "--\ntitle: \"Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU\" \nthumbnail: assets/133_trl_peft/th..."
          ],
          [
           "### 8-bit matrix multiplication\n\nEfficient 8-bit matrix multiplication is a method that has been fir..."
          ],
          [
           "The first step in the training process was fine-tuning on the pretrained model. Typically this would..."
          ],
          [
           "--\ntitle: \"Sentiment Analysis on Encrypted Data with Homomorphic Encryption\"\nthumbnail: /blog/assets..."
          ],
          [
           "```\n\n```python\n# Let's vectorize the text using the transformer\nlist_text_X_train = text_X_train.tol..."
          ],
          [
           "--\ntitle: \"How to host a Unity game in a Space\"\nthumbnail: /blog/assets/124_ml-for-games/unity-in-sp..."
          ],
          [
           "--\ntitle: \"Llama 2 on Amazon SageMaker a Benchmark\" \nthumbnail: /blog/assets/llama_sagemaker_benchma..."
          ],
          [
           "### Best Throughput Deployment\n\nThe Best Throughput configuration maximizes the number of tokens tha..."
          ],
          [
           "--\ntitle: \"Announcing Evaluation on the Hub\"\nthumbnail: /blog/assets/82_eval_on_the_hub/thumbnail.pn..."
          ],
          [
           "Clicking on the <em>Advanced configuration</em> button will show you the various settings to choose ..."
          ],
          [
           "--\ntitle: \"Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models\"\nthumbnail: ..."
          ],
          [
           "### **BERT**\n\nBERT is an *encoder-only* model, which maps an input sequence\n\\\\(\\mathbf{X}_{1:n}\\\\) t..."
          ],
          [
           "Now, we know that freely available checkpoints of large pre-trained\n*stand-alone* encoder and decode..."
          ],
          [
           "Before fine-tuning, the encoder therefore behaves exactly like a\npre-trained BERT model. Assuming th..."
          ],
          [
           "$$ \\mathbf{W}^{\\text{self-attn}, 3}_{k} = \\mathbf{W}^{\\text{self-attn}, 3}_{\\text{enc}, k} \\equiv \\m..."
          ],
          [
           "Depending on the task, a slightly different training regime was used.\n*E.g.* according to the size o..."
          ],
          [
           "Again, we observe a significant performance boost by warm-starting the\nencoder-part, with *BERT2Rnd*..."
          ],
          [
           "-   Next, we noticed that it is often beneficial to share encoder and\n    decoder weights, especiall..."
          ],
          [
           "```\nLet's start by downloading the *CNN/Dailymail* dataset.\n\n```python\nimport datasets\ntrain_data = ..."
          ],
          [
           "```..."
          ],
          [
           "```python\nOUTPUT:\n-------\nArticle:..."
          ],
          [
           "\"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military..."
          ],
          [
           "of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans....."
          ],
          [
           "Summary:\n\"\"\"Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nO..."
          ],
          [
           "```\n\nThe input data seems to consist of short news articles. Interestingly,\nthe labels appear to be ..."
          ],
          [
           "```\n\nAwesome, the data processing of the training data is finished.\nAnalogous, we can do the same fo..."
          ],
          [
           "```\n\n```python\nOUTPUT:\n-------\n\"\"\"Some weights of the model checkpoint at bert-base-uncased were not..."
          ],
          [
           "```\n\nFor once, we should take a good look at the warning here. We can see\nthat two weights correspon..."
          ],
          [
           "```\n\n```python\nOUTPUT:\n-------\n    EncoderDecoderModel(\n      (encoder): BertModel(\n        (embeddi..."
          ],
          [
           "```\n\nWe see that `bert2bert.encoder` is an instance of `BertModel` and that\n`bert2bert.decoder` one ..."
          ],
          [
           "```\n\nNext, let\\'s define all parameters related to beam search decoding.\nSince `bart-large-cnn` yiel..."
          ],
          [
           "```\n\nLet\\'s run the map function to obtain the *results* dictionary that has\nthe model\\'s predicted ..."
          ],
          [
           "--\ntitle: \"Introducing Hugging Face for Education 🤗\"\nthumbnail: /blog/assets/61_education/thumbnail...."
          ],
          [
           "--\ntitle: \"How Hugging Face Accelerated Development of Witty Works Writing Assistant\"\nthumbnail: /bl..."
          ],
          [
           "```\n  \n### **Results and conclusion**\nThe number of training sentences dropped from 100-200 per word..."
          ],
          [
           "--\ntitle: Inference for PROs\nthumbnail: /blog/assets/inference_pro/thumbnail.png\nauthors:\n  - user: ..."
          ],
          [
           "```\n\nFor more details on the generation parameters, please take a look at [_Controlling Text Generat..."
          ],
          [
           "```\n\nAs you can see, the format used for infilling follows this pattern:\n\n```\nprompt = f\"<PRE> {prom..."
          ],
          [
           "--\ntitle: \"Towards Encrypted Large Language Models with FHE\" \nthumbnail: /blog/assets/encrypted-llm/..."
          ],
          [
           "```\n\nThe forward pass is then overwritten so that the first head of the multi-head attention mechani..."
          ],
          [
           "--\ntitle: \"Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny\"\nthumbnail:..."
          ],
          [
           "```\n\n## Speed in terms of inference latency\n\nWe have observed that distilled models are up to 100% f..."
          ],
          [
           "--\ntitle: \"The Hugging Face Hub for Galleries, Libraries, Archives and Museums\"\nthumbnail: /blog/ass..."
          ],
          [
           "### Create a new dataset repository \n\nThe first step to uploading a dataset to the Hub is to create ..."
          ],
          [
           "<html>\n<iframe\n\tsrc=\"https://smithsonian-amazonian-fish-classifier.hf.space\"\n\tframeborder=\"0\"\n\twidth..."
          ],
          [
           "--\ntitle: \"Putting ethical principles at the core of the research lifecycle\"\nthumbnail: /blog/assets..."
          ],
          [
           "--\ntitle: \"StarCoder: A State-of-the-Art LLM for Code\" \nthumbnail: /blog/assets/141_starcoder/starco..."
          ],
          [
           "--\ntitle: \"Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 M..."
          ],
          [
           "In keeping with our core value of *democratization*, we have also spent a lot of time speaking publi..."
          ],
          [
           "Of course, we have also made progress on our regular work (our “work work”). The fundamental value o..."
          ],
          [
           "--\ntitle: 'Convert Transformers to ONNX with Hugging Face Optimum'\nthumbnail: /blog/assets/81_conver..."
          ],
          [
           "```\n\n### Export with `transformers.onnx`  (mid-level)\n\n[transformers.onnx](https://huggingface.co/do..."
          ],
          [
           "--\ntitle: \"Comments on U.S. National AI Research Resource Interim Report\"\nthumbnail: /blog/assets/92..."
          ],
          [
           "--\ntitle: \"3D Asset Generation: AI for Game Development #3\"\nthumbnail: /blog/assets/124_ml-for-games..."
          ],
          [
           "--\ntitle: \"Opinion Classification with Kili and HuggingFace AutoTrain\"\nthumbnail: /blog/assets/59_op..."
          ],
          [
           "```\n\nIn order to access the platform, we need to authenticate our client\n\n```python\nAPI_KEY = os.get..."
          ],
          [
           "```\n\n## Labeling\n\nNow that we have the source data uploaded, the platform has a built-in labeling in..."
          ],
          [
           "```\n\nNice! We now have the labeled data as a csv file. Let's create a dataset repository in HuggingF..."
          ],
          [
           "```\n\nAfter defining metric calculation and model initialization function, we can load the data:\n\n```..."
          ],
          [
           "--\ntitle: \"AI for Game Development: Creating a Farming Game in 5 Days. Part 2\"\nthumbnail: /blog/asse..."
          ],
          [
           "--\ntitle: How to train a new language model from scratch using Transformers and Tokenizers\nthumbnail..."
          ],
          [
           "```\n\n## 3. Train a language model from scratch\n\n**Update:** The associated Colab notebook uses our n..."
          ],
          [
           "```\n\n**Looks like it worked! 🔥**\n\n<small>For a more challenging dataset for NER, <a href=\"https://gi..."
          ],
          [
           "--\ntitle: \"Using & Mixing Hugging Face Models with Gradio 2.0\"\nthumbnail: /blog/assets/22_gradio/gra..."
          ],
          [
           "--\ntitle: \"Hugging Face and Graphcore partner for IPU-optimized Transformers\"\nthumbnail: /blog/asset..."
          ],
          [
           "--\ntitle: \"AudioLDM 2, but faster ⚡️\" \nthumbnail: /blog/assets/161_audioldm2/thumbnail.png\nauthors:\n..."
          ],
          [
           "```\n**Output:**\n```\nLoading pipeline components...: 100%|███████████████████████████████████████████..."
          ],
          [
           "```\n\n**Output:**\n```\n100%|███████████████████████████████████████████| 200/200 [01:23<00:00,  2.39it..."
          ],
          [
           "```\n\nUnless you have a GPU with high RAM, the code above probably returned an OOM error. While the A..."
          ],
          [
           "--\ntitle: \"Accelerating Stable Diffusion Inference on Intel CPUs\"\nthumbnail: /blog/assets/136_stable..."
          ],
          [
           "```\n\nNext, we install the `libiomp` library to optimize parallel processing. It's part of [Intel Ope..."
          ],
          [
           "--\ntitle: \"A Complete Guide to Audio Datasets\" \nthumbnail: /blog/assets/116_audio_datasets/thumbnail..."
          ],
          [
           "```\n\nWe can see that there are a number of features returned by the training split, including `segme..."
          ],
          [
           "```\n\nWe can apply this filtering function to all of our training examples using 🤗 Datasets' [`filter..."
          ],
          [
           "```\n\nAll the steps covered so far in this tutorial can be applied to the streaming dataset without a..."
          ],
          [
           "```\n\n#### [GigaSpeech](https://huggingface.co/datasets/speechcolab/gigaspeech)\nGigaSpeech is a multi..."
          ],
          [
           "```\n\n#### [AMI](https://huggingface.co/datasets/edinburghcstr/ami)\nAMI comprises 100 hours of meetin..."
          ],
          [
           "--\ntitle: The Annotated Diffusion Model\nthumbnail: /blog/assets/78_annotated-diffusion/thumbnail.png..."
          ],
          [
           "```\n\n## What is a diffusion model?\n\nA (denoising) diffusion model isn't that complex if you compare ..."
          ],
          [
           "with \\\\(\\alpha_t := 1 - \\beta_t\\\\) and \\\\(\\bar{\\alpha}_t := \\Pi_{s=1}^{t} \\alpha_s\\\\). Let's refer t..."
          ],
          [
           "```\n\n### Position embeddings\n\nAs the parameters of the neural network are shared across time (noise ..."
          ],
          [
           "```\n\n### Group normalization\n\nThe DDPM authors interleave the convolutional/attention layers of the ..."
          ],
          [
           "```\n\nTo start with, let's use the linear schedule for \\\\(T=300\\\\) time steps and define the various ..."
          ],
          [
           "```\n\nNext, we define a function which we'll apply on-the-fly on the entire dataset. We use the `with..."
          ],
          [
           "```\n\n<img src=\"assets/78_annotated-diffusion/output.png\" width=\"300\" />\n\nSeems like the model is cap..."
          ],
          [
           "--\ntitle: \"How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML ro..."
          ],
          [
           "--\ntitle: \"Databricks ❤️ Hugging Face: up to 40% faster training and tuning of Large Language Models..."
          ],
          [
           "--\ntitle: 'Introducing Snowball Fight ☃️, our first ML-Agents environment'\nthumbnail: /blog/assets/3..."
          ],
          [
           "--\ntitle: \"Deep Learning with Proteins\" \nthumbnail: /blog/assets/119_deep_learning_with_proteins/fol..."
          ],
          [
           "At this point, hopefully you understand what transfer learning is, and that a large language model i..."
          ],
          [
           "![folding example](assets/119_deep_learning_with_proteins/folding_example.png)\n\n*The predicted struc..."
          ],
          [
           "--\ntitle: \"Sentence Transformers in the Hugging Face Hub\"\nauthors:\n- user: osanseviero\n- user: nreim..."
          ],
          [
           "```\n\nBut not only this. People will probably want to either demo their models or play with other mod..."
          ],
          [
           "But seeing a bunch of numbers might not be very useful to you (unless you're able to understand the ..."
          ],
          [
           "```\n\n## Unleashing the Power of Sharing\n\nSo why is this powerful? In a matter of minutes, you can sh..."
          ],
          [
           "--\ntitle: \"Running IF with 🧨 diffusers on a Free Tier Google Colab\"\nthumbnail: /blog/assets/if/thumb..."
          ],
          [
           "```\n\n```bash\nMemTotal:       13297192 kB\n```\n\nAnd an NVIDIA T4 with 15 GB VRAM:\n\n``` python\n!nvidia-..."
          ],
          [
           "```\n\nLet\\'s manually convert the raw tensors to PIL and have a sneak peek at\nthe final result. The o..."
          ],
          [
           "```\n\nThe image variation pipeline requires both the original image and the\nprompt embeddings.\n\nWe ca..."
          ],
          [
           "--\ntitle: \"Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI ..."
          ],
          [
           "--\ntitle: The State of Computer Vision at Hugging Face 🤗\nthumbnail: /blog/assets/cv_state/thumbnail...."
          ],
          [
           "```\n\nBesides these datasets, we provide integration support with augmentation libraries like [albume..."
          ],
          [
           "```\n\nEven for a difficult task like object detection, the user experience doesn’t change very much:\n..."
          ],
          [
           "--\ntitle: \"Fine-tuning Stable Diffusion models on Intel CPUs\"\nthumbnail: /blog/assets/stable-diffusi..."
          ],
          [
           "```\nmkdir /home/devcloud/dicoo\ncd /home/devcloud/dicoo\nwget https://huggingface.co/sd-concepts-libra..."
          ],
          [
           "--\ntitle: \"Gradio-Lite: Serverless Gradio Running Entirely in Your Browser\"\nthumbnail: /blog/assets/..."
          ],
          [
           "```\n\n\nWe've also created a playground on the Gradio website that allows you to interactively edit co..."
          ],
          [
           "--\ntitle: \"BERT 101 - State Of The Art NLP Model Explained\"\nthumbnail: /blog/assets/52_bert_101/thum..."
          ],
          [
           "<div class=\"bg-white pb-1\">\n    <div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;apiUrl&quot..."
          ],
          [
           "</svg>\n                         <span>Fill-Mask</span>\n                     </div>\n                <..."
          ],
          [
           "**Fun Fact:** Masking has been around a long time - [1953 Paper on Cloze procedure (or ‘Masking’)](h..."
          ],
          [
           "### NLP Evaluation Methods: \n\n#### 4.1 SQuAD v1.1 & v2.0\n[SQuAD](https://huggingface.co/datasets/squ..."
          ],
          [
           "```\n\n### 7.2 Try out BERT\n\nFeel free to swap out the sentence below for one of your own. However, le..."
          ],
          [
           "--\ntitle: \"We Raised $100 Million for Open & Collaborative Machine Learning 🚀\"\nthumbnail: /blog/asse..."
          ],
          [
           "--\ntitle: \"Efficient Table Pre-training without Real Data: An Introduction to TAPEX\"\nthumbnail: /blo..."
          ],
          [
           "```\n\n### Fine-tuning\n\nDuring fine-tuning, we feed the concatenation of the natural language question..."
          ],
          [
           "<div class=\"bg-white pb-1\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;apiUrl&quot;:&qu..."
          ],
          [
           "false \n\t\tfalse\"><div class=\"inline-flex justify-between w-32 lg:w-44 rounded-md border border-gray-1..."
          ],
          [
           "### Experiments\n\nWe evaluate TAPEX on four benchmark datasets, including [WikiSQL (Weak)](https://hu..."
          ],
          [
           "--\ntitle: \"Ethics and Society Newsletter #4: Bias in Text-to-Image Models\"\nthumbnail: /blog/assets/1..."
          ],
          [
           "## Detecting Bias\n\nMost of the issues that we describe above cannot be solved with a single solution..."
          ],
          [
           "<p align=\"center\">\n <br>\n <img src=\"https://huggingface.co/datasets/huggingface/documentation-images..."
          ],
          [
           "--\ntitle: \"Active Learning with AutoNLP and Prodigy\"\nthumbnail: /blog/assets/43_autonlp_prodigy/thum..."
          ],
          [
           "```\n\nThis will provide us with a `JSONL` file which can be used for training a model using AutoNLP. ..."
          ],
          [
           "--\ntitle: \"AI Policy @🤗: Open ML Considerations in the EU AI Act\"\nthumbnail: /blog/assets/eu_ai_act_..."
          ],
          [
           "--\ntitle: \"Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration\"\nthu..."
          ],
          [
           "```\n\nWe then set up the quantization job using a [configuration]. You can find details on this confi..."
          ],
          [
           "--\ntitle: \"CO2 Emissions and the 🤗 Hub: Leading the Charge\"\nthumbnail: /blog/assets/60_carbon_emissi..."
          ],
          [
           "--\ntitle: \"What's going on with the Open LLM Leaderboard?\"\nthumbnail: /blog/assets/evaluating-mmlu-l..."
          ],
          [
           "```\n\nNote: you can very easily explore more of this dataset [in the dataset viewer](https://huggingf..."
          ],
          [
           "In this case, if our \"Zygote\" token was instead the highest probability one (as we’ve seen above), t..."
          ],
          [
           "--\ntitle: \"The Technology Behind BLOOM Training\"\nthumbnail: /blog/assets/86_bloom_megatron_deepspeed..."
          ],
          [
           "Please note that both Megatron-LM and DeepSpeed have Pipeline Parallelism and BF16 Optimizer impleme..."
          ],
          [
           "```\n===================  ===================\n|  0 | 1 | 2 | 3  |  |  4 | 5 | 6 | 7  |\n==============..."
          ],
          [
           "```\nwe just sliced it in 2 vertically, placing layers 0-3 onto GPU0 and 4-7 to GPU1.\n\nNow while data..."
          ],
          [
           "Since each dimension requires at least 2 GPUs, here you'd need at least 8 GPUs for full 3D paralleli..."
          ],
          [
           "To train BLOOM fast and efficiently it was necessary to use several custom fused CUDA kernels provid..."
          ],
          [
           "### Papers and Articles\n\nWe couldn't have possibly explained everything in detail in this article, s..."
          ],
          [
           "--\ntitle: \"Happy 1st anniversary 🤗 Diffusers!\" \nthumbnail: /blog/assets/diffusers-turns-1/diffusers-..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n  <img src=\"https://huggingface.co/datasets/huggingface/docum..."
          ],
          [
           "<div class=\"mx-auto max-w-screen-xl py-8\">\n  <div class=\"mb-8 sm:break-inside-avoid\">\n    <blockquot..."
          ],
          [
           "We also collaborated with Google Cloud (who generously provided the compute) to provide technical gu..."
          ],
          [
           "--\ntitle: \"Getting Started with Hugging Face Transformers for IPUs with Optimum\"\nthumbnail: /blog/as..."
          ],
          [
           "```\n\nThe argument ```--model_name_or_path==bert-base-uncased`` loads the [bert-base-uncased](https:/..."
          ],
          [
           "--\ntitle: Deprecation of Git Authentication using password\nthumbnail: /blog/assets/password-git-depr..."
          ],
          [
           "--\ntitle: \"Finetune Stable Diffusion Models with DDPO via TRL\" \nthumbnail: /blog/assets/166_trl_ddpo..."
          ],
          [
           "```\n\nThis should get the main library installed. The following dependencies are for tracking and ima..."
          ],
          [
           "--\ntitle: \"Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers\" \nthumbnail: /blog/assets/111_..."
          ],
          [
           "For demonstration purposes, we'll fine-tune the multilingual version of the \n[`small`](https://huggi..."
          ],
          [
           "```\n\nWe strongly advise you to upload model checkpoints directly the [Hugging Face Hub](https://hugg..."
          ],
          [
           "```\n\nMost ASR datasets only provide input audio samples (`audio`) and the \ncorresponding transcribed..."
          ],
          [
           "```\n\n> **Tip:** the blog post can be adapted for *speech translation* by setting the task to `\"trans..."
          ],
          [
           "```\n\nWe can apply the data preparation function to all of our training examples using dataset's `.ma..."
          ],
          [
           "```\n\n### Define the Training Arguments\nIn the final step, we define all the parameters related to tr..."
          ],
          [
           "--\ntitle: \"Let's talk about biases in machine learning! Ethics and Society Newsletter #2\" \nthumbnail..."
          ],
          [
           "## Putting Bias in Context\n\nThe first and maybe most important concept to consider when dealing with..."
          ],
          [
           "<p align=\"center\">\n <br>\n <img src=\"https://huggingface.co/datasets/huggingface/documentation-images..."
          ],
          [
           "You can usually get a pretty good sense of likely biases in a dataset by reflecting on where it come..."
          ],
          [
           "<p align=\"center\">\n <br>\n <img src=\"https://huggingface.co/datasets/huggingface/documentation-images..."
          ],
          [
           "## Conclusion and Overview of Bias Analysis and Documentation Tools from 🤗\n\nAs we learn to leverage ..."
          ],
          [
           "```\n@inproceedings{hf_ethics_soc_blog_2,\n  author    = {Yacine Jernite and\n               Alexandra ..."
          ],
          [
           "--\ntitle: 'Distributed Training: Train BART/T5 for Summarization using 🤗 Transformers and Amazon Sag..."
          ],
          [
           "```\n\n---\n\n## Configure distributed training and hyperparameters\n\nNext, we will define our `hyperpara..."
          ],
          [
           "```\n\nAfter we extract all the metrics we want to include we are going to create our `README.md`. Add..."
          ],
          [
           "--\ntitle: \"SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit\"\nthumbnail: /blog/asset..."
          ],
          [
           "```\n\"their dinner specials are fantastic.\"\n```\n\n**Model Output:**\n\n```\n[{'span': 'dinner specials', ..."
          ],
          [
           "--\ntitle: \"Boosting Wav2Vec2 with n-grams in 🤗 Transformers\"\nthumbnail: /blog/assets/44_boost_wav2ve..."
          ],
          [
           "```\n\nFor demonstration purposes, we have prepared a new model repository\n[patrickvonplaten/wav2vec2-..."
          ],
          [
           "```\n\nLet's download the data.\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"..."
          ],
          [
           "```\n\nNow, we just have to run KenLM's `lmplz` command to build our *n-gram*,\ncalled `\"5gram.arpa\"`. ..."
          ],
          [
           "```\n\n**Output:**\n```bash\n    Found entries of length > 1 in alphabet. This is unusual unless style i..."
          ],
          [
           "--\ntitle: \"Hugging Face Machine Learning Demos on arXiv\" \nthumbnail: /blog/assets/arxiv/thumbnail.pn..."
          ],
          [
           "--\ntitle: \"Illustrating Reinforcement Learning from Human Feedback (RLHF)\" \nthumbnail: /blog/assets/..."
          ],
          [
           "At this point in the RLHF system, we have an initial language model that can be used to generate tex..."
          ],
          [
           "TRL is designed to fine-tune pretrained LMs in the Hugging Face ecosystem with PPO. TRLX is an expan..."
          ],
          [
           "And here is a snapshot of the growing set of \"key\" papers that show RLHF's performance for LMs:\n- [F..."
          ],
          [
           "```\nLambert, et al., \"Illustrating Reinforcement Learning from Human Feedback (RLHF)\", Hugging Face ..."
          ],
          [
           "--\ntitle: 🧨 Stable Diffusion  in JAX / Flax !\nthumbnail: /blog/assets/108_stable_diffusion_jax/thumb..."
          ],
          [
           "```\n\n\nWe obtain a rng and then \"split\" it 8 times so each device receives a different generator. The..."
          ],
          [
           "--\ntitle: 'Pre-Train BERT with Hugging Face Transformers and Habana Gaudi'\nthumbnail: /blog/assets/9..."
          ],
          [
           "```\n\nWe can start training the tokenizer with `train_new_from_iterator()`.\n\n\n```python\nbert_tokenize..."
          ],
          [
           "```\n\nWe can start our training by creating a `EC2RemoteRunner` and then `launch` it. This will then ..."
          ],
          [
           "--\ntitle: \"Machine Learning Experts - Sasha Luccioni\"\nthumbnail: /blog/assets/69_sasha_luccioni_inte..."
          ],
          [
           "**Sasha:** Yeah, it's a topic I got involved in three years ago now. The first article that came out..."
          ],
          [
           "**Sasha:** Yeah, we wrote a paper a couple of years ago that was a cool experience. It's almost a hu..."
          ],
          [
           "### So sad. That's such a great story though and how there are opportunities like that.\n\n**Sasha:** ..."
          ],
          [
           "### Wow. That is so interesting!\n\n**Sasha:** It's actually really, camera trap data is a really huge..."
          ],
          [
           "**Sasha:** I would spend more time focusing on math. So as I said, my parents are mathematicians and..."
          ],
          [
           "### So should people be afraid of AI taking over the world?\n\n**Sasha:** I think that we're really fa..."
          ],
          [
           "### Where can people find you online?\n\n**Sasha:** I'm on [Twitter @SashaMTL](https://twitter.com/Sas..."
          ],
          [
           "--\ntitle: Simple considerations for simple people building fancy neural networks\nthumbnail: /blog/as..."
          ],
          [
           "> Pro-tip: in my experience working with pre-trained language models, freezing the embeddings module..."
          ],
          [
           "--\ntitle: \"Fine-tuning Llama 2 70B using PyTorch FSDP\" \nthumbnail: /blog/assets/160_fsdp_llama/thumb..."
          ],
          [
           "```\n\n### Addressing Challenge 2\nIt is addressed via choosing `SHARDED_STATE_DICT` state dict type wh..."
          ],
          [
           "```\n\nFine-tuning completed in ~13.5 hours and below is the training loss plot.\n\n![train_loss](https:..."
          ],
          [
           "--\ntitle: Optimizing Stable Diffusion for Intel CPUs with NNCF and 🤗 Optimum\nthumbnail: /blog/assets..."
          ],
          [
           "![overview](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train..."
          ],
          [
           "```\n\nYou can find the training and quantization [code](https://github.com/huggingface/optimum-intel/..."
          ],
          [
           "--\ntitle: \"A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using tran..."
          ],
          [
           "Quantization is done by essentially “rounding” from one data type to another. For example, if one da..."
          ],
          [
           "![Matmul.png](assets/96_hf_bitsandbytes_integration/Matmul.png)\n\n### What does 0 degradation mean?\n\n..."
          ],
          [
           "```\n\n2. Then you can define your own model. Note that you can convert a checkpoint or model of any p..."
          ],
          [
           "```\n\nThis function recursively replaces all `nn.Linear` layers of a given model initialized on the `..."
          ],
          [
           "--\ntitle: \"Speech Synthesis, Recognition, and More With SpeechT5\"\nthumbnail: /blog/assets/speecht5/t..."
          ],
          [
           "```\n\nTo make audio from the spectrogram, do the following:\n\n```python\nwith torch.no_grad():\n    spee..."
          ],
          [
           "```\n\nAs speech audio, we’ll use the same input as in the previous section, but any audio file will w..."
          ],
          [
           "--\ntitle: \"Code Llama: Llama 2 learns to code\" \nthumbnail: /blog/assets/160_codellama/thumbnail.jpg\n..."
          ],
          [
           "```\n\nThis may produce output like the following:\n\n```python\nResult: def fibonacci(n):\n    if n == 0:..."
          ],
          [
           "```\n\n### Using text-generation-inference and Inference Endpoints\n\n[Text Generation Inference](https:..."
          ],
          [
           "--\ntitle: \"Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU plat..."
          ],
          [
           "--\ntitle: \"Accelerating over 130,000 Hugging Face models with ONNX Runtime\"\nthumbnail: /blog/assets/..."
          ],
          [
           "--\ntitle: \"AI Speech Recognition in Unity\"\nthumbnail: /blog/assets/124_ml-for-games/unity-asr-thumbn..."
          ],
          [
           "```\n\nTo test whether this code is working correctly, you can add the following line to the end of th..."
          ],
          [
           "--\ntitle: 'Building a Playlist Generator with Sentence Transformers'\nthumbnail: /blog/assets/87_play..."
          ],
          [
           "```\n\nSince we’re searching for any verse that matches the text prompt, there’s a good chance that th..."
          ],
          [
           "--\ntitle: \"Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2\"\nthumbnail: /blog/asset..."
          ],
          [
           "Here are the throughputs we got on Gaudi2, H100 and A100:\n\n| Device     | `dataloader_num_workers=0`..."
          ],
          [
           "```\n\nThe base command line to run the script is:\n```bash\npython ../gaudi_spawn.py --use_mpi --world_..."
          ],
          [
           "--\ntitle: \"Introducing 🤗 Accelerate\"\nthumbnail: /blog/assets/20_accelerate_library/accelerate_diff.p..."
          ],
          [
           "```\n\nThis last line adds the necessary steps for the backward pass (mostly for mixed precision but o..."
          ],
          [
           "--\ntitle: \"Interactively explore your Huggingface dataset with one line of code\"\nthumbnail: /blog/as..."
          ],
          [
           "```\n\nIf you don’t want to perform the full inference run, you can alternatively download pre-compute..."
          ],
          [
           "--\ntitle: Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure\nthu..."
          ],
          [
           "The Hugging Face Blog Repository 🤗\nThis is the official repository of the [Hugging Face Blog](https:..."
          ],
          [
           "--\ntitle: Training CodeParrot 🦜 from Scratch\nthumbnail: /blog/assets/40_codeparrot/thumbnail.png\naut..."
          ],
          [
           "```\n\nWe can directly load the tokenizer and model from the local repository. Since we are dealing wi..."
          ],
          [
           "```\n\nWhen we call `wait_for_everyone()` and `unwrap_model()` we make sure that all workers are ready..."
          ],
          [
           "--\ntitle: \"Optimizing Bark using 🤗 Transformers\" \nthumbnail: /blog/assets/bark_optimization/thumbnai..."
          ],
          [
           "```\n\n## Base case\n\nBefore incorporating any optimizations, let's measure the performance of the base..."
          ],
          [
           "```\n\n**Output:**\n\n```\nExecution time: 7.4496484375000005 seconds\nMax memory footprint 0.468710912000..."
          ],
          [
           "--\ntitle: \"Director of Machine Learning Insights [Part 4]\"\nthumbnail: /blog/assets/78_ml_director_in..."
          ],
          [
           "**Fun Fact:** Addicted to playing tennis & Huge anime fan. 🎾\n\n**MasterPeace Solutions:** MasterPeace..."
          ],
          [
           "#### **4. What excites you most about the future of ML?**\nI’m excited about the opportunity to mento..."
          ],
          [
           "--\ntitle: \"Panel on Hugging Face\" \nthumbnail: /blog/assets/panel-on-hugging-face/thumbnail.png\nautho..."
          ],
          [
           "--\ntitle: \"Diffusion Models Live Event\"\nthumbnail: /blog/assets/diffusion-models-event/thumbnail.png..."
          ],
          [
           "--\ntitle: \"Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training\"\nthumbnail:..."
          ],
          [
           "--\ntitle: \"Fine-tune Llama 2 with DPO\" \nthumbnail: /blog/assets/157_dpo_trl/dpo_thumbnail.png\nauthor..."
          ],
          [
           "```\n\n### DPO Training\n\nOnce the SFT has finished, we can save the resulting model and move onto the ..."
          ],
          [
           "--\ntitle: \"Welcome fastText to the Hugging Face Hub\"\nthumbnail: /blog/assets/147_fasttext/thumbnail...."
          ],
          [
           "--\ntitle: \"Introducing Decision Transformers on Hugging Face 🤗\"\nthumbnail: /blog/assets/58_decision-..."
          ],
          [
           "```\n### Creating the environment\n\nWe provide pretrained checkpoints for the Gym Hopper, Walker2D and..."
          ],
          [
           "--\ntitle: \"Course Launch Community Event\"\nthumbnail: /blog/assets/34_course_launch/speakers_day1_thu..."
          ],
          [
           "AWS is sponsoring this event by offering free compute to participants via [Amazon SageMaker](https:/..."
          ],
          [
           "## Day 2 (November 16th): The tools you will use\n\nDay 2 will be focused on talks by the Hugging Face..."
          ],
          [
           "--\ntitle: 'Accelerated Inference with Optimum and Transformers Pipelines'\nthumbnail: /blog/assets/66..."
          ],
          [
           "```\n\nWe successfully converted our vanilla transformers to `onnx` and used the model with the `trans..."
          ],
          [
           "```\n\nWe can now leverage the [map](https://huggingface.co/docs/datasets/v2.1.0/en/process#map) funct..."
          ],
          [
           "```\n\n<figure class=\"image table text-center m-0 w-full\">\n  <img src=\"assets/66_optimum_inference/res..."
          ],
          [
           "--\ntitle: \"Hugging Face Selected for the French Data Protection Agency Enhanced Support Program\"\nthu..."
          ],
          [
           "--\ntitle: Using Stable Diffusion with Core ML on Apple Silicon\nthumbnail: /blog/assets/diffusers_cor..."
          ],
          [
           "```\n\n### Inference\n\nTo run inference, please clone Apple's repo:\n\n```bash\ngit clone https://github.c..."
          ],
          [
           "--\ntitle: \"Exploring simple optimizations for SDXL\"\nthumbnail: /blog/assets/simple_sdxl_optimization..."
          ],
          [
           "```\n\nCompared to the baseline, it now takes 20.2GB of memory which saves you 1.5GB of memory.\n\n### S..."
          ],
          [
           "--\ntitle: \"Fine-Tune ViT for Image Classification with 🤗 Transformers\"\nthumbnail: /blog/assets/51_fi..."
          ],
          [
           "```\n\nYou can see the image processor configuration by printing it.\n\n\n    ViTImageProcessor {\n      \"..."
          ],
          [
           "```\n\nThe resulting model has been shared to [nateraw/vit-base-beans](https://huggingface.co/nateraw/..."
          ],
          [
           "--\ntitle: \"~Don't~ Repeat Yourself\"\nthumbnail: /blog/assets/59_transformers_philosophy/transformers...."
          ],
          [
           "A second realization is that models do **not** depend on each other in a bidirectional way. More rec..."
          ],
          [
           "--\ntitle: \"Introducing Würstchen: Fast Diffusion for Image Generation\" \nthumbnail: /blog/assets/wuer..."
          ],
          [
           "```\n\n![Anthropomorphic cat dressed as a fire-fighter](https://huggingface.co/datasets/huggingface/do..."
          ],
          [
           "--\ntitle: Faster TensorFlow models in Hugging Face Transformers\nthumbnail: /blog/assets/10_tf-servin..."
          ],
          [
           "```\n\nThe serving method has to be overridden by the new `input_signature` argument of the `tf.functi..."
          ],
          [
           "--\ntitle: \"Object Detection Leaderboard\"\nthumbnail: /blog/assets/object-detection-leaderboard/thumbn..."
          ],
          [
           "IoU is a metric represented by a number between 0 and 1 that measures the overlap between the predic..."
          ],
          [
           "Now, we need to compute Precision and Recall considering the confidence value of each detection. A g..."
          ],
          [
           "<p style=\"text-align: center;\">\n\\\\( \\text{AP@[.5:.05:0.95} = \\frac{\\text{AP}_{0.5} + \\text{AP}_{0.55..."
          ],
          [
           "```\n\nThe parameter `threshold` in function `post_process_object_detection` is used to filter the det..."
          ],
          [
           "## Conclusions\n\nIn this post, we introduced the problem of Object Detection and depicted the main me..."
          ],
          [
           "--\ntitle: \"The Falcon has landed in the Hugging Face ecosystem\" \nthumbnail: /blog/assets/147_falcon/..."
          ],
          [
           "The video shows a lightweight app that leverages a Swift library for the heavy lifting: model loadin..."
          ],
          [
           "```\n\nAnd then, you'd run text generation using code like the following:\n\n```python\nsequences = pipel..."
          ],
          [
           "```\n\nNote, however, that mixed 8-bit inference will use `torch.float16` instead of `torch.bfloat16`,..."
          ],
          [
           "| ![repo-screenshot.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/ma..."
          ],
          [
           "```\n\nCheck out the [original qlora repository](https://github.com/artidoro/qlora/) for additional de..."
          ],
          [
           "--\ntitle: \"Gradio 3.0 is Out!\"\nthumbnail: /blog/assets/68_gradio_blocks/block-party.png\nauthors:\n- u..."
          ],
          [
           "--\ntitle: \"Releasing Swift Transformers: Run On-Device LLMs in Apple Devices\"\nthumbnail: /blog/asset..."
          ],
          [
           "You can [visit the Space](https://huggingface.co/spaces/coreml-projects/transformers-to-coreml) or u..."
          ],
          [
           "```\n  \"normalizer\": {\n    \"type\": \"Sequence\",\n    \"normalizers\": [\n      {\n        \"type\": \"Prepend\"..."
          ],
          [
           "```\n\nHowever, you don't usually need to tokenize the input text yourself - the [`Generation` code](h..."
          ],
          [
           "This is what happened when I first tried to convert Llama 2 using `coremltools`:\n\n![Llama 2 conversi..."
          ],
          [
           "---\ntitle: \"Making ML-powered web games with Transformers.js\" \nthumbnail: /blog/assets/ml-web-games/..."
          ],
          [
           "```\n\nWe can now use this worker in our `App.jsx` file by adding the following code to the `App` comp..."
          ],
          [
           "--\ntitle: \"Deploy MusicGen in no time with Inference Endpoints\" \nthumbnail: /blog/assets/run-musicge..."
          ],
          [
           "```\n\nWe can see the following waveform sequence as output.\n```\n[{\"generated_audio\":[[-0.024490159,-0..."
          ],
          [
           "--\n\ntitle: \"Results of the Open Source AI Game Jam\"\nthumbnail: /blog/assets/game-jam-first-edition-r..."
          ],
          [
           "🤖 Charmed - Texture Generator\n\n🤖 Soundful - Music generator\n\n🤖 Elevenlabs - Voice generator\n\n🤖 Scena..."
          ],
          [
           "Contrastive Search\n\nThis is a companion notebook to the [Hugging Face guest blog post entry about co..."
          ],
          [
           "```\n\n## 3. Contrastive Search:\n\n### 3.1. Generating Text with Contrastive Search:\n\n\n```python\nimport..."
          ],
          [
           "--\ntitle: 🧨 Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e\nthumbnail: /blog/as..."
          ],
          [
           "```\n\nThe prompts have to be supplied as tensors to the pipeline, and they always have to have the sa..."
          ],
          [
           "--\ntitle: \"Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia\"\nthumbnail: /..."
          ],
          [
           "```\n\n## 2. Create a custom `inference.py` script for `text-classification`\n\nThe [Hugging Face Infere..."
          ],
          [
           "```\n\nThe average latency for our BERT model is `5-6ms` for a sequence length of 128.\n<br>\n<figure cl..."
          ],
          [
           "--\ntitle: \"How to train your model dynamically using adversarial data\"\nthumbnail: /blog/assets/88_mn..."
          ],
          [
           "```\n\nNow that you have defined the structure of your model, you need to train it on the standard MNI..."
          ],
          [
           "--\ntitle: \"Rocket Money x Hugging Face: Scaling Volatile ML Models in Production​\"\nthumbnail: /blog/..."
          ],
          [
           "With the model fully positioned in the transaction processing pipeline, both uptime and latency beca..."
          ],
          [
           "--\ntitle: \"Leveraging Hugging Face for complex generative AI use cases\"\nthumbnail: /blog/assets/78_m..."
          ],
          [
           "--\ntitle: \"ControlNet in 🧨 Diffusers\" \nthumbnail: /blog/assets/controlnet/thumbnail.png \nauthors:\n- ..."
          ],
          [
           "We will explore different use cases with the `StableDiffusionControlNetPipeline` in this blog post. ..."
          ],
          [
           "```\n\nTo process different conditionings depending on the chosen ControlNet, we also need to install ..."
          ],
          [
           "```\n\nNow let's make Mr Potato posing for [Johannes Vermeer](https://en.wikipedia.org/wiki/Johannes_V..."
          ],
          [
           "```\n\n<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-imag..."
          ],
          [
           "--\ntitle: Universal Image Segmentation with Mask2Former and OneFormer\nthumbnail: /blog/assets/127_ma..."
          ],
          [
           "```\nfrom transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n\nprocessor = Au..."
          ],
          [
           "--\ntitle: \"A Dive into Text-to-Video Models\"\nthumbnail: /blog/assets/140_text-to-video/thumbnail.png..."
          ],
          [
           "<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/re..."
          ],
          [
           "```\ngit clone https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis\ncd modelsc..."
          ],
          [
           "--\ntitle: \"Stable Diffusion XL on Mac with Advanced Core ML Quantization\"\nthumbnail: /blog/assets/st..."
          ],
          [
           "```\n\nWhat this tells us is that the original model quality, as measured by PSNR in float16, is about..."
          ],
          [
           "You can download and apply them locally to experiment.\n\nIn addition, we also applied the three best ..."
          ],
          [
           "--\ntitle: \"An Introduction to Deep Reinforcement Learning\"\nthumbnail: /blog/assets/63_deep_rl_intro/..."
          ],
          [
           "**Without any supervision**, the child will get better and better at playing the game.\n\nThat’s how h..."
          ],
          [
           "<figure class=\"image table text-center m-0 w-full\">\n  <img src=\"assets/63_deep_rl_intro/rewards_3.jp..."
          ],
          [
           "<figure class=\"image table text-center m-0 w-full\">\n  <img src=\"assets/63_deep_rl_intro/policy_4.jpg..."
          ],
          [
           "--\ntitle: \"Scaling up BERT-like model Inference on modern CPU  - Part 2\"\nauthors:\n- user: echarlaix\n..."
          ],
          [
           "Each pushes forward different approaches to improve aspects of the memory allocation and management ..."
          ],
          [
           "Also, from the comments we had about the previous blog post, we wanted to change the way we present ..."
          ],
          [
           "So, what are the alternatives, and when are they more suitable than the default ones? Well, again, i..."
          ],
          [
           "This time, by knowing the underlying structure of the operator flows and matrix shapes involved then..."
          ],
          [
           "SigOpt is also very useful for analysis: it provides a lot of figures and valuable information.\nFirs..."
          ],
          [
           "--\ntitle: \"Supercharged Searching on the 🤗 Hub\"\nthumbnail: /blog/assets/48_hubsearch/thumbnail.png\na..."
          ],
          [
           "```\n\n\nVery quickly we see that it's a much more coordinated approach for searching through the API, ..."
          ],
          [
           "--\ntitle: \"Optimization story: Bloom inference\"\nthumbnail: /blog/assets/bloom-inference-pytorch-scri..."
          ],
          [
           "```\n**Note: This is not the best nor the only load testing we used, but it was\nalways the first to b..."
          ],
          [
           "```\n\nNow that we have a good understanding of where we stand it's time to get to work.\n\nWe tried man..."
          ],
          [
           "## Pure PyTorch\n  - Purely modify the existing code to make it faster by removing operations\n    lik..."
          ],
          [
           "```\n\nto \n\n```python\n@torch.jit.script\ndef bloom_gelu_forward(x):\n    return x * 0.5 * (1.0 + torch.t..."
          ],
          [
           "```\n\nThe first masked fill is creating a new tensor, which is here only to \nsay to the softmax opera..."
          ],
          [
           "--\ntitle: \"Welcome spaCy to the Hugging Face Hub\"\nthumbnail: /blog/assets/23_spacy/thumbnail.png\n\nau..."
          ],
          [
           "<div><a class=\"text-xs block mb-3 text-gray-300\" href=\"/spacy/en_core_web_sm\"><code>spacy/en_core_we..."
          ],
          [
           "\"> <div class=\"font-semibold flex items-center mb-2\"><div class=\"text-lg flex items-center\"><svg xml..."
          ],
          [
           "### Using existing models\n\nAll models from the Hub can be directly installed using `pip install`. \n\n..."
          ],
          [
           "```\n\n```python\n# Using spacy.load().\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Importing as..."
          ],
          [
           "--\ntitle: \"Porting fairseq wmt19 translation system to transformers\"\nthumbnail: /blog/assets/07_port..."
          ],
          [
           "```\n\nNote: the path could be different when you try it yourself, since the hash value of the model c..."
          ],
          [
           "```\n\ngives us:\n\n```\n('tokenize ', 'Machine Learning is great')\n('apply_bpe: ', 'Mach@@ ine Lear@@ ni..."
          ],
          [
           "```\n\nAfter running the conversion script, let's check the converted dictionary:\n\n```\n$ grep '\"Mach\"'..."
          ],
          [
           "```\nFirst I looked at the model:\n```\nprint(ru2en[\"models\"][0])\n```\n```\nTransformerModel(\n  (encoder)..."
          ],
          [
           "```\nAll that remains is to save the configuration into `config.json` and create a new `state_dict` d..."
          ],
          [
           "```\ntransformers-cli upload -y wmt19-en-ru/config.json --filename wmt19-en-ru/config.json\ntransforme..."
          ],
          [
           "```\ninstead of:\n```\nfrom transformers.tokenization_fsmt import FSMTTokenizer\nfrom transformers.model..."
          ],
          [
           "```\nwhich took a few minutes to run and returned:\n```\n{'bleu': 39.0498, 'n_obs': 2000, 'runtime': 18..."
          ],
          [
           "```\nmake docs\n```\nto test that the newly added document was building correctly. The file I needed to..."
          ],
          [
           "--\ntitle: \"Understanding BigBird's Block Sparse Attention\"\nthumbnail: /blog/assets/18_big_bird/attn...."
          ],
          [
           "```\n\nThis way, the query token attends only to a subset of all possible tokens while yielding a good..."
          ],
          [
           "```\n\n### Random Attention\n\nRandom attention is ensuring that each query token will attend a few rand..."
          ],
          [
           "```\n\n</details>\n\n## ITC vs ETC\n\nThe BigBird model can be trained using 2 different strategies: **ITC..."
          ],
          [
           "--\ntitle: \"Train your first Decision Transformer\"\nthumbnail: /blog/assets/101_train-decision-transfo..."
          ],
          [
           "```\n\nWhile most datasets on the hub are ready to use out of the box, sometimes we wish to perform so..."
          ],
          [
           "```\n\nThe transformers Trainer class required a number of arguments, defined in the TrainingArguments..."
          ],
          [
           "--\ntitle: Goodbye cold boot - how we made LoRA Inference 300% faster\nthumbnail: /blog/assets/171_loa..."
          ],
          [
           "### LoRA structure\n\nIn the Hub, LoRAs can be identified with two attributes:\n\n![Hub](https://hugging..."
          ],
          [
           "```\n\n## Loading figures\n\nAll numbers below are in seconds:\n\n<table>\n  <tr>\n    <th>GPU</th>\n    <td>..."
          ],
          [
           "--\ntitle: \"Open-Source Text Generation & LLM Ecosystem at Hugging Face\"\nthumbnail: /blog/assets/os_l..."
          ],
          [
           "Snippets to use all models mentioned in this blog post are given in either the model repository or t..."
          ],
          [
           "You can find a comprehensive table of some open-source/open-access models below. \n\n| Model          ..."
          ],
          [
           "![HuggingChat Search](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/..."
          ],
          [
           "--\ntitle: \"Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action\" \nthumbnail: /blog/ass..."
          ],
          [
           "```\n\n## Starting a BentoML Service\n\nYou can directly run the BentoML HTTP server with a web UI power..."
          ],
          [
           "--\ntitle: \"Deep Q-Learning with Space Invaders\"\nthumbnail: /blog/assets/78_deep_rl_dqn/thumbnail.gif..."
          ],
          [
           "<img src=\"assets/78_deep_rl_dqn/deep-q-network.jpg\" alt=\"Deep Q Network\"/>\n  \nSo, we see that Deep Q..."
          ],
          [
           "Therefore, Double DQN helps us reduce the overestimation of q values and, as a consequence, helps us..."
          ],
          [
           "--\ntitle: \"Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore\"\nthumbnail: /blog/assets..."
          ],
          [
           "<p>In 2017 a group of Google AI researchers published a paper introducing the transformer model arch..."
          ],
          [
           "<p>For this blog post, we will use a ViT model pre-trained on ImageNet-21k, based on the paper <a hr..."
          ],
          [
           "<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h2>Getting the dataset</h2>\n<a id=\"getting-the-dataset\" data-hs-anchor=..."
          ],
          [
           "<div class=\"blog-caption\" style=\"max-height: 100%; max-width: 90%; margin-left: auto; margin-right: ..."
          ],
          [
           "</div>\n<div style=\"font-size: 14px; line-height: 1.3;\">\n<script src=\"https://gist.github.com/nickmax..."
          ],
          [
           "--\ntitle: \"Nyströmformer: Approximating self-attention in linear time and memory via the Nyström met..."
          ],
          [
           "```python\n\nkey_layer = self.transpose_for_scores(self.key(hidden_states)) # K\nvalue_layer = self.tra..."
          ],
          [
           "```\n\n\n## Using Nyströmformer with HuggingFace\n\nNyströmformer for Masked Language Modeling (MLM) is a..."
          ],
          [
           "--\ntitle: \"Llama 2 is here - get it on Hugging Face\" \nthumbnail: /blog/assets/llama2/thumbnail.jpg\na..."
          ],
          [
           "```\n\n```\nResult: I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of o..."
          ],
          [
           "```\n\nAs you can see, the instructions between the special `<<SYS>>` tokens provide context for the m..."
          ],
          [
           "--\ntitle: \"Introducing The World's Largest Open Multilingual Language Model: BLOOM\"\nthumbnail: /blog..."
          ],
          [
           "--\ntitle: \"Optimum-NVIDIA Unlocking blazingly fast LLM inference in just 1 line of code\" \nthumbnail:..."
          ],
          [
           "--\ntitle: \"Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA\" \nthumbn..."
          ],
          [
           "`-1 * 2^(2) * (1 + 2^-1) = -1 * 4 * 1.5 = -6`\n\nFor FP4 there is no fixed format and as such one can ..."
          ],
          [
           "```\n\n### Quickstart\n\nThe basic way to load a model in 4bit is to pass the argument `load_in_4bit=Tru..."
          ],
          [
           "```\nNote that if your favorite model is not there, you can open a Pull Request or raise an issue in ..."
          ],
          [
           "We have used the recent `SFTTrainer` from TRL library, and the benchmarking script can be found [her..."
          ],
          [
           "--\ntitle: \"Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models\"\nthumbnail: /..."
          ],
          [
           "```\nPyTorch: 1.14.0.dev20221103+cu116; ORT: 1.14.0.dev20221103001+cu116; DeepSpeed: 0.6.6; HuggingFa..."
          ],
          [
           "```\n\n## Looking Forward\n\nThe Hugging Face team is working on open sourcing more large models and low..."
          ],
          [
           "--\ntitle: \"SafeCoder vs. Closed-source Code Assistants\"\nthumbnail: /blog/assets/safecoder-vs-closed-..."
          ],
          [
           "--\ntitle: \"Optimizing your LLM in production\"\nthumbnail: /blog/assets/163_optimize_llm/optimize_llm...."
          ],
          [
           "```\n```python\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretr..."
          ],
          [
           "```\n\nNice, we're getting the same result as before, so no loss in accuracy! Let's look at how much m..."
          ],
          [
           "```\n\nOverall, we saw that running OctoCoder in 8-bit precision reduced the required GPU VRAM from 32..."
          ],
          [
           "The Starcoder models are a series of 15.5B parameter models trained on 80+ programming languages fro..."
          ],
          [
           "```\nFor demonstration purposes, we duplicate the system by ten so that the input length is long enou..."
          ],
          [
           "```\n\n## 3. The Science Behind LLM Architectures: Strategic Selection for Long Text Inputs and Chat\n\n..."
          ],
          [
           "> Both RoPE and ALiBi are relative positional embeddings that are *not* learned during training, but..."
          ],
          [
           "```\n\n**Output**:\n```\nshape of input_ids torch.Size([1, 21])\nshape of input_ids torch.Size([1, 22])\ns..."
          ],
          [
           "```\n\n**Output**:\n```\n7864320000\n```\n\nRoughly 8 billion float values! Storing 8 billion float values ..."
          ],
          [
           "--\ntitle: \"Deploy GPT-J 6B for inference using  Hugging Face Transformers and Amazon SageMaker\"\nthum..."
          ],
          [
           "```\n\nNow we are able to load our `GPT-J` model with `torch.load()` to run predictions. \n\n```python\nf..."
          ],
          [
           "```\n\n---\n\nTo delete your endpoint you can run. \n\n```python\npredictor.delete_endpoint()\n```\n\n## Concl..."
          ],
          [
           "--\ntitle: \"Visualize proteins on Hugging Face Spaces\"\nthumbnail: /blog/assets/98_spaces_3dmoljs/thum..."
          ],
          [
           "--\ntitle: \"Announcing our new Content Guidelines and Policy\"\nthumbnail: /blog/assets/content-guideli..."
          ],
          [
           "--\ntitle: \"Fine-Tune MMS Adapter Models for low-resource ASR\"\nthumbnail: /blog/assets/151_mms/mms_ma..."
          ],
          [
           "The work done in **MMS** leverages this idea of adapters for speech recognition across different lan..."
          ],
          [
           "```\n\nWe strongly suggest to upload your training checkpoints directly to the [🤗 Hub](https://hugging..."
          ],
          [
           "```\n\n```python\ncommon_voice_train = common_voice_train.map(remove_special_characters)\ncommon_voice_t..."
          ],
          [
           "```\n\nLet's now save the vocabulary as a json file.\n\n```python\nimport json\nwith open('vocab.json', 'w..."
          ],
          [
           "```\n\n```bash\n    Target text: bağış anlaşması bir ağustosta imzalandı\n    Input array shape: (70656,..."
          ],
          [
           "```\n\n```python\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n```\n\nNe..."
          ],
          [
           "```\n\n| Training Loss | Training Steps | Validation Loss | Wer    |\n|:-------------:|:----:|:--------..."
          ],
          [
           "--\ntitle: \"Policy Gradient with PyTorch\"\nthumbnail: /blog/assets/85_policy_gradient/thumbnail.gif\nau..."
          ],
          [
           "For instance, with a self-driving car, at each state, you can have a (near) infinite choice of actio..."
          ],
          [
           "--\ntitle: \"Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account\"\nthumbnail: /blog..."
          ],
          [
           "--\ntitle: \"Practical 3D Asset Generation: A Step-by-Step Guide\"\nthumbnail: /blog/assets/124_ml-for-g..."
          ],
          [
           "--\ntitle: \"Making LLMs lighter with AutoGPTQ and transformers\" \nthumbnail: /blog/assets/159_autogptq..."
          ],
          [
           "```\n\nCheck out the Transformers [documentation](https://huggingface.co/docs/transformers/main/en/mai..."
          ],
          [
           "```\n\nQuantizing a model may take a long time. Note that for a 175B model, at least 4 GPU-hours are r..."
          ],
          [
           "--\ntitle: \"Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets\"\nthum..."
          ],
          [
           "- Adherence to [Zipf’s law](https://en.wikipedia.org/wiki/Zipf%27s_law), which provides measurements..."
          ],
          [
           "--\ntitle: \"New ViT and ALIGN Models From Kakao Brain\" \nthumbnail: /blog//assets/132_vit_align/thumbn..."
          ],
          [
           "<p>\n<center>\n<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main..."
          ],
          [
           "```\n\nWhile it is significantly smaller than the `LAION` dataset, the `COYO` dataset is still massive..."
          ],
          [
           "```\n\nAlternatively, we can use the stand-along vision and text encoders of ALIGN to retrieve multi-m..."
          ],
          [
           "--\ntitle: \"Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon\"\nthumbnail: /bl..."
          ],
          [
           "In this example, we ask the model: “*What is the role of Hugging Face in democratizing NLP?*”. This ..."
          ],
          [
           "--\ntitle: \"An overview of inference solutions on Hugging Face\"\nthumbnail: /blog/assets/116_inference..."
          ],
          [
           "--\ntitle: \"Hugging Face's TensorFlow Philosophy\"\nthumbnail: /blog/assets/96_tensorflow_philosophy/th..."
          ],
          [
           "```\n\n#### Philosophy #2: Loss functions are provided by default, but can be easily changed.\n\nIn Kera..."
          ],
          [
           "```\n\nWe’ve made a number of major improvements recently in this area. Most significantly, we’ve upda..."
          ],
          [
           "--\ntitle: The Age of Machine Learning As Code Has Arrived\nthumbnail: /blog/assets/31_age_of_ml_as_co..."
          ],
          [
           "It's a Good Thing in so many ways. State of the art is constantly advancing, and hardly anyone can k..."
          ],
          [
           "--\ntitle: \"Introducing Storage Regions on the HF Hub\"\nthumbnail: /blog/assets/172_regions/thumbnail...."
          ],
          [
           "--\ntitle: \"Announcing the 🤗 AI Research Residency Program\"\nthumbnail: /blog/assets/57_ai_residency/r..."
          ],
          [
           "--\ntitle: \"Hugging Face Reads, Feb. 2021 - Long-range Transformers\"\nthumbnail: /blog/assets/14_long_..."
          ],
          [
           "### [Compressive Transformers for Long-Range Sequence Modelling](https://arxiv.org/abs/1911.05507)\n\n..."
          ],
          [
           "### [Rethinking Attention with Performers](https://arxiv.org/abs/2009.14794)\n\nKrzysztof Choromanski,..."
          ],
          [
           "## @Hugging Face 🤗: Long-range modeling\n\nThe Longformer implementation and the associated open-sourc..."
          ],
          [
           "--\ntitle: \"VQ-Diffusion\" \nthumbnail: /blog/assets/117_vq_diffusion/thumbnail.png\nauthors:\n- user: wi..."
          ],
          [
           "```\n\n![png](assets/117_vq_diffusion/vq_diffusion_teddy_bear_pool.png)\n\n### Architecture\n\n![svg](asse..."
          ],
          [
           "[Image Transformer](https://arxiv.org/abs/1802.05751) uses transformers by restricting self attentio..."
          ],
          [
           "--\ntitle: Zero-shot image segmentation with CLIPSeg\nthumbnail: /blog/assets/123_clipseg-zero-shot/th..."
          ],
          [
           "One interesting feature of CLIPSeg is that both the query (the image we want to segment) and the pro..."
          ],
          [
           "```\n\nTo download the model, simply instantiate it.\n\n```python\nfrom transformers import CLIPSegProces..."
          ],
          [
           "```\n\n<figure class=\"image table text-center m-0 w-9/12\">\n  <medium-zoom background=\"rgba(0,0,0,.7)\" ..."
          ],
          [
           "--\ntitle: \"Getting Started with Sentiment Analysis on Twitter\"\nthumbnail: /blog/assets/85_sentiment_..."
          ],
          [
           "```\n\n2. Setting up Twitter credentials\n\nThen, you need to set up the [Twitter API credentials](https..."
          ],
          [
           "```\n\nCuriously, some of the words that stand out from the positive tweets include \"notes\", \"cron\", a..."
          ],
          [
           "### Step 3: Save the results on Google Sheets\n\nAs the last step to your Zap, you will save the resul..."
          ],
          [
           "--\ntitle: \"Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub\"..."
          ],
          [
           "```\n\nHowever, for some of the datasets on the Hub, we might be keen not to download the whole datase..."
          ],
          [
           "--\ntitle: \"Jupyter X Hugging Face\" \nthumbnail: /blog/assets/135_notebooks-hub/before_after_notebook_..."
          ],
          [
           "--\ntitle: \"Gradio is joining Hugging Face!\"\nthumbnail: /blog/assets/42_gradio_joins_hf/thumbnail.png..."
          ],
          [
           "--\ntitle: \"Generating Stories: AI for Game Development #5\"\nthumbnail: /blog/assets/124_ml-for-games/..."
          ],
          [
           "Despite the limitations I've discussed, dialog agents are an incredibly useful tool for game develop..."
          ],
          [
           "--\ntitle: \"Making automatic speech recognition work on large files with Wav2Vec2 in 🤗 Transformers\"\n..."
          ],
          [
           "--\ntitle: \"Red-Teaming Large Language Models\" \nthumbnail: /blog/assets/red-teaming/thumbnail.png\naut..."
          ],
          [
           "Given this persistent challenge of red-teaming, there are incentives for multi-organization collabor..."
          ],
          [
           "--\ntitle: \"2023, year of open LLMs\"\nthumbnail: /blog/assets/cv_state/thumbnail.png\nauthors:\n- user: ..."
          ],
          [
           "These huge models were exciting but also very expensive to run! When performing inference (computing..."
          ],
          [
           "In parallel, a notable event of the end of the year 2023 was the rise of performances and a number o..."
          ],
          [
           "❄️ Winter 2022/2023: In January this year, the [Human ChatGPT Instruction corpus](https://huggingfac..."
          ],
          [
           "These techniques allow anybody to easily generate combinations of models and are made especially eas..."
          ],
          [
           "--\ntitle: \"The N Implementation Details of RLHF with PPO\"\nthumbnail: /blog/assets/167_the_n_implemen..."
          ],
          [
           "# General Implementation Details\n\nWe now take a technical deep dive into the implementation details ..."
          ],
          [
           "```\n    \n3. **Adjust position indices correspondingly for padding tokens**\n    1. When calculating t..."
          ],
          [
           "```\n        \n    3. Note that in a more recent codebase https://github.com/openai/summarize-from-fee..."
          ],
          [
           "# Reward Model Implementation Details\n\nIn this section, we discuss reward-model-specific implementat..."
          ],
          [
           "1. **Scale the logits by sampling temperature.** \n    1. When calculating the log probability of res..."
          ],
          [
           "micro_batch_size = mini_batch_size // gradient_accumulation_steps\n        data = np.arange(batch_siz..."
          ],
          [
           "```\n        \n8. **Per-token KL penalty**\n    - The code adds a per-token KL penalty ([lm_human_prefe..."
          ],
          [
           "```\n        \n    - For the `sentiment` and `descriptiveness` tasks examined in this work, we have `i..."
          ],
          [
           "```\n\n- Let’s compare the update equations of pytorch-style and tensorflow-style adam. Following the ..."
          ],
          [
           "The particular training run we had showed poor GPU utilization (around 30%), so it takes almost 4 da..."
          ],
          [
           "```..."
          ],
          [
           "--\ntitle: \"Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel\"\nthumbnail: /bl..."
          ],
          [
           "```\n\n| Method | Batch Size Max ($BS) | Num GPUs | Approx Train Time (Hours) | Notes |\n| --- | --- | ..."
          ],
          [
           "```\n    {\n    '_fsdp_wrapped_module.flat_param': torch.Size([494209]),\n    \n    '_fsdp_wrapped_modul..."
          ],
          [
           "--\ntitle: \"Hosting your Models and Datasets on Hugging Face Spaces using Streamlit\"\nthumbnail: /blog..."
          ],
          [
           "--\ntitle: \"Mixture of Experts Explained\"\nthumbnail: /blog/assets/moe/thumbnail.png\nauthors:\n- user: ..."
          ],
          [
           "<figure class=\"image text-center\">\n  <img src=\"https://huggingface.co/datasets/huggingface/documenta..."
          ],
          [
           "Just as in GShard, the authors replaced the FFN layers with a MoE layer. The Switch Transformers pap..."
          ],
          [
           "One could experiment with freezing all non-expert weights. That is, we'll only update the MoE layers..."
          ],
          [
           "<figure class=\"image text-center\">\n  <img src=\"https://huggingface.co/datasets/huggingface/documenta..."
          ],
          [
           "```\n\n```\nSanseviero, et al., \"Mixture of Experts Explained\", Hugging Face Blog, 2023.\n```..."
          ],
          [
           "--\ntitle: \"An Introduction to Q-Learning Part 1\"\nthumbnail: /blog/assets/70_deep_rl_q_part1/thumbnai..."
          ],
          [
           "<figure class=\"image table text-center m-0 w-full\">\n  <img src=\"assets/70_deep_rl_q_part1/two-approa..."
          ],
          [
           "## **Monte Carlo vs Temporal Difference Learning**\n\nThe last thing we need to talk about before divi..."
          ],
          [
           "- With *the Monte Carlo method*, we update the value function from a complete episode, and so we **u..."
          ],
          [
           "--\ntitle:  Introducing the Hugging Face LLM Inference Container for Amazon SageMaker\nthumbnail: /blo..."
          ],
          [
           "```\n\nAfter we have created the `HuggingFaceModel` we can deploy it to Amazon SageMaker using the `de..."
          ],
          [
           "--\ntitle: \"Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face\"\nthumbnail:..."
          ],
          [
           "Users enjoy the updates too; Fetch has grown from 10 million to 18 million monthly active users sinc..."
          ],
          [
           "--\ntitle: \"Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator\"\nthumbnail: ..."
          ],
          [
           "We also ran these models on first-gen Gaudi. While it is slower than Gaudi2, it is interesting from ..."
          ],
          [
           "```\nBatch n°1\nInput: ['Facebook has released a report that shows what content was most widely viewed..."
          ],
          [
           "--\ntitle: Deploying 🤗 ViT on Kubernetes with TF Serving\nthumbnail: /blog/assets/94_tf_serving_kubern..."
          ],
          [
           "```\n\n## Running the Docker image locally\n\nLastly, you can run the newly built Docker image locally t..."
          ],
          [
           "```\n\nWe made the service type ‘LoadBalancer’ so the endpoints are\nexposed externally to the Kubernet..."
          ],
          [
           "--\ntitle: 'Welcome Stable-baselines3 to the Hugging Face Hub 🤗'\nthumbnail: /blog/assets/47_sb3/thumb..."
          ],
          [
           "--\ntitle: \"Director of Machine Learning Insights [Part 2: SaaS Edition]\"\nthumbnail: /blog/assets/67_..."
          ],
          [
           "#### **3. What’s a common mistake you see people make trying to integrate ML into a SaaS product?**\n..."
          ],
          [
           "#### **Any final thoughts?**\n–It’s challenging to put models into production. Believe data science t..."
          ],
          [
           "--\ntitle: \"From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community\" \nthumbnail: ..."
          ],
          [
           "--\ntitle: \"🐶Safetensors audited as really safe and becoming the default\"\nthumbnail: /blog/assets/142..."
          ],
          [
           "--\ntitle: \"Federated Learning using Hugging Face and Flower\" \nthumbnail: /blog/assets/fl-with-flower..."
          ],
          [
           "```\n\nThe `get_parameters` function lets the server get the client's parameters. Inversely, the `set_..."
          ],
          [
           "--\ntitle: \"Creating open machine learning datasets? Share them on the Hugging Face Hub!\"\nthumbnail: ..."
          ],
          [
           "<p align=\"center\"> \n <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/reso..."
          ],
          [
           "--\ntitle: \"Assisted Generation: a new direction toward low-latency text generation\"\nthumbnail: /blog..."
          ],
          [
           "```\n\nFinally, if you have multiple devices available to you, you can distribute the workload using [..."
          ],
          [
           "```\n\n\nThis means that you can use a model forward pass for a different purpose: in addition to feedi..."
          ],
          [
           "```\n\n\nIs the additional internal complexity worth it? Let’s have a look at the latency numbers for t..."
          ],
          [
           "--\ntitle: \"Introducing the Private Hub: A New Way to Build With Machine Learning\"\nthumbnail: /blog/a..."
          ],
          [
           "<figure class=\"image table text-center m-0 w-full\">\n  <medium-zoom background=\"rgba(0,0,0,.7)\" alt=\"..."
          ],
          [
           "- **On-cloud Private Hub**: runs in a cloud account on AWS, Azure or GCP owned by the customer. This..."
          ],
          [
           "### Easily demo models to relevant stakeholders\n\nNow that we have trained our custom model for analy..."
          ],
          [
           "```\n\nWith just 12 lines of code, we are up and running in running inferences with an infrastructure ..."
          ],
          [
           "--\ntitle: \"Speculative Decoding for 2x Faster Whisper Inference\" \nthumbnail: /blog/assets/whisper-sp..."
          ],
          [
           "Now that we know the background behind speculative decoding, we're ready to dive into the practical ..."
          ],
          [
           "```\n\nLet's load the English speech transcription dataset that we will use for benchmarking. We'll lo..."
          ],
          [
           "```\n**Outputs:**\n\n```\n Mr. Quilter is the apostle of the middle classes and we are glad to welcome h..."
          ],
          [
           "--\ntitle: \"Snorkel AI x Hugging Face: unlock foundation models for enterprises\"\nthumbnail: /blog/ass..."
          ],
          [
           "--\ntitle: \"An Introduction to Q-Learning Part 2/2\"\nthumbnail: /blog/assets/73_deep_rl_q_part2/thumbn..."
          ],
          [
           "- *With probability 1 — ɛ* : we do **exploitation** (aka our agent selects the action with the highe..."
          ],
          [
           "As we continue exploring and exploiting the environment and updating Q-values using TD target, **Q-T..."
          ],
          [
           "--\ntitle: \"Overview of natively supported quantization schemes in 🤗 Transformers\" \nthumbnail: /blog/..."
          ],
          [
           "We will use the following setup: \n- bitsandbytes: 4-bit quantization with `bnb_4bit_compute_dtype=to..."
          ],
          [
           "From the results above, we conclude that there is less degradation in bigger models. More interestin..."
          ],
          [
           "--\ntitle: 'Train and Fine-Tune Sentence Transformers Models'\nthumbnail: /blog/assets/95_training_st_..."
          ],
          [
           "```\n\nNow for the most critical part: the dataset format.\n\n## How to prepare your dataset for trainin..."
          ],
          [
           "```\nConvert the training examples to a `Dataloader`.\n\n```py\nfrom torch.utils.data import DataLoader\n..."
          ],
          [
           "--\ntitle: \"SDXL in 4 steps with Latent Consistency LoRAs\"\nthumbnail: /blog/assets/lcm_sdxl/lcm_thumb..."
          ],
          [
           "```\n\nThese are the 8 images displayed in a grid:\n\n<p align=\"center\">\n    <img src=\"https://huggingfa..."
          ],
          [
           "```\n\n<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-imag..."
          ],
          [
           "```\n\n<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-imag..."
          ],
          [
           "--\ntitle: \"Introducing Skops\"\nthumbnail: /blog/assets/94_skops/introducing_skops.png\nauthors:\n- user..."
          ],
          [
           "```\n\nOnce we push the model to the Hub, anyone can use it unless the repository is private. You can ..."
          ],
          [
           "--\ntitle: \"Run a Chatgpt-like Chatbot on a Single GPU with ROCm\" \nthumbnail: /blog/assets/chatbot-am..."
          ],
          [
           "```\ngit clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\ncd GPTQ-for-LLaMa\npython setup..."
          ],
          [
           "```\n(Note, do not use <https://github.com/qwopqwop200/GPTQ-for-LLaMa> for\nnow. Because 2,3,4bit quan..."
          ],
          [
           "--\ntitle: \"Zero-shot image-to-text generation with BLIP-2\" \nthumbnail: /blog/assets/blip-2/thumbnail..."
          ],
          [
           "```\nfrom transformers import AutoProcessor, Blip2ForConditionalGeneration\nimport torch\n\nprocessor = ..."
          ],
          [
           "--\ntitle: \"Scaling-up BERT Inference on CPU (Part 1)\"\nthumbnail: /blog/assets/21_bert_cpu_scaling_pa..."
          ],
          [
           "One possible way to explain such difference between the two frameworks might be the underlying techn..."
          ],
          [
           "```\n\nIn our case we have a machine with **2 sockets**, each socket providing **24 physical cores** w..."
          ],
          [
           "```\n\nThen we specify the core and memory affinity through `numactl` using all the **physical** cores..."
          ],
          [
           "```\n\nThe outcomes remain the same, our 4 instances are effectively running in a truly parallel manne..."
          ],
          [
           "```\n\n\n## 8. Batch size scaling - Improving throughput and latency with multiple parallel & independe..."
          ],
          [
           "Stay tuned! 🤗\n\n## Acknowledgments\n\n- [Omry Yadan](https://github.com/omry) (Facebook FAIR) - Author ..."
          ],
          [
           "--\ntitle: \"Welcome PaddlePaddle to the Hugging Face Hub\" \nthumbnail: /blog/assets/126_paddlepaddle/t..."
          ],
          [
           "--\ntitle: Image Similarity with Hugging Face Datasets and Transformers\nthumbnail: /blog/assets/image..."
          ],
          [
           "```\n\nAnd we can map `extract_embeddings()` like so:\n\n```py\ndevice = \"cuda\" if torch.cuda.is_availabl..."
          ],
          [
           "--\ntitle: \"Japanese Stable Diffusion\" \nthumbnail: /blog/assets/106_japanese_stable_diffusion/jsd_thu..."
          ],
          [
           "```\n\nOn the other hand, by using our Japanese tokenizer, the prompt is split into interpretable toke..."
          ],
          [
           "--\ntitle: \"Fine-Tune Wav2Vec2 for English ASR in Hugging Face with 🤗 Transformers\"\nthumbnail: /blog/..."
          ],
          [
           "```\n\nMany ASR datasets only provide the target text, `'text'` for each audio\nfile `'file'`. Timit ac..."
          ],
          [
           "```\n\nIn a final step, we use the json file to instantiate an object of the\n`Wav2Vec2CTCTokenizer` cl..."
          ],
          [
           "```\n\nIt can be heard, that the speakers change along with their speaking rate, accent, etc. Overall,..."
          ],
          [
           "```\n\nLet's apply the data preparation function to all examples.\n\n```python\ntimit = timit.map(prepare..."
          ],
          [
           "```\n\nNow, we can load the pretrained `Wav2Vec2` checkpoint. The tokenizer\\'s\n`pad_token_id` must be ..."
          ],
          [
           "```\n\nYou can now share this model with all your friends, family, favorite pets: they can all load it..."
          ],
          [
           "--\ntitle: \"Hugging Face and AWS partner to make AI more accessible\" \nthumbnail: /blog/assets/131_aws..."
          ],
          [
           "--\ntitle: \"Deploy Livebook notebooks as apps to Hugging Face Spaces\"\nthumbnail: /blog/assets/120_eli..."
          ],
          [
           "--\ntitle: \"Getting Started with Sentiment Analysis using Python\"\nthumbnail: /blog/assets/50_sentimen..."
          ],
          [
           "```\n\nYou can use a specific sentiment analysis model that is better suited to your language or use c..."
          ],
          [
           "```\n\nThen, let's define the metrics you will be using to evaluate how good is your fine-tuned model ..."
          ],
          [
           "```\n!pip install -q transformers tweepy wordcloud matplotlib\n```\n\n### 2. Set up Twitter API credenti..."
          ],
          [
           "```\n\nSome of the words associated with positive tweets include Discord, Ethereum, Join, Mars4 and Sh..."
          ],
          [
           "a href=\"https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whispe..."
          ],
          [
           "```\n\nWe strongly advise you to upload model checkpoints directly the [Hugging Face Hub](https://hugg..."
          ],
          [
           "```\n\nWe can apply the data preparation function to all of our training examples using dataset's `.ma..."
          ],
          [
           "```\n\n**Note**: if one does not want to upload the model checkpoints to the Hub, \nset `push_to_hub=Fa..."
          ],
          [
           "--\ntitle: How to train a Language Model with Megatron-LM\nthumbnail: /blog/assets/100_megatron_traini..."
          ],
          [
           "```\n\nThe data is then tokenized, shuffled and processed into a binary format for training using the ..."
          ],
          [
           "--\ntitle: \"Accelerating Hugging Face Transformers with AWS Inferentia2\" \nthumbnail: /blog/assets/140..."
          ],
          [
           "Let’s highlight a few insights of the benchmark.\n\n### BERT-base\n\nHere is the latency comparison for ..."
          ],
          [
           "--\ntitle: \"Introducing SafeCoder\" \nthumbnail: /blog/assets/159_safecoder/thumbnail.jpg\nauthors:\n- us..."
          ],
          [
           "## How does it work?\n\nSafeCoder is a complete commercial solution, including service, software and s..."
          ],
          [
           "--\ntitle: \"The Reformer - Pushing the limits of language modeling\"\nthumbnail: /blog/assets/03_reform..."
          ],
          [
           "Let's take our input sequence for \\\\(n=16, d_h=3\\\\) again for visualization:\n\n![alt text](https://ra..."
          ],
          [
           "For each set of indices \\\\(C_{m}\\\\), the softmax function on the corresponding bucket of query vecto..."
          ],
          [
           "---\n \\\\( {}^{1} \\\\) The authors run some preliminary experiments confirming that shared query key se..."
          ],
          [
           "```\n#@title Installs and Imports\n# pip installs\n!pip -qq install git+https://github.com/huggingface/..."
          ],
          [
           "```\n\n    1 / 1\n    Doesn't fit on GPU. CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 11.17 ..."
          ],
          [
           "---\n \\\\( {}^1 \\\\) For a simpler explanation, the layer norm layer which is normally applied to \\\\( \\..."
          ],
          [
           "```\n#@title Installs and Imports\n# pip installs\n!pip -qq install git+https://github.com/huggingface/..."
          ],
          [
           "```\n\n    1 / 2\n    2 / 2\n    \n    ====================      INFERENCE - MEMORY - RESULT       ======..."
          ],
          [
           "If we assume to know \\\\( \\mathbf{\\overline{Y}}^{(1)}, \\mathbf{\\overline{Y}}^{(2)} \\\\), it can easily..."
          ],
          [
           "```\n#@title Installs and Imports\n# pip installs\n!pip -qq install git+https://github.com/huggingface/..."
          ],
          [
           "```\n\n    1 / 3\n    2 / 3\n    3 / 3\n    \n    ====================        TRAIN - MEMORY - RESULTS    ..."
          ],
          [
           "The crucial aspect to see here is that Axial Positional Encodings make sure that none of the vectors..."
          ],
          [
           "```\n#@title Installs and Imports\n# pip installs\n!pip -qq install git+https://github.com/huggingface/..."
          ],
          [
           "--\ntitle: \"Chat Templates: An End to the Silent Performance Killer\" \nthumbnail: /blog/assets/chat-te..."
          ],
          [
           "```\n\nThere's also a second reason not to hardcode a standard format, though, beyond the proliferatio..."
          ],
          [
           "--\ntitle: \"Make your llama generation time fly with AWS Inferentia2\"\nthumbnail: /blog/assets/inferen..."
          ],
          [
           "```\n>>> from optimum.neuron import pipeline\n\n>>> p = pipeline('text-generation', 'aws-neuron/Llama-2..."
          ],
          [
           "--\ntitle: \"Introduction to 3D Gaussian Splatting\"\nthumbnail: /blog/assets/124_ml-for-games/thumbnail..."
          ],
          [
           "--\ntitle: \"Train your ControlNet with diffusers\"\nthumbnail: /blog/assets/136_train-your-controlnet/t..."
          ],
          [
           "With just 1 epoch (so after the model \"saw\" 100K images), it already converged to following the pose..."
          ],
          [
           "```\n\nAnd then run the [train_controlnet.py](https://github.com/huggingface/diffusers/blob/main/examp..."
          ],
          [
           "--\ntitle: \"Spread Your Wings: Falcon 180B is here\" \nthumbnail: /blog/assets/162_falcon_180b/thumbnai..."
          ],
          [
           "```\n\n### Transformers\n\nWith the release of Transformers 4.33, you can use Falcon 180B and leverage a..."
          ],
          [
           "--\ntitle: Swift 🧨Diffusers - Fast Stable Diffusion for Mac\nthumbnail: /blog/assets/fast-mac-diffuser..."
          ],
          [
           "## Other Improvements in Version 1.1\n\nIn addition to the performance optimization and fixing a few b..."
          ],
          [
           "--\ntitle: \"Director of Machine Learning Insights\"\nthumbnail: /blog/assets/61_ml_director_insights/th..."
          ],
          [
           "<img class=\"mx-auto\" style=\"float: left;\" padding=\"5px\" width=\"200\" src=\"/blog/assets/61_ml_director..."
          ],
          [
           "**Background:** Nathan is a passionate machine learning leader with 7 years of experience in researc..."
          ],
          [
           "At BEN, Nic innovates intelligent technologies that scale human capabilities to reach people. See hi..."
          ],
          [
           "<img class=\"mx-auto\" style=\"float: left;\" padding=\"5px\" width=\"200\" src=\"/blog/assets/61_ml_director..."
          ],
          [
           "--\ntitle: \"My Journey to a serverless transformers pipeline on Google Cloud\"\nthumbnail: /blog/assets..."
          ],
          [
           "```\n\nThen the `DockerFile` which will be used to create a docker image of the service. We specify th..."
          ],
          [
           "--\ntitle: \"Machine Learning Experts - Margaret Mitchell\"\nthumbnail: /blog/assets/57_meg_mitchell_int..."
          ],
          [
           "One of the best ways to be more inclusive is to not be exclusive. Feels fairly obvious but is often ..."
          ],
          [
           "*Note: Everyone at Hugging Face wears several hats.* :)\n\n### Meg’s impact on AI\n\nMeg is featured in ..."
          ],
          [
           "--\ntitle: \"Accelerating PyTorch distributed fine-tuning with Intel technologies\"\nthumbnail: /blog/as..."
          ],
          [
           "Once the instance is up, I connect to it with ```ssh``` in order to install dependencies.\n\n### Insta..."
          ],
          [
           "```\nwget https://registrationcenter-download.intel.com/akdlm/irc_nas/18236/l_BaseKit_p_2021.4.0.3422..."
          ],
          [
           "```\n\nSetup is now complete. Let's scale our training job to 2 nodes and 4 nodes.\n\n### Running a dist..."
          ],
          [
           "--\ntitle: \"Introducing new audio and vision documentation in 🤗 Datasets\"\nthumbnail: /blog/assets/87_..."
          ],
          [
           "```\n\nYou can use `ImageFolder` to load an image dataset for nearly any type of image task if you hav..."
          ],
          [
           "--\ntitle: \"Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face\"\nthumbnail: /blog/assets/mixt..."
          ],
          [
           "```\n\nThis format has to be exactly reproduced for effective use. We’ll show later how easy it is to ..."
          ],
          [
           "```\n\nThen you can run the script:\n\n```bash\naccelerate launch --config_file examples/accelerate_confi..."
          ],
          [
           "--\ntitle: Hyperparameter Search with Transformers and Ray Tune\nthumbnail: /blog/assets/06_ray_tune/r..."
          ],
          [
           "```\n\n\nIt also works with [Weights and Biases](https://wandb.ai/) out of the box!\n\n![alt_text](/blog/..."
          ],
          [
           "--\ntitle: \"Accelerate Large Model Training using DeepSpeed\"\nthumbnail: /blog/assets/83_accelerate_de..."
          ],
          [
           "```\n\nNow, run below command for training:\n```bash\naccelerate launch run_cls_no_trainer.py \\\n  --mode..."
          ],
          [
           "```\n\n---\n| Method | Batch Size Max | Eval Size Max | Train time per epoch (seconds) | Eval time  per..."
          ],
          [
           "--\ntitle: \"Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs\"\nthumbnail: /..."
          ],
          [
           "You can find the full data of the benchmark in this google spreadsheet: [🤗 Infinity: CPU Ice-Lake Be..."
          ],
          [
           "```\n\n### Throughput\n\nBelow you can find the throughput comparison for running infinity on 2 physical..."
          ],
          [
           "--\ntitle: \"Introducing ⚔️ AI vs. AI ⚔️ a deep reinforcement learning multi-agents competition system..."
          ],
          [
           "If you’re interested, **you don’t need to participate in the course to be able to participate in the..."
          ],
          [
           "```\n@article{cochet-simonini2023,\n  author = {Cochet, Carl and Simonini, Thomas},\n  title = {Introdu..."
          ],
          [
           "--\ntitle: \"SetFit: Efficient Few-Shot Learning Without Prompts\"\nthumbnail: /blog/assets/103_setfit/i..."
          ],
          [
           "```\n\nNow, let's download a text classification dataset from the Hugging Face Hub. We'll use the [Sen..."
          ],
          [
           "--\ntitle: \"Creating a Coding Assistant with StarCoder\"\nthumbnail: /blog/assets/starchat_alpha/thumbn..."
          ],
          [
           "```\n\nAs we can see, the first part of the prompt “Below are a series...” corresponds to the system m..."
          ],
          [
           "```\n\n```\nDatasetDict({\n    train: Dataset({\n        features: ['messages'],\n        num_rows: 19034\n..."
          ],
          [
           "```\n\n```\n{\n    \"bos_token\": \"<|endoftext|>\",\n    \"eos_token\": \"<|endoftext|>\",\n    \"unk_token\": \"<|e..."
          ],
          [
           "```\n\n<p align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-imag..."
          ],
          [
           "```\n\nGPT4 Evaluation:\n\n```\n4 7\n\nAssistant 1's code was not well-structured, and it was difficult to ..."
          ],
          [
           "--\ntitle: \"AI Policy @🤗: Response to the U.S. NTIA's Request for Comment on AI Accountability\"\nthumb..."
          ],
          [
           "--\ntitle: \"Creating Privacy Preserving AI with Substra\" \nthumbnail: /blog/assets/139_owkin-substra/t..."
          ],
          [
           "--\ntitle:  Deploy Embedding Models with Hugging Face Inference Endpoints\nthumbnail: /blog/assets/168..."
          ],
          [
           "You can then deploy your model with a click on “Create Endpoint”. After 1-3 minutes, the Endpoint sh..."
          ],
          [
           "```\n\n## Conclusion\n\nTEI on Hugging Face Inference Endpoints enables blazing fast and ultra cost-effi..."
          ],
          [
           "--\ntitle: \"What Makes a Dialog Agent Useful?\" \nthumbnail: /blog/assets/dialog-agents/thumbnail.png\na..."
          ],
          [
           "SFT and IFT are very closely linked. Instruction tuning can be seen as a subset of supervised fine-t..."
          ],
          [
           "```\n@article{rajani2023ift,\n  author = {Rajani, Nazneen and Lambert, Nathan and Sanh, Victor and Wol..."
          ],
          [
           "--\ntitle: \"AI for Game Development: Creating a Farming Game in 5 Days. Part 1\"\nthumbnail: /blog/asse..."
          ],
          [
           "```\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n```\n4. Download the [Stabl..."
          ],
          [
           "--\ntitle: \"From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease\"\nthu..."
          ],
          [
           "```\n\nThe optimizer needs to be declared based on the model *on the specific device* (so `ddp_model` ..."
          ],
          [
           "```\n\nOr:\n\n```python\nnotebook_launcher(train_ddp_accelerate, args=(), num_processes=2)\n```\n\n## Using ..."
          ],
          [
           "--\ntitle: \"Probabilistic Time Series Forecasting with 🤗 Transformers\"\nthumbnail: /blog/assets/118_ti..."
          ],
          [
           "```\n\n\nAs can be seen, the dataset contains 3 splits: train, validation and test.\n\n\n```python\ndataset..."
          ],
          [
           "```\n\nNote that, similar to other models in the 🤗 Transformers library, [`TimeSeriesTransformerModel`..."
          ],
          [
           "```\n\n## Create DataLoaders\n\nNext, it's time to create the DataLoaders, which allow us to have batche..."
          ],
          [
           "```\n\n```python\nprint(\"Loss:\", outputs.loss.item())\n\n>>> Loss: 9.069628715515137\n```\n\nNote that the m..."
          ],
          [
           "```\n\nFor example:\n\n```python\nplot(334)\n```\n\n![png](https://huggingface.co/datasets/huggingface/docum..."
          ],
          [
           "--\ntitle: Image Classification with AutoTrain \nthumbnail: /blog/assets/105_autotrain-image-classific..."
          ],
          [
           "--\ntitle: \"Fine-Tune XLSR-Wav2Vec2 for low-resource ASR with 🤗 Transformers\"\nthumbnail: /blog/assets..."
          ],
          [
           "```\n\nWe strongly suggest to upload your training checkpoints directly to the\n[Hugging Face Hub](http..."
          ],
          [
           "```\n\n```python\ncommon_voice_train = common_voice_train.map(remove_special_characters)\ncommon_voice_t..."
          ],
          [
           "```\n\nIn a final step, we use the json file to load the vocabulary into an\ninstance of the `Wav2Vec2C..."
          ],
          [
           "```\n\n**Print Output:**\n\n```bash\n    Target text: makedonya bu yıl otuz adet tyetmiş iki tankı aldı\n ..."
          ],
          [
           "```\n\n```python\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n```\n\nNe..."
          ],
          [
           "```\n\nYou can now share this model with all your friends, family, favorite\npets: they can all load it..."
          ],
          [
           "--\ntitle: \"Advantage Actor Critic (A2C)\"\nthumbnail: /blog/assets/89_deep_rl_a2c/thumbnail.gif\nauthor..."
          ],
          [
           "This is the idea behind Actor-Critic. We learn two function approximations:\n\n- *A policy* that **con..."
          ],
          [
           "--\ntitle: \"Faster Training and Inference: Habana Gaudi®2 vs Nvidia A100 80GB\"\nthumbnail: /blog/asset..."
          ],
          [
           "The results we got, which are consistent with the numbers published by Habana [here](https://develop..."
          ],
          [
           "--\ntitle: \"Parameter-Efficient Fine-Tuning using 🤗 PEFT\"\nthumbnail: /blog/assets/130_peft/thumbnail...."
          ],
          [
           "```\n\n3. Wrapping base 🤗 Transformers model by calling `get_peft_model`\n```diff\n  model = AutoModelFo..."
          ],
          [
           "--\ntitle: \"MTEB: Massive Text Embedding Benchmark\" \nthumbnail: /blog/assets/110_mteb/thumbnail.png\na..."
          ],
          [
           "--\ntitle: Deploying 🤗 ViT on Vertex AI\nthumbnail: /blog/assets/97_vertex_ai/image1.png\nauthors:\n- us..."
          ],
          [
           "```\n\nLet’s unpack the code piece by piece:\n\n- `GCS_BUCKET` denotes the path of your GCS bucket where..."
          ],
          [
           "```\n\nThe `predict_image()` utility prepares the request payload conforming\nto this specification.\n\nI..."
          ],
          [
           "--\ntitle: 'Few-shot learning in practice: GPT-Neo and the 🤗 Accelerated Inference API'\n# thumbnail: ..."
          ],
          [
           "```\n\n---\n## Practical Insights\n\nHere are some practical insights, which help you get started using `..."
          ],
          [
           "--\ntitle: \"Director of Machine Learning Insights [Part 3: Finance Edition]\"\nthumbnail: /blog/assets/..."
          ],
          [
           "**Background:** Debanjan is Director of Machine Learning in the AI Team at  Moody's Analytics and al..."
          ],
          [
           "**Fun Fact:** Soumitri is a prolific inventor with 100+ issued U.S. patents in varied fields includi..."
          ],
          [
           "--\ntitle: \"Instruction-tuning Stable Diffusion with InstructPix2Pix\" \nthumbnail: assets/instruction_..."
          ],
          [
           "| ![cartoonization_dataset_overview](https://huggingface.co/datasets/huggingface/documentation-image..."
          ],
          [
           "However, for low-light image enhancement, it leaves a lot to be desired: \n\n| ![image_enhancement_res..."
          ],
          [
           "--\ntitle: \"Deploying the AI Comic Factory using the Inference API\"\nthumbnail: /blog/assets/165_ai_co..."
          ],
          [
           "--\ntitle: What's new in Diffusers? 🎨\nthumbnail: /blog/assets/102_diffusers_2nd_month/inpainting.png\n..."
          ],
          [
           "```\n\nAlternatively, you can also convert your SD checkpoints to ONNX directly with the exporter scri..."
          ],
          [
           "--\ntitle: \"Announcing the Hugging Face Fellowship Program\"\nthumbnail: /blog/assets/62_fellowship/fel..."
          ],
          [
           "--\ntitle: \"How 🤗 Accelerate runs very large models thanks to PyTorch\"\nthumbnail: /blog/assets/104_ac..."
          ],
          [
           "```\n\nAccelerate evaluated that the embeddings and the decoder up until the 9th block could all fit o..."
          ],
          [
           "```\n\nNote that if you are trying to load a very large model that require some disk offload on top of..."
          ],
          [
           "--\ntitle: 'The Partnership: Amazon SageMaker and Hugging Face'\nthumbnail: /blog/assets/17_the_partne..."
          ],
          [
           "---\n\n## **Getting started: End-to-End Text Classification 🧭**\n\nIn this getting started guide, we wil..."
          ],
          [
           "```\n\nTo run training on SageMaker we need to create a sagemaker Session and provide an IAM role with..."
          ],
          [
           "```\n\nThe hyperparameters you define in the HuggingFace Estimator are passed in as named arguments.\n\n..."
          ],
          [
           "```\n\n## SageMaker Metrics\n\n[SageMaker Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/train..."
          ],
          [
           "--\ntitle: \"Introducing Optimum: The Optimization Toolkit for Transformers at Scale\"\nauthors:\n- user:..."
          ],
          [
           "![Automatic quantization code snippet](assets/25_hardware_partners_program/carbon_inc_quantizer.png)..."
          ]
         ],
         "hovertemplate": "source=blog<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "blog, circle",
         "marker": {
          "color": "#B6E880",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "blog, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -0.80081177,
          1.4489661,
          3.2109733,
          -4.3812604,
          -3.3518867,
          3.1123059,
          -4.0940375,
          3.8412707,
          4.3841443,
          -2.6452215,
          4.32496,
          -3.0322757,
          -0.9839252,
          -1.59203,
          2.9999397,
          2.9102116,
          -2.8306327,
          1.9178338,
          -2.8560758,
          0.2935552,
          -3.5349355,
          -3.4269707,
          1.1921101,
          -1.2257079,
          -4.6423287,
          -0.786772,
          -3.2736983,
          3.7083123,
          4.3797283,
          -1.2799549,
          -1.2256238,
          1.5360807,
          -0.2812761,
          2.4375045,
          -2.297376,
          -3.2071686,
          4.2697263,
          -1.1678821,
          3.3108473,
          -1.2257804,
          0.3763419,
          4.5281453,
          4.2963686,
          -2.1465232,
          4.4647455,
          3.2257488,
          -2.4244435,
          -2.22971,
          -2.5489945,
          -3.8308442,
          -2.9947968,
          -3.7602623,
          -2.409935,
          -3.9607644,
          2.3704507,
          0.30977845,
          -2.1403403,
          4.288158,
          4.5577354,
          -1.4075357,
          -0.08847073,
          3.209607,
          -3.7666867,
          -4.3729815,
          -0.62171817,
          4.2081738,
          3.9079185,
          -0.51244044,
          3.2211096,
          1.3961371,
          1.0273964,
          4.370968,
          4.410471,
          2.0988264,
          2.662306,
          1.9400685,
          2.2275314,
          0.059231386,
          -2.2764323,
          0.8958363,
          1.6137121,
          2.4268925,
          0.50479853,
          -2.3678415,
          -4.163605,
          -3.5112252,
          2.0277286,
          -3.4076357,
          -3.906743,
          1.7968516,
          0.3687336,
          -3.0143766,
          -1.7425016,
          -2.390452,
          -3.8084183,
          -3.1192307,
          2.7456157,
          4.3384275,
          2.1069567,
          0.13805258,
          1.7083995,
          1.2117904,
          -3.1135607,
          -3.2419248,
          0.79273343,
          3.8958747,
          -0.8868878,
          2.996232,
          -3.8135846,
          1.1475865,
          0.8467987,
          2.113819,
          -3.6926463,
          3.87382,
          3.7040703,
          1.0829357,
          -4.110158,
          0.3118525,
          -3.6357996,
          -3.1043167,
          -1.5881189,
          2.4891772,
          -3.4990644,
          -3.1392612,
          1.7697141,
          2.2416022,
          1.4241819,
          -2.8818784,
          1.5385509,
          -0.068715006,
          1.334116,
          3.251301,
          0.20922454,
          3.1345572,
          -3.8072925,
          -3.1124623,
          -3.0973167,
          -3.5900202,
          -0.64477915,
          -2.6411738,
          2.1467075,
          3.4115186,
          -4.657585,
          0.14374956,
          1.7952299,
          0.4299463,
          -1.7565042,
          -3.2673552,
          -4.001938,
          1.6035626,
          1.9828924,
          -1.6856844,
          -1.6325036,
          -0.6143934,
          -3.49664,
          -3.4443645,
          -3.1712883,
          1.7032032,
          0.62770087,
          4.5422974,
          10.322396,
          -2.1807508,
          -1.5109541,
          1.2540671,
          -3.1040673,
          -2.124498,
          5.2779527,
          -3.2163174,
          10.321765,
          2.339085,
          -3.3964853,
          0.6449502,
          4.648726,
          -3.7058666,
          3.0774906,
          1.491988,
          2.1617994,
          -2.9939198,
          3.3355765,
          0.41438666,
          3.0537884,
          -4.170395,
          -4.433719,
          -2.2922735,
          3.0946102,
          -3.7963045,
          2.4062955,
          -2.2117739,
          0.35146067,
          -3.8452532,
          5.0055265,
          -0.43720204,
          3.7949638,
          2.553521,
          4.5515604,
          1.714239,
          0.5266485,
          3.3087966,
          3.3633873,
          4.944582,
          -0.57398677,
          3.69539,
          -1.9871813,
          3.5290403,
          5.2052794,
          1.8566546,
          4.926954,
          2.9271162,
          2.112778,
          -0.6466754,
          -3.3055027,
          4.6160517,
          -2.6400068,
          -0.5277556,
          1.490545,
          -3.3276465,
          2.3972175,
          2.8783414,
          4.321949,
          2.6252854,
          -3.363278,
          -4.398237,
          -1.42616,
          -0.366753,
          -4.440698,
          3.153338,
          -2.969149,
          -1.7897087,
          -2.1300025,
          4.348989,
          -4.325092,
          2.7952683,
          3.043276,
          -2.6631708,
          -4.0141673,
          3.3938656,
          2.727174,
          1.7978015,
          -1.120576,
          3.2834406,
          3.1643891,
          -1.5708057,
          2.1963878,
          1.4729732,
          4.980735,
          1.9002036,
          1.9614654,
          -4.05332,
          -3.5267668,
          -1.8868443,
          0.28073916,
          -4.1225715,
          -2.3553555,
          2.1292744,
          -1.0664836,
          2.9080071,
          -4.173655,
          -0.922141,
          0.74997807,
          -3.3409863,
          -1.9198974,
          1.2514563,
          -0.35960558,
          2.2630172,
          4.6779027,
          0.98416656,
          -3.9366193,
          -1.882919,
          -1.1694293,
          -3.2757425,
          -1.3082273,
          0.2827013,
          4.3569293,
          -0.8964334,
          1.5891113,
          -1.8654249,
          2.1409616,
          0.12532999,
          1.2036848,
          3.0358853,
          0.48565552,
          2.0699644,
          1.4485751,
          2.9478023,
          2.4392712,
          1.1124275,
          -4.175804,
          -1.2933989,
          -4.069525,
          2.4150035,
          -1.4792453,
          1.386867,
          -3.5679712,
          -3.749593,
          -3.6813135,
          2.5737906,
          -0.96941274,
          1.897811,
          -4.0230513,
          1.3087608,
          2.4231706,
          4.2097425,
          -0.51817393,
          3.0326302,
          4.679719,
          1.3812834,
          -3.8166707,
          -2.3287103,
          -0.62377346,
          2.1541452,
          4.3971095,
          3.953066,
          1.1861593,
          -1.3606043,
          -1.1883922,
          3.725526,
          3.4545949,
          -4.2185965,
          4.24298,
          2.705508,
          4.80088,
          2.2133071,
          4.574344,
          1.970096,
          -3.1102257,
          2.7593706,
          3.238749,
          2.8429794,
          -0.82871616,
          3.66914,
          4.5093727,
          0.2702801,
          -3.6258276,
          1.537116,
          -2.563957,
          -1.9957638,
          1.2379739,
          -1.0248563,
          -1.6625725,
          -1.5664521,
          -0.92856175,
          -2.8995986,
          -4.5652213,
          -1.882205,
          2.8393052,
          -3.3338513,
          -4.075667,
          -1.5642292,
          -1.862867,
          -1.9387966,
          2.3137398,
          0.79462373,
          1.8616028,
          -4.4745774,
          -2.7679057,
          -1.5283809,
          1.9306756,
          1.4368275,
          1.5573097,
          -2.7522445,
          -0.051740702,
          1.8102381,
          2.5894148,
          -0.4498476,
          -2.4721193,
          4.1082573,
          -3.9385867,
          2.6612322,
          -3.1707284,
          3.9271824,
          -2.434274,
          4.6178293,
          -2.5586343,
          -4.5525904,
          1.9678043,
          -3.7807434,
          2.4956965,
          5.3595033,
          -2.3805075,
          2.6179852,
          0.42398223,
          -3.3962173,
          1.1219887,
          2.4160852,
          -0.7292575,
          -1.2709866,
          0.87136596,
          -3.88352,
          -0.1603727,
          -2.2555578,
          -1.7591504,
          -2.0145693,
          -2.71502,
          2.313275,
          3.1648998,
          -0.98206645,
          -0.40928966,
          -0.36675924,
          -2.8549273,
          1.8755,
          1.3214465,
          -2.498963,
          0.31522894,
          -3.8252041,
          0.89854157,
          -0.3544143,
          -2.920422,
          -4.134169,
          -3.553546,
          3.7813118,
          3.774953,
          4.1362057,
          2.6175435,
          -0.09899969,
          -0.85278,
          2.1911752,
          -3.0085664,
          -4.2598367,
          -0.17985158,
          3.6696455,
          -3.1531994,
          -2.4923892,
          3.835045,
          -1.9148961,
          -1.1961492,
          -1.3337417,
          -0.14540383,
          -2.0504382,
          -0.49958298,
          3.8136654,
          2.6943905,
          -1.1074673,
          -1.1060785,
          2.1409702,
          2.883523,
          1.8119133,
          -2.6113832,
          1.7145853,
          -1.772141,
          -4.809541,
          3.0680058,
          0.3007917,
          -1.1735109,
          3.3013914,
          -4.6071267,
          -2.2752516,
          1.2899303,
          0.35594302,
          -0.8622037,
          2.1410878,
          -3.7660167,
          -1.0144174,
          -1.5990019,
          -1.981876,
          3.6484356,
          -1.1311285,
          2.6738656,
          -2.1945078,
          0.36302897,
          -3.2336366,
          2.895347,
          3.0939825,
          0.48729512,
          -2.4457927,
          0.6455665,
          -1.9188582,
          -0.7091935,
          -4.3837276,
          1.8125926,
          4.4204445,
          4.689756,
          0.57399696,
          2.9366152,
          1.3720112,
          4.940367,
          2.8471234,
          3.297047,
          -3.3221955,
          3.4085329,
          5.4997387,
          -2.385479,
          1.7130994,
          -3.3031154,
          2.3882341,
          2.0596876,
          -2.91436,
          1.691478,
          -1.9521112,
          -3.2604585,
          1.5703354,
          -0.17761514,
          4.2849417,
          -3.4474494,
          3.2501943,
          1.0037645,
          0.72164965,
          -0.2470611,
          2.751806,
          1.6074082,
          2.4375715,
          1.9308829,
          4.05914,
          4.0653014,
          -0.07306517,
          -0.15584634,
          -2.9991276,
          0.8646495,
          0.55159897,
          -2.2334213,
          -3.8603382,
          3.3290024,
          2.5718324,
          3.4595811,
          4.024212,
          4.981593,
          -3.506314,
          -3.2054293,
          1.7933775,
          2.8936548,
          -0.8427036,
          2.1879065,
          0.42016748,
          2.9390306,
          -4.0109625,
          2.5460958,
          0.17363471,
          -0.036630567,
          -3.039385,
          -2.2140296,
          -1.7153865,
          1.4903646,
          1.6881335,
          -2.3971405,
          0.6534088,
          -1.5007104,
          -2.0368507,
          0.20516674,
          0.9257395,
          -0.76979434,
          -3.046358,
          -2.1846368,
          1.6219743,
          0.42948416,
          3.622343,
          -4.106368,
          0.50059134,
          -0.5031464,
          0.8343988,
          -2.4233835,
          3.692349,
          0.2527678,
          2.6505692,
          -3.8635714,
          -1.8929415,
          -1.0393406,
          -3.3028357,
          4.4603314,
          1.8928863,
          4.532153,
          -0.2796945,
          -1.019279,
          -2.9857304,
          -0.7763651,
          -1.2308308,
          -4.6286693,
          4.0277863,
          2.6628768,
          5.096408,
          3.4141026,
          4.0439186,
          2.980791,
          -4.2586875,
          -1.3168285,
          5.14461,
          -0.7424032,
          4.055184,
          -2.2099154,
          1.9261209,
          2.8316784,
          -3.2673213,
          -2.801303,
          3.4626737,
          -4.1402097,
          -2.5999773,
          2.8206782,
          -3.5607448,
          3.0173361,
          -1.7505234,
          -3.6215992,
          -1.3078834,
          4.1280584,
          -1.5736294,
          3.5838563,
          2.9059613,
          2.815103,
          3.9053037,
          -1.0644614,
          4.843749,
          -3.7911777,
          -1.9169399,
          -0.73752517,
          3.4885798,
          -3.3907173,
          4.3007135,
          4.9899898,
          0.6866499,
          1.309901,
          -1.0930353,
          -1.42298,
          -2.4744227,
          2.6403482,
          -1.3333333,
          1.3026134,
          3.0092149,
          -4.1784415,
          -4.3654532,
          -3.2142286,
          -3.6396158,
          0.7802993,
          1.2155888,
          2.1046915,
          -2.1328454,
          0.07633929,
          -1.7747108,
          1.2819066,
          0.39005363,
          -4.276898,
          2.0588856,
          -2.1386974,
          1.7120509,
          -2.8123658,
          -3.9987805,
          -2.4530027,
          3.1234238,
          3.1126804,
          -0.7384406,
          1.9146854,
          3.0608823,
          -3.0915775,
          -3.3412373,
          -1.5492417,
          2.833725,
          -0.82209957,
          1.5959332,
          -2.4380324,
          3.349162,
          2.437508,
          -4.3570557,
          -1.6820247,
          2.1376388,
          -3.2983096,
          -0.23881693,
          2.2343369,
          0.34112895,
          2.6707537,
          -0.9113259,
          1.6699191,
          -2.2245245,
          4.657916,
          0.08249562,
          4.680836,
          -3.2932217,
          -4.390391,
          3.5636985,
          4.442327,
          -2.2719746,
          -2.5247245,
          -0.9488852,
          3.931943,
          4.1252866,
          1.5388138,
          -3.8952312,
          1.0756239,
          -2.1671727,
          -2.2062597,
          -4.2205033,
          1.9668525,
          -1.2967368,
          -0.08621123,
          -1.9386944,
          -3.1039648,
          5.395475,
          -3.2829945,
          -1.765382,
          -2.6499162,
          -3.7002807,
          -3.5756996,
          1.8965336,
          -3.4480958,
          -3.0664842,
          0.83318704,
          2.9259183,
          2.5886657,
          3.0602937,
          1.4074457,
          4.2091413,
          -4.0278893,
          1.2104236,
          -1.3168707,
          4.4169345,
          0.29816517,
          1.9601586,
          0.011856215,
          -2.6718032,
          -2.9778361,
          3.529702,
          -1.8714753,
          1.4729168,
          -3.2668195,
          1.7039654,
          3.0112724,
          2.2002308,
          -3.3351886,
          0.9714155,
          10.321379,
          -2.6394753,
          1.8345181,
          -3.1951165,
          -2.0244966,
          4.4474564,
          0.6844385,
          3.2416213,
          4.320586,
          2.3503857,
          0.865761,
          -3.5910017,
          -1.4472612,
          -1.3298458,
          4.341506,
          -2.6550581,
          4.720235,
          0.5254908,
          -1.3828206,
          -2.7174127,
          3.8675048,
          -4.7280917,
          3.6271281,
          -1.3710303,
          1.7934176,
          -3.6941957,
          5.6495256,
          4.177263,
          -2.8500566,
          -4.0540953,
          0.44434598,
          -3.1307285,
          3.8986957,
          -1.4708581,
          2.7356956,
          2.889059,
          -3.3146427,
          0.10145784,
          4.093757,
          -0.85370195,
          1.6581484,
          2.486214,
          -3.786119,
          1.7940953,
          2.2913392,
          3.0593305,
          -3.7411172,
          1.277464,
          2.4385962,
          -2.9774885,
          -2.164054,
          0.19537108,
          1.6061523,
          -3.7049897,
          2.129827,
          -1.5065053,
          3.2403567,
          -2.706109,
          4.942182,
          4.2523403,
          -2.6657326,
          4.911253,
          5.1542406,
          1.186645,
          -0.7380659,
          -0.38057953,
          -3.878743,
          -1.8077942,
          -0.04821098,
          -4.5047083,
          2.538592,
          -3.0130706,
          1.4620965,
          2.3025098,
          1.7515632,
          2.419942,
          4.7128367,
          2.3117275,
          -2.8910267,
          -4.3586125,
          -3.6530468,
          3.3810673,
          -0.9698451,
          2.9070222,
          3.1058812,
          -0.6202836,
          -2.4296813,
          2.6698248,
          -2.812542,
          -2.2055914,
          0.122703396,
          -3.1925488,
          0.422923,
          -2.8415496,
          0.36580846,
          -2.1701148,
          -2.9328516,
          5.1727858,
          0.58985853,
          -0.9723141,
          2.0516016,
          1.5856936,
          2.1381087,
          -3.7358375,
          -3.465628,
          4.1912804,
          -0.8534744,
          2.961532,
          -3.549992,
          -0.16543412,
          -0.38448063,
          -3.0826385,
          -2.8525162,
          4.657224,
          -0.2733459,
          -0.3257324,
          -2.8962843,
          -2.6002493,
          -4.1468415,
          1.0521287,
          -2.6231613,
          -1.0672824,
          -3.6314259,
          2.0835173,
          1.8652338,
          -3.4104335,
          -1.8307465,
          3.089581,
          -1.4816775,
          3.4685748,
          -1.3639599,
          4.4689493,
          4.5289907,
          1.0310197,
          -0.69327515,
          1.6863832,
          3.6161895,
          1.9668337,
          2.0206275,
          3.2603927,
          -0.7924903,
          0.6095577,
          1.3618866,
          2.4594674,
          0.8019461,
          -1.05157,
          -3.6018398,
          -1.1483536,
          4.777248,
          3.934136,
          1.5086592,
          0.9951586,
          3.2843258,
          1.2298555,
          -1.2815857,
          2.0831432,
          -0.6866,
          -3.0820065,
          -2.3564262,
          0.3971151,
          -0.3887568,
          3.3065844,
          0.5186697,
          2.3793242,
          3.3573675,
          2.64894,
          -2.2607214,
          4.8117127,
          1.4849429,
          -4.4490166,
          1.8165162,
          1.9081426,
          1.5717634,
          0.114372924,
          1.6962669,
          -2.1236794,
          2.847205,
          3.6729617,
          -2.103801,
          -2.4914956,
          1.2663504,
          0.97650796,
          5.0767612,
          1.6586386,
          -1.4783841,
          -1.9462229,
          -2.883123,
          1.6109331,
          3.3631983,
          -1.9487361,
          -1.9464859,
          3.339415,
          -2.7271295,
          4.4564767,
          1.8183178,
          -0.08651061,
          -0.11591836,
          4.3830614,
          -3.2162542,
          -0.12045829,
          -0.020743107,
          -3.2171478,
          3.7094593,
          -1.6658965,
          -3.9942644,
          -3.607987,
          1.583713,
          -0.4679542,
          4.64011,
          1.9410915,
          3.8285139,
          -2.7622037,
          3.0249224,
          5.0101657,
          -4.031913,
          0.075306945,
          3.2042303,
          -0.58967733,
          1.0894673,
          -1.499853,
          4.6448503,
          -1.6752728,
          -0.23493598,
          -1.3624856,
          -3.0385845,
          0.6498018,
          1.8252441,
          4.0004096
         ],
         "xaxis": "x",
         "y": [
          -0.29668358,
          1.2993984,
          1.6344024,
          2.0131333,
          2.2348206,
          -1.7117221,
          2.818743,
          1.1186917,
          1.609549,
          1.2246233,
          0.71218306,
          -1.6853021,
          -3.6672127,
          0.9195855,
          1.1743773,
          2.2599425,
          -2.1449354,
          2.8963332,
          -0.63971436,
          3.6943395,
          2.8510966,
          2.7277408,
          -1.953962,
          3.3902535,
          1.3706304,
          4.1035423,
          1.3389285,
          2.2359138,
          2.0682313,
          2.360951,
          0.3330946,
          -0.82273936,
          4.007444,
          -2.382525,
          1.6404533,
          2.620322,
          0.90222514,
          -3.5605953,
          2.9122684,
          2.4152894,
          -3.4271102,
          0.5632005,
          0.8259197,
          3.244257,
          2.6805725,
          -1.458218,
          3.3760767,
          -0.7659335,
          1.0116434,
          1.4787242,
          1.5130546,
          3.4505594,
          3.1645966,
          2.006208,
          -2.5669672,
          2.8885245,
          3.0117707,
          0.43490866,
          0.8192745,
          4.050079,
          0.12364386,
          -0.46894252,
          2.0646584,
          0.440887,
          -0.98583496,
          1.8772984,
          2.6284707,
          1.2459036,
          -0.359093,
          2.224691,
          3.2839098,
          2.0577848,
          1.2654054,
          3.7618618,
          1.4637552,
          4.11737,
          -1.8522197,
          1.3082036,
          -0.4745294,
          3.0088983,
          2.7283494,
          2.9239068,
          4.758316,
          -4.9337673,
          1.4921815,
          3.4125226,
          1.9694592,
          3.6256428,
          -0.2550966,
          2.5790195,
          3.4998343,
          2.5964596,
          -3.3641834,
          -0.54798293,
          0.61918557,
          -1.5158279,
          0.009364917,
          0.6064579,
          2.1700535,
          2.9093022,
          0.81538343,
          -2.137884,
          1.5680711,
          1.3793666,
          1.9255837,
          -1.2167032,
          4.4846992,
          -1.3139615,
          3.460061,
          0.09731617,
          3.946039,
          3.5700064,
          1.6592265,
          1.3727031,
          2.183446,
          0.4535372,
          2.1569262,
          3.6204524,
          1.5392437,
          4.5517726,
          4.3414764,
          3.1649516,
          2.1789062,
          3.5467937,
          3.8746748,
          1.5697289,
          3.746394,
          -3.188265,
          -1.5655042,
          2.1754045,
          -2.4016948,
          -2.162346,
          -2.8379207,
          2.4073405,
          0.3358831,
          3.3617964,
          2.267968,
          0.9542624,
          -1.9923409,
          1.2949185,
          -2.7428772,
          -1.6462606,
          -0.11956593,
          -6.2907796,
          -3.77318,
          -1.3296168,
          -3.3826637,
          -2.3052754,
          -1.2810981,
          -3.6147156,
          -3.3463717,
          -0.14497788,
          -1.0977417,
          -2.1119876,
          0.16691856,
          -1.9776738,
          0.79626435,
          -4.090765,
          -2.3074126,
          -0.100796774,
          19.5879,
          -4.014905,
          -6.4029665,
          3.541423,
          -2.2030218,
          3.3954587,
          1.5808053,
          -3.6876245,
          19.58196,
          1.943718,
          2.429218,
          2.8852148,
          -0.38278598,
          3.4024713,
          2.7216265,
          -0.099902,
          3.4337802,
          0.51008344,
          2.4681728,
          -1.4430552,
          -1.3223944,
          1.2259212,
          0.548633,
          -0.56878096,
          2.3882463,
          2.221861,
          2.7341557,
          1.0313889,
          0.006643576,
          2.986898,
          0.83831066,
          -2.4112833,
          1.2368066,
          2.9025211,
          1.6053524,
          0.26762748,
          -0.07963417,
          1.604958,
          -0.9235047,
          0.5732255,
          -1.0643388,
          2.0365496,
          -2.575486,
          -1.3303512,
          1.5509716,
          0.053493135,
          0.5567896,
          3.1728733,
          2.282167,
          -2.2969306,
          0.78157717,
          -0.030309256,
          2.4812796,
          -5.9321985,
          2.7099495,
          0.48168492,
          -1.6488762,
          1.5743814,
          -0.13554034,
          2.7944977,
          3.4454498,
          1.2675481,
          1.6030227,
          -1.2716703,
          1.3607422,
          -0.78924936,
          1.9909483,
          0.038189877,
          -3.1882646,
          1.0546699,
          3.1517665,
          0.9199187,
          1.6242782,
          1.3620926,
          2.7684424,
          1.9965694,
          -1.3976129,
          -2.5004158,
          2.0015922,
          -2.1058214,
          -0.5461512,
          -5.4427605,
          -1.1664476,
          -0.16915846,
          1.7021595,
          -1.5384065,
          -0.14404128,
          1.610842,
          2.0416477,
          3.9763865,
          3.9875426,
          0.69787943,
          -0.7468805,
          -3.6014822,
          1.4429259,
          2.628626,
          2.563858,
          -1.1858839,
          1.9172605,
          3.654676,
          -3.056541,
          4.8765574,
          -6.1910076,
          4.21975,
          -1.2763798,
          -5.769921,
          0.9603785,
          -3.0397832,
          4.1193814,
          1.8832723,
          1.3782638,
          -3.1620262,
          2.0880146,
          -0.1413223,
          2.6241035,
          -0.9931045,
          1.6369358,
          1.5801414,
          0.6442275,
          -1.0346487,
          0.74294883,
          -0.43148294,
          3.8948123,
          3.1870005,
          -0.69305784,
          -1.7450464,
          2.808231,
          1.8898427,
          3.0419593,
          2.77918,
          2.4281416,
          -0.6140959,
          -2.1808593,
          -2.4642901,
          2.3379006,
          2.6665318,
          2.1937485,
          -2.4659297,
          -0.1877759,
          3.5400767,
          2.4317002,
          1.9635835,
          4.1491103,
          0.5287897,
          -1.1871058,
          2.105944,
          3.1757877,
          -0.77922285,
          -1.0151964,
          2.2048674,
          0.3623105,
          1.7942904,
          2.7124634,
          -0.984026,
          -4.053344,
          -1.5616307,
          0.12704745,
          -1.671414,
          2.3450394,
          -2.2450876,
          -0.72048444,
          -0.8691197,
          2.6146424,
          0.75344527,
          -0.6494579,
          -1.4560794,
          0.4853972,
          2.6593287,
          4.3228817,
          2.3429542,
          0.8660841,
          3.571347,
          2.8170493,
          3.6433113,
          -3.1435442,
          -3.296157,
          -4.449633,
          1.4041303,
          -2.4165907,
          -2.2248979,
          -2.3278599,
          3.1476758,
          1.5715737,
          -0.1954155,
          2.488747,
          4.0628257,
          1.7924454,
          2.5447361,
          0.21780828,
          1.1087983,
          -0.59318507,
          3.8174202,
          0.11762262,
          0.23839015,
          0.89150023,
          3.683502,
          0.03647325,
          2.8770916,
          0.35346237,
          -4.0927677,
          4.679052,
          2.4162102,
          3.2022638,
          3.0082097,
          -0.82602525,
          2.0133536,
          1.8822005,
          2.175154,
          3.7588904,
          -0.8475031,
          4.331656,
          -0.06712438,
          0.7807597,
          2.1954763,
          -1.1650667,
          -4.4138675,
          3.2508779,
          1.7724502,
          -2.1732528,
          -1.2812762,
          0.71579903,
          0.49226522,
          -1.999126,
          3.4807405,
          -2.324358,
          -2.1917229,
          3.3858526,
          2.624666,
          -0.8319074,
          3.2598386,
          3.4318547,
          -0.4187561,
          1.7986116,
          -2.9503424,
          -2.5194454,
          -2.3143198,
          2.6922557,
          2.3533168,
          1.8563133,
          0.016610589,
          3.8828056,
          2.9432147,
          -5.780642,
          1.0937026,
          -1.9135901,
          2.5775177,
          3.2715187,
          1.4353312,
          -0.8201095,
          -0.58521277,
          0.02680027,
          -1.4058546,
          0.9781036,
          2.2170935,
          3.6844335,
          3.0203407,
          1.7398366,
          -2.2667813,
          -1.0417001,
          1.0438875,
          -0.3201919,
          1.6116575,
          -1.3627491,
          1.422726,
          3.9743762,
          2.3715556,
          3.2569802,
          -0.07426854,
          3.865171,
          -3.1567204,
          2.857892,
          3.7489536,
          2.014341,
          2.167429,
          1.0870268,
          -2.5385008,
          2.0937665,
          2.4239674,
          -1.4079245,
          0.13179657,
          2.1542106,
          3.457108,
          0.20458694,
          2.0354183,
          0.5149354,
          1.0828103,
          -2.9394238,
          -2.61087,
          -0.14756536,
          -1.174623,
          1.7544919,
          4.934938,
          -1.6265594,
          3.999017,
          0.13099422,
          -2.8010535,
          2.3127933,
          1.1158026,
          0.9265455,
          -3.6387181,
          1.3595551,
          2.4360516,
          -0.81640714,
          -1.8633441,
          4.8152976,
          2.4990945,
          1.2767265,
          3.336993,
          -1.6784428,
          -1.2384673,
          -0.20640558,
          -2.3581095,
          2.4680955,
          3.7579494,
          1.411049,
          3.2027192,
          -0.9505187,
          3.0713573,
          -0.37014034,
          0.55068046,
          -0.9830151,
          3.2498994,
          2.8933032,
          1.5156249,
          0.32762334,
          -0.5103714,
          -1.4433545,
          -3.3341494,
          -1.236994,
          -0.8245325,
          2.3081405,
          1.1214118,
          2.493952,
          -1.1925017,
          2.6489942,
          -3.10522,
          1.531,
          -1.4213669,
          2.7135534,
          2.9426146,
          0.6348058,
          1.6718076,
          -0.6006912,
          -4.5430093,
          4.371902,
          0.7614203,
          1.8945483,
          1.969907,
          -0.89044863,
          1.2630234,
          2.661347,
          2.3490956,
          -2.5224254,
          1.2332113,
          -0.7631167,
          2.956189,
          -1.760083,
          0.54858255,
          -0.20807986,
          1.5059401,
          -1.7534249,
          -2.5066571,
          -1.6131171,
          1.1073892,
          0.9261214,
          -2.2724655,
          3.4266822,
          0.8937697,
          -4.898901,
          -5.1646886,
          0.6942883,
          2.974543,
          1.0302299,
          -1.0730886,
          -0.49048805,
          2.740894,
          2.2216802,
          4.8280306,
          4.374764,
          3.8295019,
          -0.25371593,
          0.41772836,
          -0.072274014,
          0.9936239,
          0.9975895,
          -1.4277251,
          -3.1227763,
          -0.36022764,
          1.1525902,
          -0.6145014,
          3.9021657,
          1.9912869,
          -1.4441125,
          0.1953751,
          -3.4344883,
          -2.5550027,
          -0.07799089,
          3.147853,
          0.86231065,
          -0.51116383,
          -1.8498255,
          1.5394717,
          -2.0070987,
          -2.0092824,
          -0.699916,
          0.7518441,
          3.2141554,
          1.7879866,
          1.9888687,
          1.9415833,
          1.6800312,
          3.21659,
          -5.5334363,
          0.589668,
          -5.533614,
          -0.51142263,
          -2.8065963,
          0.5607053,
          3.1988785,
          1.2371459,
          -0.52597237,
          -1.8195937,
          -0.18501079,
          -2.7599654,
          -1.6725128,
          0.52459764,
          -2.5014856,
          0.2380017,
          1.4671435,
          -2.4821255,
          -0.9082556,
          0.16681848,
          -0.3182539,
          -0.7249843,
          -1.5750989,
          2.962766,
          4.519507,
          0.24097395,
          3.5021327,
          0.24820352,
          0.5433779,
          1.7589923,
          1.2033733,
          0.41804728,
          0.41200328,
          4.25539,
          -2.1972685,
          0.6066369,
          -1.1042283,
          2.3748448,
          1.4481791,
          -2.1274052,
          -5.1778336,
          -1.9482957,
          3.1825414,
          0.08733952,
          2.9941654,
          1.8949909,
          -1.7114139,
          1.0647117,
          -0.6441337,
          -2.2371988,
          3.9695418,
          0.6715536,
          -0.13435489,
          4.4304724,
          1.7301576,
          2.4567738,
          -0.3592677,
          -0.81541675,
          -3.102211,
          2.9830935,
          4.138477,
          -2.224752,
          1.8082694,
          -2.2697973,
          -2.1070328,
          2.6551294,
          -1.6163251,
          -0.07584483,
          0.35228798,
          -1.4270617,
          3.2250187,
          4.1879873,
          1.1584551,
          0.10831887,
          -0.015250094,
          -0.3634241,
          0.2904719,
          -1.9647664,
          0.11769555,
          1.0243659,
          3.006976,
          -1.3042245,
          -1.5464107,
          4.3845115,
          1.6377386,
          3.3157957,
          0.9315122,
          3.5406816,
          1.2748853,
          -0.76385665,
          0.65422183,
          2.4265742,
          0.41568407,
          -1.3065213,
          -0.30954602,
          1.1947526,
          2.5084248,
          2.312745,
          2.2713645,
          -0.5204301,
          3.442082,
          1.0380665,
          -0.87029886,
          0.9821831,
          3.5252316,
          -1.2540635,
          -3.178032,
          0.42029852,
          2.2368774,
          0.71675223,
          2.9194343,
          3.4751992,
          0.45509556,
          2.3618388,
          -0.11218918,
          -0.92100054,
          1.1625836,
          0.9952905,
          3.817604,
          3.4763594,
          2.2593331,
          2.6912532,
          3.484758,
          -0.42077357,
          -0.027943023,
          3.4282117,
          2.5314636,
          -1.1014231,
          4.439462,
          3.9154472,
          4.74693,
          3.6015942,
          -1.3195232,
          0.27253672,
          1.7117792,
          3.4133968,
          1.534747,
          1.6293557,
          0.5959769,
          2.3220956,
          3.989002,
          -2.172184,
          19.580025,
          2.0094554,
          3.696181,
          1.4870476,
          -2.2431686,
          1.686342,
          1.6647842,
          2.0600362,
          1.6177512,
          -1.9560854,
          -5.735527,
          2.6801853,
          -1.4893119,
          -1.8199903,
          -0.46775502,
          4.1369166,
          1.9754227,
          4.340904,
          4.777116,
          1.9554874,
          -0.69249254,
          1.6783601,
          2.4626763,
          -3.4962287,
          -1.6166782,
          1.8910568,
          1.9264104,
          0.9001858,
          2.1270628,
          2.1812954,
          -1.6111236,
          -0.92485654,
          -0.025781715,
          1.3135965,
          2.8750863,
          2.7099948,
          -2.2542589,
          -0.1242225,
          1.5715842,
          3.7294502,
          4.586406,
          1.1842301,
          0.38988987,
          2.620032,
          0.6295233,
          -1.9797014,
          -1.6684173,
          1.428996,
          3.5937867,
          2.8589962,
          -0.81521475,
          1.7823279,
          2.3312848,
          -1.037818,
          3.7738209,
          -0.5189413,
          1.6969283,
          -2.3326068,
          0.907172,
          1.8811741,
          -0.33181658,
          1.4985709,
          0.88330626,
          -4.9002357,
          -2.0083642,
          2.49821,
          2.5074303,
          -1.0760616,
          -1.764073,
          2.9148722,
          -2.4557312,
          -3.4798803,
          -0.50341433,
          -2.508413,
          2.8489492,
          0.5517998,
          0.31157693,
          0.7670788,
          1.4306194,
          -0.21136566,
          2.9142962,
          0.8535184,
          -3.4147758,
          -0.81169856,
          -2.812803,
          -3.6929622,
          -1.2498518,
          -0.04860663,
          3.4671888,
          4.1223803,
          2.3761814,
          -0.41235563,
          -1.4253777,
          -0.033153962,
          4.072666,
          -0.9928877,
          -1.0934856,
          0.56732386,
          -2.384063,
          3.3967087,
          0.58839774,
          3.703277,
          -2.6671658,
          3.2228754,
          2.1196826,
          0.4518025,
          -0.9072222,
          -2.8950782,
          -2.2774887,
          2.8188634,
          -1.0358257,
          -2.6838646,
          0.9788782,
          -0.6929637,
          -2.9988165,
          3.414815,
          -0.7469489,
          -0.8689507,
          -2.8672352,
          -1.3325553,
          -1.1364813,
          -1.1713741,
          -0.7852599,
          -1.84606,
          -0.53617275,
          -1.7611674,
          0.7151538,
          0.24476835,
          4.116746,
          2.186215,
          -0.010591195,
          -0.5243132,
          -0.9262936,
          3.2341087,
          4.94706,
          -0.055955637,
          -1.9513265,
          -1.6789944,
          3.9531748,
          -3.1929696,
          2.5846217,
          4.0160418,
          3.3246636,
          2.5254183,
          -3.7165346,
          3.5894256,
          0.043032654,
          3.9656868,
          -0.042239986,
          0.6251293,
          -1.1110983,
          3.8444104,
          1.8858829,
          -0.56040233,
          1.673707,
          2.093868,
          -2.010813,
          2.2761178,
          -1.0251191,
          3.0248775,
          -3.660155,
          2.342293,
          -2.3822398,
          2.7992356,
          -1.0664264,
          -2.35097,
          -1.5242443,
          1.212483,
          3.8977697,
          1.7038867,
          3.810089,
          -1.8016188,
          0.8329879,
          4.1273518,
          3.8689172,
          0.9407518,
          -0.21223596,
          2.379264,
          0.03610848,
          -0.57431287,
          2.366309,
          -4.569318,
          0.34849676,
          -4.106875,
          -2.2876232,
          0.3891717,
          -2.8781686,
          -1.0305011,
          3.6088343,
          1.0162884,
          -0.802735,
          -2.7513256,
          0.015659252,
          -1.2916102,
          -3.56651,
          -2.9503696,
          2.8712735,
          1.2929236,
          2.0981681,
          2.5648031,
          -1.3035089,
          -2.5172598,
          2.0578823,
          2.9767325,
          3.1096587,
          1.671386,
          1.793101,
          2.5536215,
          1.9494275,
          3.363759,
          2.8612053,
          2.2047627,
          1.9911274,
          0.5805956,
          3.640564,
          4.2024627,
          0.22612292,
          2.3880315,
          -0.60244095,
          -1.2715391,
          1.798046,
          4.1335163,
          0.674321,
          1.3348852,
          -2.1338246,
          3.145057,
          2.2754073,
          3.2443657
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "hat is dynamic padding? In the \"Batching Inputs together\" video, we have seen that to be able to gro..."
          ],
          [
           "ow to slice and dice a dataset. Most of the time, the data you work with won’t be perfectly prepared..."
          ],
          [
           "he Hugging Face Datasets library: A Quick overview. The Hugging Face Datasets library is a library t..."
          ],
          [
           "efore diving in character-based tokenization, understanding why this kind of tokenization is interes..."
          ],
          [
           "Normalization and pre-tokenization[[normalization-and-pre-tokenization]]\n\n<CourseFloatingBanner chap..."
          ],
          [
           "```\n\nit will split on whitespace and punctuation as well, but it will keep the spaces and replace th..."
          ],
          [
           "ow to preprocess pairs of sentences? We have seen how to tokenize single sentences and batch them to..."
          ],
          [
           "The Hugging Face Course\n\nThis repo contains the content that's used to create the **[Hugging Face co..."
          ],
          [
           "| Language                                                                      | Source            ..."
          ],
          [
           "| [Korean](https://huggingface.co/course/ko/chapter1/1) (WIP)                   | [`chapters/ko`](ht..."
          ],
          [
           "### Translating the course into your language\n\nAs part of our mission to democratise machine learnin..."
          ],
          [
           "```\n\n**📋 Copy-paste the English files with a new language code**\n\nThe course files are organised und..."
          ],
          [
           "What to do when you get an error[[what-to-do-when-you-get-an-error]]\n\n<CourseFloatingBanner chapter=..."
          ],
          [
           "```\n\n```python out\n\"\"\"\nOSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squa..."
          ],
          [
           "```\n\n```python out\n\"\"\"\n---------------------------------------------------------------------------\nA..."
          ],
          [
           "hat is transfer learning? The idea of Transfer Learning is to leverage the knowledge acquired by a m..."
          ],
          [
           "ow to batch inputs together? In this video, we will see how to batch input sequences together. In ge..."
          ],
          [
           "upercharge your Pytorch training loop with Hugging Face Accelerate. There are multiple setups on whi..."
          ],
          [
           "Building your first demo[[building-your-first-demo]]\n\n<CourseFloatingBanner chapter={9}\n  classNames..."
          ],
          [
           "Natural Language Processing[[natural-language-processing]]\n\n<CourseFloatingBanner\n    chapter={1}\n  ..."
          ],
          [
           "Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={8}\n    classNames=\"absolute z-10 ri..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Sharing pretrained models[[sharing-pretrained-models]]\n\n{#if fw ===..."
          ],
          [
           "```\n\nThis will create the new repository `dummy-model` in your profile, and populate it with your mo..."
          ],
          [
           "```\n\n\nAdditionally, it offers the very powerful `Repository` class to manage a local repository. We ..."
          ],
          [
           "```\n\nCongratulations! You just pushed your first files on the hub.\n\n### The git-based approach[[the-..."
          ],
          [
           "```\n{/if}\n\nPushing can take a bit of time, depending on the speed of your internet connection and th..."
          ],
          [
           "n these few videos, we'll take a look at the tokenizers. In Natural Language Processing, most of the..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fine-tuning a masked language model[[fine-tuning-a-masked-language-..."
          ],
          [
           "```\n\n{/if}\n\nWith around 67 million parameters, DistilBERT is approximately two times smaller than th..."
          ],
          [
           "```\n\nYep, these are certainly movie reviews, and if you're old enough you may even understand the co..."
          ],
          [
           "```\n\nNote that in the last step of `group_texts()` we create a new `labels` column which is a copy o..."
          ],
          [
           "```\n\nNice, it worked! We can see that the `[MASK]` token has been randomly inserted at various locat..."
          ],
          [
           "```\n\nThis has automatically created new `train` and `test` splits, with the training set size set to..."
          ],
          [
           "```\n\n{:else}\n\nAssuming our test set consists mostly of sentences that are grammatically correct, the..."
          ],
          [
           "```\n\nThere is just one last thing to do before training: create a model repository on the Hugging Fa..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Using pretrained models[[using-pretrained-models]]\n\n{#if fw === 'pt..."
          ],
          [
           "Understanding the Interface class[[understanding-the-interface-class]]\n\n<CourseFloatingBanner chapte..."
          ],
          [
           "```\n\n<iframe src=\"https://course-demos-generate-tone.hf.space\" frameBorder=\"0\" height=\"450\" title=\"G..."
          ],
          [
           "ou are at the right place if you want to understand what the Byte pair Encoding subword tokenization..."
          ],
          [
           "ome bugs in your code are very straightforward. You try running it, you get a syntax error somewhere..."
          ],
          [
           "How to write a good issue[[how-to-write-a-good-issue]]\n\n<CourseFloatingBanner chapter={8}\n  classNam..."
          ],
          [
           "oading a custom dataset. Although the Hugging Face Hub hosts over a thousand public datasets, you'll..."
          ],
          [
           "Summary[[summary]]\n\n<CourseFloatingBanner\n    chapter={1}\n    classNames=\"absolute z-10 right-0 top-..."
          ],
          [
           "What if my dataset isn't on the Hub?[[what-if-my-dataset-isnt-on-the-hub]]\n\n<CourseFloatingBanner ch..."
          ],
          [
           "```\n\nThis returns the same `DatasetDict` object obtained above, but saves us the step of manually do..."
          ],
          [
           "rite your own training loop in PyTorch. In this video, we will look at how we can do the same fine-t..."
          ],
          [
           "atasets and DataFrames equals love. Although the processing functions of Datasets will cover most th..."
          ],
          [
           "n this video, we'll study the decoder architecture. An example of a popular decoder-only architectur..."
          ],
          [
           "n our other videos, and as always, there'll be links below if you want to check those out, we showed..."
          ],
          [
           "Unigram tokenization[[unigram-tokenization]]\n\n<CourseFloatingBanner chapter={6}\n  classNames=\"absolu..."
          ],
          [
           "```\n(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)\n```\n\nThe tokenization of each word..."
          ],
          [
           "```\n\nWe can already try our initial model on some words:\n\n```python\nprint(encode_word(\"Hopefully\", m..."
          ],
          [
           "n this video, we're going to go over the HuggingFace Model Hub navigation. This is the huggingface.c..."
          ],
          [
           "n this video, we're going to see how to load and fine-tune a pre-trained model. It's very quick, and..."
          ],
          [
           "Part 2 Release Event[[part-2-release-event]]\n\nFor the release of part 2 of the course, we organized ..."
          ],
          [
           "Lysandre is a Machine Learning Engineer at Hugging Face where he is involved in many open source pro..."
          ],
          [
           "How do Transformers work?[[how-do-transformers-work]]\n\n<CourseFloatingBanner\n    chapter={1}\n    cla..."
          ],
          [
           "## Transfer Learning[[transfer-learning]]\n\n<Youtube id=\"BqqfQnyjmgg\" />\n\n*Pretraining* is the act of..."
          ],
          [
           "To speed things up during training (when the model has access to target sentences), the decoder is f..."
          ],
          [
           "n this video we'll take a look at how you upload your very own dataset to the Hub. The first you'll ..."
          ],
          [
           "n this video we take a look at the mysterious sounding metric called Perplexity. You might have enco..."
          ],
          [
           "Decoder models[[decoder-models]]\n\n<CourseFloatingBanner\n    chapter={1}\n    classNames=\"absolute z-1..."
          ],
          [
           "n this video, we'll study the encoder architecture. An example of a popular encoder-only architectur..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Translation[[translation]]\n\n{#if fw === 'pt'}\n\n<CourseFloatingBanne..."
          ],
          [
           "```\n\n```python out\n[{'translation_text': 'Par défaut pour les threads élargis'}]\n```\n\nAnother exampl..."
          ],
          [
           "```\n\n{:else}\n\n## Fine-tuning the model with Keras[[fine-tuning-the-model-with-keras]]\n\nFirst things ..."
          ],
          [
           "```\n\n```python out\n{'score': 46.750469682990165,\n 'counts': [11, 6, 4, 3],\n 'totals': [12, 11, 10, 9..."
          ],
          [
           "```\n\nNext, we define a `PushToHubCallback` to upload our model to the Hub during training, as we saw..."
          ],
          [
           "```\n\nNext we reinstantiate our model, to make sure we're not continuing the fine-tuning from before ..."
          ],
          [
           "Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={6}\n    classNames=\"absolute z-10 ri..."
          ],
          [
           "Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={5}\n    classNames=\"absolute z-10 ri..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Question answering[[question-answering]]\n\n{#if fw === 'pt'}\n\n<Cours..."
          ],
          [
           "```\n\n```python out\n{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': ..."
          ],
          [
           "```\n\nAs we can see, our example has been in split into four inputs, each of them containing the ques..."
          ],
          [
           "```\n\n```python out\n'Theoretical answer: a Marian place of prayer and reflection, decoded example: [C..."
          ],
          [
           "```\n\nWe can apply this function on the whole validation dataset like before:\n\n```py\nvalidation_datas..."
          ],
          [
           "```\n\nFor ease of experimentation, let's convert these outputs to NumPy arrays:\n\n```python\nstart_logi..."
          ],
          [
           "```\n\nWe can check it works on our predictions:\n\n```python\ncompute_metrics(start_logits, end_logits, ..."
          ],
          [
           "```\n\n{:else}\n\nOnce the training is complete, we can finally evaluate our model (and pray we didn't s..."
          ],
          [
           "```\n\n```python out\n'sgugger/bert-finetuned-squad-accelerate'\n```\n\nThen we can clone that repository ..."
          ],
          [
           "ow to write a good issue on GitHub? GitHub is the main place for the Hugging Face open source librar..."
          ],
          [
           "The Hugging Face Hub[[the-hugging-face-hub]]\n\n<CourseFloatingBanner\n    chapter={4}\n    classNames=\"..."
          ],
          [
           "n this video, we will study together \"the Unigram Language Model subword tokenization algorithm\".\n\nT..."
          ],
          [
           "Creating your own dataset[[creating-your-own-dataset]]\n\n<CourseFloatingBanner chapter={5}\n  classNam..."
          ],
          [
           "```\n\n<Tip warning={true}>\n\n⚠️ Do not share a notebook with your `GITHUB_TOKEN` pasted in it. We reco..."
          ],
          [
           "```\n\n```python out\n[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/89759..."
          ],
          [
           "```\n\nOnce we've done this, we can upload our dataset by running:\n\n```py\nissues_with_comments_dataset..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n<!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-..."
          ],
          [
           "### 9. What does the `result` variable contain in this code sample?\n\n```py\nfrom transformers import ..."
          ],
          [
           "```\n\n<Question\n\tchoices={[\n\t\t{\n\t\t\ttext: \"A list of strings, each string being a token\",\n\t\t\texplain: ..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Processing the data[[processing-the-data]]\n\n{#if fw === 'pt'}\n\n<Cou..."
          ],
          [
           "```\n\nHowever, we can't just pass two sequences to the model and get a prediction of whether the two ..."
          ],
          [
           "```\n\nThe way the 🤗 Datasets library applies this processing is by adding new fields to the datasets,..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Models[[models]]\n\n{#if fw === 'pt'}\n\n<CourseFloatingBanner chapter=..."
          ],
          [
           "```\n\nThis saves two files to your disk:\n\n{#if fw === 'pt'}\n```\nls directory_on_my_computer\n\nconfig.j..."
          ],
          [
           "ow to instantiate a Transformers model? In this video we will look at how we can create and use a mo..."
          ],
          [
           "he Hugging Face Datasets library: A Quick overview. The Hugging Face Datasets library is a library t..."
          ],
          [
           "Introduction to Gradio[[introduction-to-gradio]]\n\n<CourseFloatingBanner\n    chapter={9}\n    classNam..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Handling multiple sequences[[handling-multiple-sequences]]\n\n{#if fw..."
          ],
          [
           "```\n\nIn order to work around this, we'll use *padding* to make our tensors have a rectangular shape...."
          ],
          [
           "Advanced Interface features[[advanced-interface-features]]\n\n<CourseFloatingBanner chapter={9}\n  clas..."
          ],
          [
           "n this video we will see together what is the purpose of training a tokenizer, what are the key step..."
          ],
          [
           "he Trainer API. The Transformers library provides a Trainer API that allows you to easily fine-tune ..."
          ],
          [
           "he tokenizer pipeline. In this video, we'll look at how a tokenizer converts raw text to numbers tha..."
          ],
          [
           "Sharing demos with others[[sharing-demos-with-others]]\n\n<CourseFloatingBanner chapter={9}\n  classNam..."
          ],
          [
           "```\n\nNow that we have a `predict()` function. The next step is to define and launch our gradio inter..."
          ],
          [
           "ow to preprocess pairs of sentences? We have seen how to tokenize single sentences and batch them to..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fast tokenizers in the QA pipeline[[fast-tokenizers-in-the-qa-pipel..."
          ],
          [
           "```\n\n{#if fw === 'pt'}\n\n```python out\ntorch.Size([1, 66]) torch.Size([1, 66])\n```\n\n{:else}\n\n```pytho..."
          ],
          [
           "```\n\n```python out\n461\n```\n\nSo, we'll need to truncate our inputs at that maximum length. There are ..."
          ],
          [
           "```\n\n{:else}\n\n```py\nsequence_ids = inputs.sequence_ids()\n# Mask everything apart from the tokens of ..."
          ],
          [
           "he tokenization pipeline involves several steps that convert raw text into numbers. In this video, w..."
          ],
          [
           "et's see how to preprocess a dataset for summarization. This is the task of well summarizing a long ..."
          ],
          [
           "he post-processing step in a question answering task. When doing question answering, the processing ..."
          ],
          [
           "A full training[[a-full-training]]\n\n<CourseFloatingBanner chapter={3}\n  classNames=\"absolute z-10 ri..."
          ],
          [
           "```\n\n```python out\n{'accuracy': 0.8431372549019608, 'f1': 0.8907849829351535}\n```\n\nAgain, your resul..."
          ],
          [
           "Transformers, what can they do?[[transformers-what-can-they-do]]\n\n<CourseFloatingBanner chapter={1}\n..."
          ],
          [
           "```\n\n```python out\n[{'generated_text': 'In this course, we will teach you how to manipulate the worl..."
          ],
          [
           "```\n\nLike with text generation, you can specify a `max_length` or a `min_length` for the result.\n\n\n#..."
          ],
          [
           "sing the Python debugger in a notebook. In this video, we'll learn how to use the Python debugger in..."
          ],
          [
           "ow to instantiate a Transformers model? In this video we will look at how we can create and use a mo..."
          ],
          [
           "n this video, we're going to understand how to manage a model repository on the HuggingFace model hu..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Behind the pipeline[[behind-the-pipeline]]\n\n{#if fw === 'pt'}\n\n<Cou..."
          ],
          [
           "```\n{:else}\nWe can download our pretrained model the same way we did with our tokenizer. 🤗 Transform..."
          ],
          [
           "🤗 Datasets, check![[datasets-check]]\n\n<CourseFloatingBanner\n    chapter={5}\n    classNames=\"absolute..."
          ],
          [
           "n this video we will see together what is the normalizer component that we find at the beginning of ..."
          ],
          [
           "Building a tokenizer, block by block[[building-a-tokenizer-block-by-block]]\n\n<CourseFloatingBanner c..."
          ],
          [
           "```\n\nOr we can build it from scratch:\n\n```python\ntokenizer.pre_tokenizer = pre_tokenizers.Whitespace..."
          ],
          [
           "```\n\nYou can then use this tokenizer like any other 🤗 Transformers tokenizer. You can save it with t..."
          ],
          [
           "```\n\nAnd we can test it works by encoding a pair of sentences:\n\n```python\nencoding = tokenizer.encod..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n<!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-..."
          ],
          [
           "{:else}\n\n### 9. Why is it often unnecessary to specify a loss when calling `compile()` on a Transfor..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n<!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-..."
          ],
          [
           "ext embeddings and semantic search. In this video we’ll explore how Transformer models represent tex..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-chapter-quiz]]\n\n<CourseFloatingB..."
          ],
          [
           "```\n\nWhich of the following might be a good choice for the title of a forum topic to ask for help?\n\n..."
          ],
          [
           "et's study the transformer architecture. This video is the introductory video to the encoders, decod..."
          ],
          [
           "Introduction to Gradio Blocks[[introduction-to-gradio-blocks]]\n\n<CourseFloatingBanner chapter={9}\n  ..."
          ],
          [
           "```\n\n<iframe src=\"https://course-demos-flip-text-image.hf.space\" frameBorder=\"0\" height=\"450\" title=..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-chapter-quiz]]\n\n<CourseFloatingB..."
          ],
          [
           "i, this is going to be a video about the push_to_hub API for Tensorflow and Keras. So, to get starte..."
          ],
          [
           "et's take a look at word-based tokenization. Word-based tokenization is the idea of splitting the ra..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Putting it all together[[putting-it-all-together]]\n\n{#if fw === 'pt..."
          ],
          [
           "n this video, I'm going to give you a very quick introduction to how our transformers models work to..."
          ],
          [
           "Gradio, check![[gradio-check]]\n\n<CourseFloatingBanner\n    chapter={9}\n    classNames=\"absolute z-10 ..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fast tokenizers' special powers[[fast-tokenizers-special-powers]]\n\n..."
          ],
          [
           "```\n\n```python out\nSylvain\n```\n\nAs we mentioned previously, this is all powered by the fact the fast..."
          ],
          [
           "```\n\n{:else}\n\n```py\nimport tensorflow as tf\n\nprobabilities = tf.math.softmax(outputs.logits, axis=-1..."
          ],
          [
           "```\n\n```python out\nHugging Face\n```\n\nTo write the code that post-processes the predictions while gro..."
          ],
          [
           "et's take a look at subword-based tokenization. Understanding why subword-based tokenization is inte..."
          ],
          [
           "et's see together what is the training strategy of the WordPiece algorithm and how it performs the t..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Summarization[[summarization]]\n\n{#if fw === 'pt'}\n\n<CourseFloatingB..."
          ],
          [
           "```\n\n```python out\nhome                      17679\napparel                   15951\nwireless         ..."
          ],
          [
           "```\n\nNow that we've prepared our corpus, let's take a look at a few possible Transformer models that..."
          ],
          [
           "```\n\nLet's walk through this code to understand what's happening. The first thing we've done is defi..."
          ],
          [
           "```\n\nand then download the punctuation rules:\n\n```python\nimport nltk\n\nnltk.download(\"punkt\")\n```\n\nNe..."
          ],
          [
           "```\n\n{/if}\n\nNext, we need to define a data collator for our sequence-to-sequence task. Since mT5 is ..."
          ],
          [
           "```\n\nAnd finally, we fit the model. We use a `PushToHubCallback` to save the model to the Hub after ..."
          ],
          [
           "```\n\n```python out\n'lewtun/mt5-finetuned-amazon-en-es-accelerate'\n```\n\nNow we can use this repositor..."
          ],
          [
           "et's study how to preprocess a dataset for token classification! Token classification regroups any t..."
          ],
          [
           "he fast tokenizers of the Transformers library are fast, but they also implement features that will ..."
          ],
          [
           "et's have a look inside the question answering pipeline. The question answering pipeline can extract..."
          ],
          [
           "Basic usage completed![[basic-usage-completed]]\n\n<CourseFloatingBanner\n    chapter={2}\n    className..."
          ],
          [
           "et's study how to preprocess a dataset for question answering! Question answering is the task of fin..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={7}..."
          ],
          [
           "hat happens inside the pipeline function? In this video, we will look at what actually happens when ..."
          ],
          [
           "et's see how to preprocess a dataset for translation. This is the task of well translating a sentenc..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fine-tuning, Check![[fine-tuning-check]]\n\n<CourseFloatingBanner\n   ..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Debugging the training pipeline[[debugging-the-training-pipeline]]\n..."
          ],
          [
           "```\n\nNow we'll use the model's internal loss, and this problem should be resolved!\n\n<Tip>\n\n✏️ **Your..."
          ],
          [
           "```\n\n*Now* we're getting somewhere! There are no `nan` values in our logits, which is reassuring. Bu..."
          ],
          [
           "```\n\n```python out\n2\n```\n\nNow we see the problem: the model thinks there are only two classes, but t..."
          ],
          [
           "```\n\nThen you can compare it with the first label, like so:\n\n```py\nlabels = batch[\"labels\"].numpy()\n..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Debugging the training pipeline[[debugging-the-training-pipeline]]\n..."
          ],
          [
           "```\n\n```python out\n'[CLS] conceptually cream skimming has two basic dimensions - product and geograp..."
          ],
          [
           "```\n\nThis code will fail because the `train_dataset` contains string columns, which the `Trainer` us..."
          ],
          [
           "```\n\nIt's pretty rare to get an error at this stage, but if you do get one, make sure to go back to ..."
          ],
          [
           "```\n\nIn this instance, there are no more problems, and our script will fine-tune a model that should..."
          ],
          [
           "Part 1 completed![[part-1-completed]]\n\n<CourseFloatingBanner\n    chapter={4}\n    classNames=\"absolut..."
          ],
          [
           "Bias and limitations[[bias-and-limitations]]\n\n<CourseFloatingBanner chapter={1}\n  classNames=\"absolu..."
          ],
          [
           "n this video, we'll study the encoder-decoder architecture. An example of a popular encoder-decoder ..."
          ],
          [
           "et's have a look inside the token classification pipeline. In the pipeline video, we looked at the d..."
          ],
          [
           "hat is the ROUGE metric? For many NLP tasks we can use common metrics like accuracy or F1 score, but..."
          ],
          [
           "WordPiece tokenization[[wordpiece-tokenization]]\n\n<CourseFloatingBanner chapter={6}\n  classNames=\"ab..."
          ],
          [
           "```\n\nFirst, we need to pre-tokenize the corpus into words. Since we are replicating a WordPiece toke..."
          ],
          [
           "emory mapping and streaming. In this video we'll take a look at two core features of the Datasets li..."
          ],
          [
           "Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={2}\n    classNames=\"absolute z-10 ri..."
          ],
          [
           "Introduction[[introduction]]\n\nWelcome to the Hugging Face course! This introduction will guide you t..."
          ],
          [
           "n this video we take a look at the data processing necessary to train causal language models. Causal..."
          ],
          [
           "hat is the BLEU metric? For many NLP tasks we can use common metrics like accuracy or F1 score, but ..."
          ],
          [
           "elcome to the Hugging Face Course! This course has been designed to teach you all about the Hugging ..."
          ],
          [
           "Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={1}\n    classNames=\"absolute z-10 ri..."
          ],
          [
           "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/ch..."
          ],
          [
           "```\n@misc{huggingfacecourse,\n  author = {Hugging Face},\n  title = {The Hugging Face Course, 2022},\n ..."
          ],
          [
           "ote: the following transcripts are associated with Merve Noyan's videos in the Hugging Face Tasks pl..."
          ],
          [
           "as recorded adlib - need to generate transcript with Whisper :)..."
          ],
          [
           "Big data? 🤗 Datasets to the rescue![[big-data-datasets-to-the-rescue]]\n\n<CourseFloatingBanner chapte..."
          ],
          [
           "```\n\n```python out\n'Iterated over 15518009 examples (about 19.5 GB) in 64.2s, i.e. 0.304 GB/s'\n```\n\n..."
          ],
          [
           "```\n\n```python out\n[{'meta': {'pmid': 11409574, 'language': 'eng'},\n  'text': 'Epidemiology of hypox..."
          ],
          [
           "et's see how we can preprocess our data for masked language modeling. As a reminder, masked language..."
          ],
          [
           "Subtitles for the course videos\n\nThis folder contains all the subtitles for the course videos on You..."
          ],
          [
           "he pipeline function. The pipeline function is the most high-level API of the Transformers library. ..."
          ],
          [
           "Sequence-to-sequence models[sequence-to-sequence-models]\n\n<CourseFloatingBanner\n    chapter={1}\n    ..."
          ],
          [
           "aving and reloading a dataset. In this video we'll take a look saving a dataset in various formats, ..."
          ],
          [
           "n our other videos we talked about the basics of fine-tuning a language model with Tensorflow (and a..."
          ],
          [
           "Tokenizers, check![[tokenizers-check]]\n\n<CourseFloatingBanner\n    chapter={6}\n    classNames=\"absolu..."
          ],
          [
           "et's have a look inside the question answering pipeline. The question answering pipeline can extract..."
          ],
          [
           "hat happens inside the pipeline function? In this video, we will look at what actually happens when ..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-chapter-quiz]]\n\n<CourseFloatingB..."
          ],
          [
           "```\n\n<Question\n\tchoices={[\n\t\t{\n\t\t\ttext: \"This &#60;mask> has been waiting for you.\",\n\t\t\texplain: \"Th..."
          ],
          [
           "n this video we will see how you can create your own tokenizer from scratch! To create your own toke..."
          ],
          [
           "Gradio Blocks Party[[gradio-blocks-party]]\n\nAlong with the release of the Gradio chapter of the cour..."
          ],
          [
           "Training a new tokenizer from an old one[[training-a-new-tokenizer-from-an-old-one]]\n\n<CourseFloatin..."
          ],
          [
           "```\n\nwhich will produce the exact same generator as before, but allows you to use more complex logic..."
          ],
          [
           "```\n\nThis will display a widget where you can enter your Hugging Face login credentials. If you aren..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n<!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-..."
          ],
          [
           "### 9. Why should you use the 🤗 Accelerate library?\n\n<Question\n\tchoices={[\n\t\t{\n\t\t\ttext: \"It provides..."
          ],
          [
           "et's have a look inside the token classification pipeline. In the pipeline video, we looked at the d..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fine-tuning a model with Keras[[fine-tuning-a-model-with-keras]]\n\n<..."
          ],
          [
           "```\n\nNow, we fit again:\n\n```py\nmodel.fit(tf_train_dataset, validation_data=tf_validation_dataset, ep..."
          ],
          [
           "he post-processing step in a question answering task. When doing question answering, the processing ..."
          ],
          [
           "Asking for help on the forums[[asking-for-help-on-the-forums]]\n\n<CourseFloatingBanner chapter={8}\n  ..."
          ],
          [
           "```\n\n```python output\nIndexError: index out of range in self\n```\n\nUh-oh, we've hit a problem -- and ..."
          ],
          [
           "ow to batch inputs together? In this video, we will see how to batch input sequences together. In ge..."
          ],
          [
           "n this video, we will see how to debug an error you encounter when running trainer.train(). As an ex..."
          ],
          [
           "Encoder models[[encoder-models]]\n\n<CourseFloatingBanner\n    chapter={1}\n    classNames=\"absolute z-1..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Token classification[[token-classification]]\n\n{#if fw === 'pt'}\n\n<C..."
          ],
          [
           "```\n\n```python out\n'EU    rejects German call to boycott British lamb .'\n'B-ORG O       B-MISC O    ..."
          ],
          [
           "```\n\nNote that we haven't padded our inputs yet; we'll do that later, when creating the batches with..."
          ],
          [
           "```\n\nNote also that we don't supply a `loss` argument to `compile()`. This is because the models can..."
          ],
          [
           "```\n\n\n```python out\n{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},\n 'MISC'..."
          ],
          [
           "```\n\nThen we will need an optimizer. We'll use the classic `AdamW`, which is like `Adam`, but with a..."
          ],
          [
           "```\n\nIn case this is the first time you're seeing a model saved with 🤗 Accelerate, let's take a mome..."
          ],
          [
           "n this video we take a look at setting up a custom loss function for training. In the default loss f..."
          ],
          [
           "Time to slice and dice[[time-to-slice-and-dice]]\n\n<CourseFloatingBanner chapter={5}\n  classNames=\"ab..."
          ],
          [
           "```\n\nwhere `lambda` is one of Python's special [keywords](https://docs.python.org/3/reference/lexica..."
          ],
          [
           "```\n\nAs you saw in [Chapter 3](/course/chapter3), we can pass one or several examples to the tokeniz..."
          ],
          [
           "```\n\nNow this works without error. We can check that our new dataset has many more elements than the..."
          ],
          [
           "```\n\n```python out\nDatasetDict({\n    train: Dataset({\n        features: ['patient_id', 'drugName', '..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Introduction[[introduction]]\n\n<CourseFloatingBanner\n    chapter={3}..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-chapter-quiz]]\n\n<CourseFloatingB..."
          ],
          [
           "```\n\n<Question\n\tchoices={[\n\t\t{\n\t\t\ttext: \"It tries to stream a dataset that's too large to fit in RAM..."
          ],
          [
           "hy are fast tokenizers called fast? In this video we will see exactly how much faster the so-called ..."
          ],
          [
           "Part 2 completed![[part-2-completed]]\n\n<CourseFloatingBanner\n    chapter={8}\n    classNames=\"absolut..."
          ],
          [
           "n a lot of our examples, you're going to see DataCollators popping up over and over. They're used in..."
          ],
          [
           "Integrations with the Hugging Face Hub[[integrations-with-the-hugging-face-hub]]\n\n<CourseFloatingBan..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Fine-tuning a model with the Trainer API[[fine-tuning-a-model-with-..."
          ],
          [
           "```\n\nWe can now compare those `preds` to the labels. To build our `compute_metric()` function, we wi..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Tokenizers[[tokenizers]]\n\n{#if fw === 'pt'}\n\n<CourseFloatingBanner ..."
          ],
          [
           "```\n\n```python out\n['Jim', 'Henson', 'was', 'a', 'puppeteer']\n```\n\nThere are also variations of word..."
          ],
          [
           "```\n\nWe can now use the tokenizer as shown in the previous section:\n\n```python\ntokenizer(\"Using a Tr..."
          ],
          [
           "Building a model card[[building-a-model-card]]\n\n<CourseFloatingBanner\n    chapter={4}\n    classNames..."
          ],
          [
           "Byte-Pair Encoding tokenization[[byte-pair-encoding-tokenization]]\n\n<CourseFloatingBanner chapter={6..."
          ],
          [
           "```\n\n```python out\ndefaultdict(int, {'This': 3, 'Ġis': 2, 'Ġthe': 1, 'ĠHugging': 1, 'ĠFace': 1, 'ĠCo..."
          ],
          [
           "Live sessions and workshops[[live-sessions-and-workshops]]\n\nFor the release of parts 1 and 2 of the ..."
          ],
          [
           "sing the Python debugger in a terminal. In this video, we'll learn how to use the Python debugger in..."
          ],
          [
           "n this video, we will learn the first things to do when you get an error. Let's say we want to use t..."
          ],
          [
           "Mastering NLP[[mastering-nlp]]\n\n<CourseFloatingBanner\n    chapter={7}\n    classNames=\"absolute z-10 ..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Semantic search with FAISS[[semantic-search-with-faiss]]\n\n{#if fw =..."
          ],
          [
           "```\n\nWhen we explode `df`, we expect to get one row for each of these comments. Let's check if that'..."
          ],
          [
           "```\n\nWe can test the function works by feeding it the first text entry in our corpus and inspecting ..."
          ],
          [
           "he Push to Hub API. Let's have a look at the push_to_hub API. You will need to be logged in with you..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# End-of-chapter quiz[[end-of-chapter-quiz]]\n\n<CourseFloatingB..."
          ],
          [
           "### 8. Select the sentences that apply to the BPE model of tokenization.\n\n<Question\n\tchoices={[\n\t\t{\n..."
          ],
          [
           "FrameworkSwitchCourse {fw} />\n\n# Training a causal language model from scratch[[training-a-causal-la..."
          ],
          [
           "```\n\n```python out\nDatasetDict({\n    train: Dataset({\n        features: ['repo_name', 'path', 'copie..."
          ],
          [
           "```\n\n```python out\nDatasetDict({\n    train: Dataset({\n        features: ['input_ids'],\n        num_r..."
          ],
          [
           "```\n\nNow we can just start the `Trainer` and wait for training to finish. Depending on whether you r..."
          ],
          [
           "```\n\nNot bad; that's the right way to do it. Finally, let's see if we can also use it for `scikit-le..."
          ],
          [
           "```\n\nWith the `evaluate()` function we can report loss and [perplexity](/course/chapter7/3) at regul..."
          ],
          [
           "ow to ask a question on the Hugging Face forums?\n\nIf you have a general question or are looking to d..."
          ],
          [
           "hat is domain adaptation? When fine-tuning a pretrained model on a new dataset, the fine-tuned model..."
          ]
         ],
         "hovertemplate": "source=course<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "course, circle",
         "marker": {
          "color": "#FF97FF",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "course, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0.41568014,
          -1.4453439,
          -0.84446174,
          2.38452,
          -4.116929,
          4.4101267,
          2.6795287,
          1.1138408,
          -1.3972989,
          2.7571402,
          -4.365545,
          -1.7840534,
          4.6067204,
          -2.2711804,
          1.1481986,
          1.0469277,
          2.3716905,
          1.1535395,
          2.7612708,
          -3.6991098,
          -3.0145867,
          2.649434,
          3.6454284,
          2.2445836,
          0.3939893,
          -0.6656845,
          0.031107815,
          0.596152,
          1.7604932,
          0.43580818,
          -3.0522482,
          3.905898,
          -1.1983128,
          -1.9124277,
          2.2549825,
          -2.8881772,
          0.32765928,
          1.5032097,
          -0.037519533,
          1.413858,
          3.098196,
          -3.7351887,
          -1.587749,
          0.6653363,
          0.8605788,
          1.8306967,
          2.2114956,
          2.7317498,
          0.45436877,
          0.06297862,
          -1.447761,
          2.156359,
          3.12017,
          -0.17286564,
          -2.893019,
          -2.7487226,
          2.942175,
          2.8970065,
          1.3715904,
          0.9226953,
          -2.6674192,
          2.1314275,
          -2.9348495,
          0.9306842,
          1.405718,
          0.30237964,
          3.3250024,
          0.24262004,
          3.3721147,
          -1.5810919,
          1.0019362,
          -1.6986852,
          -4.4694448,
          2.7857969,
          4.753219,
          2.845883,
          1.065105,
          1.8915846,
          -0.14161046,
          3.9905188,
          1.8972015,
          -2.0114121,
          1.6022952,
          -2.917759,
          1.1674179,
          -3.1648016,
          1.5058783,
          -0.19146082,
          1.9184612,
          0.83241826,
          -3.328675,
          0.12907091,
          -1.3092635,
          -1.628525,
          3.4486485,
          2.1382985,
          -0.8441845,
          1.783082,
          3.1943696,
          0.44164154,
          3.2896078,
          -1.5339026,
          -2.2373,
          2.3526268,
          -3.976742,
          3.884114,
          2.269175,
          3.8484106,
          1.0527999,
          1.8120183,
          -1.6162429,
          -2.7435246,
          1.2868791,
          0.5343137,
          -2.952122,
          1.4069501,
          -2.2654226,
          1.6234083,
          0.492978,
          2.3105059,
          -1.3672261,
          1.1836039,
          -4.3844337,
          -3.1570885,
          -1.7902834,
          -2.7571435,
          1.5361143,
          -0.51080275,
          0.2543065,
          -1.705535,
          -2.9543636,
          -2.1597242,
          4.6799617,
          -2.061724,
          -0.101533815,
          4.651745,
          3.1852586,
          -1.5697999,
          -3.1182802,
          -1.7681824,
          2.2217789,
          1.1736097,
          1.4597903,
          0.9718102,
          -1.3417541,
          -2.902872,
          -2.9705863,
          -1.9292243,
          1.6443403,
          -0.9792623,
          -1.6811514,
          3.6269934,
          2.3233547,
          1.4510741,
          2.1317773,
          2.6616292,
          -2.643187,
          -1.0632358,
          -3.5823314,
          2.3056927,
          -3.6004503,
          -2.1550243,
          1.2972163,
          0.26756737,
          -3.2547204,
          1.1731392,
          4.917069,
          2.01963,
          3.23188,
          4.394553,
          -0.7113057,
          1.5995528,
          0.8407847,
          -2.653216,
          -4.4864244,
          3.6161568,
          1.93213,
          5.0102115,
          -0.083448656,
          -4.0061707,
          -2.1601377,
          1.6876171,
          -0.6621507,
          -3.4877827,
          -4.3300414,
          1.5805509,
          2.225673,
          1.4241803,
          1.9547983,
          3.773546,
          0.7674653,
          -3.429599,
          -1.4930388,
          -2.5220215,
          -2.8608065,
          -2.437045,
          -3.4111485,
          -3.389557,
          -2.9012005,
          0.902837,
          0.1148501,
          -0.3096473,
          1.1820363,
          -1.0114344,
          2.4179,
          -1.8047322,
          -1.7031997,
          -2.6619096,
          -2.9303153,
          1.5648414,
          0.6837688,
          2.1673832,
          1.2737757,
          -4.5017834,
          -1.4989523,
          -0.43794197,
          2.113391,
          2.082438,
          0.824334,
          2.4357216,
          -0.66003877,
          -1.1018592,
          4.8516684,
          2.4775019,
          0.761985,
          2.1967795,
          0.5119994,
          -2.2656455,
          -1.387009,
          2.783957,
          1.2292916,
          3.735024,
          -2.790678,
          3.0437977,
          4.120997,
          1.1679665,
          -3.061451,
          -3.1661751,
          0.7970357,
          -2.5457263,
          2.2461758,
          2.863664,
          2.363664,
          3.2944083,
          2.011377,
          -2.0881772,
          2.4891818,
          1.1593231,
          4.5026307,
          -1.384646,
          0.5044461,
          -0.011891477,
          -1.0256238,
          -0.06102651,
          2.8446836,
          0.2617684,
          -0.1831362,
          2.7626736,
          -3.4936447,
          3.7920072,
          -2.9025235,
          0.036446273,
          4.0488896,
          -0.80569416,
          3.7057064,
          3.7718647,
          1.0223318,
          2.393963,
          -2.5117095,
          5.666981,
          1.2344364,
          0.9350719
         ],
         "xaxis": "x",
         "y": [
          4.2052016,
          -0.15578593,
          2.8575957,
          -0.51811594,
          -0.14933136,
          0.13200778,
          0.19423915,
          3.3695972,
          4.015304,
          -1.7260427,
          1.2703656,
          -1.0217437,
          0.27358788,
          -0.6950181,
          -2.7977643,
          4.9965415,
          0.17139931,
          4.745128,
          -0.66903895,
          1.3122627,
          2.9290388,
          -2.0877295,
          1.4795045,
          3.334766,
          -2.7063797,
          -2.2583983,
          1.4121892,
          -0.90279436,
          1.9127499,
          -1.9597303,
          0.95664173,
          1.9475416,
          -1.4946876,
          0.5873448,
          -3.4296181,
          -2.0574665,
          -2.0846324,
          -1.0196975,
          4.5102463,
          2.6742976,
          -1.1277268,
          -1.0841959,
          1.2992669,
          -3.136379,
          3.5312703,
          4.1489778,
          -1.5895907,
          2.7766905,
          3.3907018,
          2.0996556,
          0.29693162,
          -1.5242704,
          2.9979022,
          4.2611933,
          0.121473126,
          -1.0128789,
          2.6347604,
          -0.25095212,
          -1.4764174,
          4.6565623,
          -0.48081762,
          -2.9953554,
          3.4603853,
          -0.78407806,
          -3.7195735,
          -2.4884202,
          -1.3841738,
          0.73130774,
          -1.0137273,
          1.0673622,
          3.5787756,
          -1.6493223,
          -0.39349696,
          -2.4742327,
          0.48582003,
          -2.3260527,
          -4.21689,
          -2.2005851,
          -2.2293453,
          -0.5292242,
          3.013298,
          1.5303737,
          0.619731,
          -3.111692,
          -0.9021012,
          -0.7791068,
          -3.1244497,
          -1.9742268,
          -4.786809,
          -3.5931346,
          -2.3584142,
          3.7494256,
          4.291704,
          -0.70081896,
          -1.981913,
          3.9691632,
          3.001878,
          -1.6186802,
          -3.4058979,
          -1.2374408,
          1.3316797,
          -3.2394092,
          4.2208624,
          1.9901421,
          2.5564377,
          -0.5650692,
          0.41550696,
          0.29202828,
          -2.832046,
          -0.8932129,
          -0.7573492,
          -1.336072,
          4.6561027,
          4.8094444,
          -0.61208016,
          -0.35260937,
          -1.090504,
          -1.7988975,
          -3.7316813,
          3.277218,
          1.9952786,
          3.899789,
          1.7508124,
          0.33748174,
          -0.6742736,
          0.12236059,
          -2.3992982,
          -4.8893394,
          -4.0917363,
          -4.1413,
          0.17300336,
          1.5916668,
          0.44769803,
          2.9588,
          -2.5456166,
          0.9387024,
          1.7577368,
          -1.5968885,
          0.24450774,
          -0.1717534,
          3.433869,
          4.4466205,
          -2.4108388,
          4.328111,
          3.3156834,
          0.9205714,
          1.7083321,
          -2.1753085,
          -2.1095393,
          4.7226,
          1.7385452,
          -1.9818052,
          1.9773937,
          0.084420055,
          -0.28250584,
          1.1672405,
          1.3360256,
          -0.4410957,
          -0.2985386,
          -2.313757,
          3.1751847,
          0.4136257,
          2.9120228,
          4.559445,
          -1.7248306,
          4.452709,
          1.5097785,
          1.8655273,
          2.3457766,
          0.07366762,
          4.8560314,
          -0.18189158,
          2.3438659,
          -1.4321418,
          0.29763034,
          2.0123992,
          2.6903777,
          0.9189945,
          4.835509,
          1.7957625,
          -2.0469787,
          -0.18490365,
          5.295407,
          -0.08642801,
          -0.26604685,
          2.7178605,
          4.1454787,
          -2.9704351,
          1.8915837,
          2.8952212,
          4.7530203,
          -0.84857273,
          4.974705,
          -3.877011,
          2.3353708,
          2.1588745,
          2.0011501,
          1.8768679,
          -1.8327539,
          4.2578964,
          -4.074565,
          5.0322223,
          -0.9396583,
          -1.1921751,
          -2.8258584,
          -1.2259828,
          0.25726566,
          2.5601194,
          -2.8689852,
          1.1529398,
          4.1216736,
          -1.5414104,
          1.3854465,
          0.31830472,
          3.5598617,
          -0.2808219,
          0.33731687,
          -0.828527,
          -1.1166246,
          -2.2574143,
          4.0181994,
          1.2656376,
          0.22294979,
          0.31232274,
          4.2533326,
          -1.3458556,
          -3.260396,
          -2.3086083,
          -3.3359811,
          -0.6922944,
          0.27795267,
          0.8663918,
          -1.2866254,
          -0.6184644,
          -0.16583318,
          -1.4084437,
          -1.5377889,
          -2.1745162,
          2.0647008,
          -4.1621695,
          -4.0552783,
          -0.6041775,
          3.190661,
          2.888672,
          1.8824669,
          -2.7649794,
          -1.5830927,
          1.7604566,
          1.1880271,
          0.9338202,
          -2.8866394,
          3.087581,
          -0.5369674,
          1.9540194,
          -1.7150822,
          4.4214606,
          2.778373,
          0.739885,
          0.03950774,
          -0.113278136,
          -1.9145311,
          4.374688,
          -0.6879924,
          -1.8467853,
          -0.73487407,
          0.2633415,
          -1.0138822,
          -3.135957,
          -0.45739925,
          1.095137,
          2.60758,
          4.8074126
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe [optimizer](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab00..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lcm..."
          ],
          [
           "```\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lcm..."
          ],
          [
           "Latent Consistency Distillation Example:\n\n[Latent Consistency Models (LCMs)](https://arxiv.org/abs/2..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Stable Diffusion\n\n## Overview\n\nStable Diffusion was proposed in [Stable Diffusion Announcement](http..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen [`~AutoPipelineForImage2Image.from_pipe`] maps the original `\"stable-diffusion\"` pipeline ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "--\n{{ card_data }}\n---\n\n<!-- This model card has been generated automatically according to the infor..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nFinally, pass the prompt and control image to the pipeline\n\n```py\n# fix the random seed, so you..."
          ],
          [
           "```\n\nThe two control images look as such:\n\n![img](https://huggingface.co/datasets/diffusers/docs-ima..."
          ],
          [
           "Adapt a model to a new task\n\nMany diffusion systems share the same components, allowing you to adapt..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<table>\n    <tr>\n        <td><center>\n        masterpiece, bestquality, sunset.\n        <br>\n  ..."
          ],
          [
           "!--Copyright 2023 The GLIGEN Authors and The HuggingFace Team. All rights reserved.\n\nLicensed under ..."
          ],
          [
           "Würstchen text-to-image fine-tuning\n\n## Running locally with PyTorch\n\nBefore running the scripts, ma..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# [Deprecated] Multi Token Textual Inversion\n\n**IMPORTART: This research project is deprecated. Mult..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nYou can also get the active adapters of each pipeline component with [`~diffusers.loaders.LoraL..."
          ],
          [
           "Consistency Decoder\n\nConsistency decoder can be used to decode the latents from the denoising UNet i..."
          ],
          [
           "# Amused training\n\nAmused can be finetuned on simple datasets relatively cheaply and quickly. Using ..."
          ],
          [
           "```\n\n### Finetuning the 512 checkpoint\n\nThese examples finetune on this [minecraft](https://huggingf..."
          ],
          [
           "# Diffusers examples with Intel optimizations\n\n**This research project is not actively maintained by..."
          ],
          [
           "🧨 Diffusers Experimental\n\nWe are adding experimental code to support novel applications and usages o..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Train text encoder\n\nTo improve the quality of the generated outputs, you can also train the..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"12GB\">\n\nOn a 12GB GPU, you'll need bitsandbytes 8-bit optimizer, grad..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nInstead of the default [`PNDMScheduler`], exchange it for the [`UniPCMultistepScheduler`] to se..."
          ],
          [
           "Overview\n\nThese examples show how to run [Diffuser](https://arxiv.org/abs/2205.09991) in Diffusers. ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen, you can generate an image like:\n\n```py\nfrom diffusers import DiffusionPipeline\n\npipeline ..."
          ],
          [
           "InstructPix2Pix SDXL training example\n\n***This is based on the original InstructPix2Pix training exa..."
          ],
          [
           "```\n\nWe encourage you to play with the following three parameters to control\nspeed and quality durin..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "ControlNet training example\n\n[Adding Conditional Control to Text-to-Image Diffusion Models](https://..."
          ],
          [
           "```\n\n## Training on a 12 GB GPU\n\nOptimizations:\n- Gradient checkpointing\n- bitsandbyte's 8-bit optim..."
          ],
          [
           "```\n\nAnd finally start the training\n\n```bash\npython3 train_controlnet_flax.py \\\n --pretrained_model_..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nPass the `controlnet` to the [`AutoPipelineForText2Image`], and provide the prompt and pose est..."
          ],
          [
           "```\n\n## Control image generation\n\nThere are several ways to exert more control over how an image is ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Textual Inversion fine-tuning example\n\n[Textual inversion](https://arxiv.org/abs/2208.01618) is a ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIt is often a good idea to quickly check the sample image shape matches the model output shape:..."
          ],
          [
           "```\n\nNow you can wrap all these components together in a training loop with 🤗 Accelerate for easy Te..."
          ],
          [
           "ConsistencyDecoderScheduler\n\nThis scheduler is a part of the [`ConsistencyDecoderPipeline`] and was ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Stable Diffusion text-to-image fine-tuning\n\nThe `train_text_to_image.py` script shows how to fine-tu..."
          ],
          [
           "```\n\n\n#### Training with Min-SNR weighting\n\nWe support training with the Min-SNR weighting strategy ..."
          ],
          [
           "```\n\n```bash\nexport MODEL_NAME=\"duongna/stable-diffusion-v1-4-flax\"\nexport DATASET_NAME=\"lambdalabs/..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Diffusers examples with ONNXRuntime optimizations\n\n**This research project is not actively maintai..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The Intel Labs Team Authors and HuggingFace Team. All rights reserved.\n\nLicensed u..."
          ],
          [
           "# Training examples\n\nCreating a training image set is [described in a different document](https://hu..."
          ],
          [
           "Models\n\nFor more detail on the models, please refer to the [docs](https://huggingface.co/docs/diffus..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 Custom Diffusion authors The HuggingFace Team. All rights reserved.\n\nLicensed unde..."
          ],
          [
           "```\n\nNow you'll need to add the [Custom Diffusion weights](https://github.com/huggingface/diffusers/..."
          ],
          [
           "```\n\n</hfoption>\n</hfoptions>\n\nOnce training is finished, you can use your new Custom Diffusion mode..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Vers..."
          ],
          [
           "Stable Diffusion text-to-image fine-tuning\n\nThe `train_text_to_image.py` script shows how to fine-tu..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nCompel provides a `DiffusersTextualInversionManager` class to simplify prompt weighting with te..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "You can find the original codebase for Stable Diffusion v1.0 at [CompVis/stable-diffusion](https://g..."
          ],
          [
           "```\n\n### Reuse pipeline components to save memory\n\nTo save memory and use the same components across..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nStart with `batch_size=4` and see how much memory you've consumed:\n\n```python\nfrom diffusers.ut..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 - The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License,..."
          ],
          [
           "```\n\nCheck out the [Quickstart](https://huggingface.co/docs/diffusers/quicktour) to launch your diff..."
          ],
          [
           "## Popular libraries using 🧨 Diffusers\n\n- https://github.com/microsoft/TaskMatrix\n- https://github.c..."
          ],
          [
           "```..."
          ],
          [
           "Stable Diffusion text-to-image fine-tuning\nThis extended LoRA training script was authored by [haofa..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "[Paper](https://arxiv.org/abs/2211.09800)\n\n[InstructPix2Pix](../api/pipelines/pix2pix) is fine-tuned..."
          ],
          [
           "## Model Editing\n\n[Paper](https://arxiv.org/abs/2303.08084)\n\nThe [text-to-image model editing pipeli..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<Tip warning={true}>\n\nIn order to properly offload models after they're called, it is required ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### 2. Opening new issues on the GitHub issues tab\n\nThe 🧨 Diffusers library is robust and reliable t..."
          ],
          [
           "Also, many issues tend to be simply off-topic, duplicates of other issues, or irrelevant. It is of g..."
          ],
          [
           "```\n\nas well as to install all additional dependencies required for training:\n\n```bash\npip install -..."
          ],
          [
           "```\n\nTo learn more, read this section of the [~Don't~ Repeat Yourself*](https://huggingface.co/blog/..."
          ],
          [
           "```\n\n**Do not** work on the `main` branch.\n\n4. Set up a development environment by running the follo..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n- #### SDXL Support\n\t\n\tSince our attention processor also works with SDXL, it can be utilized to..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNow pass your prompt, initial image, and depth map to the pipeline:\n\n```py\noutput = pipe(\n    \"..."
          ],
          [
           "```\n\n<div class=\"flex gap-4\">\n  <div>\n    <img class=\"rounded-xl\" src=\"https://huggingface.co/takuma..."
          ],
          [
           "```\n\n<div class=\"flex gap-4\">\n  <div>\n    <img class=\"rounded-xl\" src=\"https://huggingface.co/datase..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### 2. Opening new issues on the GitHub issues tab\n\nThe 🧨 Diffusers library is robust and reliable t..."
          ],
          [
           "Also, many issues tend to be simply off-topic, duplicates of other issues, or irrelevant. It is of g..."
          ],
          [
           "```\n\nas well as to install all additional dependencies required for training:\n\n```bash\npip install -..."
          ],
          [
           "```\n\nTherefore when adding an example, the `requirements.txt` file shall define all pip dependencies..."
          ],
          [
           "Please make sure to add links to the original codebase/paper to the PR and ideally also ping the\nori..."
          ],
          [
           "```\n\n3. Create a new branch to hold your development changes:\n\n ```bash\n $ git checkout -b a-descrip..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nPush the pipeline to the Hub to share with the community!\n\n```python\npipeline.push_to_hub(\"cust..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "DreamBooth training example for Stable Diffusion XL (SDXL)\n\n[DreamBooth](https://arxiv.org/abs/2208...."
          ],
          [
           "```\n\nHere's a side-by-side comparison of the with and without Refiner pipeline outputs:\n\n| Without R..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Deprecated Pipelines\n\nThis folder contains pipelines that have very low usage as measured by model d..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe [prompt and image embeddings](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Schedulers\n\nFor more information on the schedulers, please refer to the [docs](https://huggingface.c..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Text Guided Image-to-Image Generation\n\nThe same IF model weights can be used for text-guide..."
          ],
          [
           "```\n\nYou can also use [`torch.compile`](../../optimization/torch2.0). Note that we have not exhausti..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nWithin the [`main()`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883..."
          ],
          [
           "```\n\n</hfoption>\n</hfoptions>\n\nOnce training is complete, you can use your newly trained model for i..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## Design Philosophy in Details\n\nNow, let's look a bit into the nitty-gritty details of the design p..."
          ],
          [
           "### Schedulers\n\nSchedulers are responsible to guide the denoising process for inference as well as t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Core ML inference in Swift\n\nRunning inference in Swift is slightly faster than in Python bec..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nFinally, the [training loop](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f8409..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nKandinsky uses a [`PriorTransformer`] to generate the image embeddings, so you'll want to setup..."
          ],
          [
           "```\n\n<Tip>\n\nFeel free to replace `kandinsky-community/kandinsky-2-2-decoder` with your own trained d..."
          ],
          [
           "InstructPix2Pix training example\n\n[InstructPix2Pix](https://arxiv.org/abs/2211.09800) is a method to..."
          ],
          [
           "```\n\nAn example model repo obtained using this training script can be found\nhere - [sayakpaul/instru..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Training an unconditional diffusion model\n\nCreating a training image set is [described in a differ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nGenerate some images with multiple prompts:\n\n```python\nprompts = [\n    \"a photo of an astronaut..."
          ],
          [
           "```\n\nTo measure the directional similarity, we first load CLIP's image and text encoders:\n\n```python..."
          ],
          [
           "```\n\n```python\nfrom PIL import Image\nimport os\n\ndataset_path = \"sample-imagenet-images\"\nimage_paths ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe `img2text` mode requires that an input `image` be supplied. You can set the `img2text` mode..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nFinally, in the [training loop](https://github.com/huggingface/diffusers/blob/64603389da0108205..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "T2I-Adapter training example for Stable Diffusion XL (SDXL)\n\nThe `train_t2i_adapter_sdxl.py` script ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### ControlNet\n\n```python\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetMo..."
          ],
          [
           "```\n</details>\n\nThe graph below highlights the relative speed-ups for the [`StableDiffusionPipeline`..."
          ],
          [
           "### RTX 4090 (batch size: 4)\n\n| **Pipeline** | **torch 2.0 - <br>no compile** | **torch nightly - <b..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Reuse components across pipelines\n\nYou can also reuse the same components in multiple pipel..."
          ],
          [
           "```\n\nOr directly from a repository's [directory](https://huggingface.co/google/ddpm-cifar10-32/tree/..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/doc..."
          ],
          [
           "```\n\nGenerate an image from the base model, and set the model output to **latent** space:\n\n```py\npro..."
          ],
          [
           "```\n\n2. Use `torch.compile` for ~20% speed-up (you need `torch>=2.0`):\n\n```diff\n+ base.unet = torch...."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n![img](https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/stable_diffusion_jax..."
          ],
          [
           "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pled..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nLastly, in the [training loop](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Stable Diffusion XL for JAX + TPUv5e\n\n[TPU v5e](https://cloud.google.com/blog/products/compute/how-c..."
          ],
          [
           "```\nThe initial run of the `generate` function will be slow because JAX compiles the function during..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lcm..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNow when you run the same pipeline twice, you'll get identical results.\n\n```py\nimport torch\nfro..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/datasets/patrickvonplaten/imag..."
          ],
          [
           "# Textual Inversion fine-tuning example\n\n[Textual inversion](https://arxiv.org/abs/2208.01618) is a ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<div class=\"flex justify-center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/doc..."
          ],
          [
           "```\n\nTo speed up the denoising process, move the input and model to a GPU:\n\n```py\n>>> model.to(\"cuda..."
          ],
          [
           "🧨 Diffusers Pipelines\n\nPipelines provide a simple way to run state-of-the-art diffusion models in in..."
          ],
          [
           "**Note**: Pipelines are simple examples of how to play around with the diffusion systems as describe..."
          ],
          [
           "```\n\n### Image-to-Image text-guided generation with Stable Diffusion\n\nThe `StableDiffusionImg2ImgPip..."
          ],
          [
           "Distillation for quantization on Textual Inversion models to personalize text2image\n\n[Textual invers..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Latent Consistency Distillation Example:\n\n[Latent Consistency Models (LCMs)](https://arxiv.org/abs/2..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"Kandinsky 2.2\">\n\n```py\nfrom diffusers import AutoPipelineForText2Imag..."
          ],
          [
           "```\n\n</Tip>\n\nFor inpainting, you'll need the original image, a mask of the area to replace in the or..."
          ],
          [
           "```\n\nCall the `interpolate` function to generate the embeddings, and then pass them to the pipeline ..."
          ],
          [
           "```\n\nNow you can run the [`KandinskyV22ControlnetImg2ImgPipeline`] to generate an image from the ini..."
          ],
          [
           "# Diffusers examples with ONNXRuntime optimizations\n\n**This research project is not actively maintai..."
          ],
          [
           "Multi Subject DreamBooth training\n\n[DreamBooth](https://arxiv.org/abs/2208.12242) is a method to per..."
          ],
          [
           "```\n\nYou can use the helper from the script to get a better sense of each parameter.\n\n### Inference\n..."
          ],
          [
           "```\n\n### Fine-tune text encoder with the UNet.\n\nThe script also allows to fine-tune the `text_encode..."
          ],
          [
           "Inference Examples\n\n**The inference examples folder is deprecated and will be removed in a future ve..."
          ],
          [
           "ControlNet training example for Stable Diffusion XL (SDXL)\n\nThe `train_controlnet_sdxl.py` script sh..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n<div class=\"flex gap-4\">\n  <div>\n    <img class=\"rounded-xl\" src=\"https://huggingface.co/datase..."
          ],
          [
           "```\n\n<div class=\"flex flex-row gap-4\">\n  <div class=\"flex-1\">\n    <img class=\"rounded-xl\" src=\"https..."
          ],
          [
           "```\n\nRepeat one more time to generate the final image in a [pixel art style](https://huggingface.co/..."
          ],
          [
           "```\n\nNow generate a new image conditioned on the depth map, initial image, and prompt:\n\n```py\nprompt..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Stable Diffusion XL text-to-image fine-tuning\n\nThe `train_text_to_image_sdxl.py` script shows how to..."
          ],
          [
           "```\n\nFor this example we want to directly store the trained LoRA embeddings on the Hub, so\nwe need t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "<!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ve..."
          ],
          [
           "```\n\nThe special [placeholder token](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0b..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nIn the [`main()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42f..."
          ],
          [
           "Custom Diffusion training example \n\n[Custom Diffusion](https://arxiv.org/abs/2212.04488) is a method..."
          ],
          [
           "```\n\n## Inference\n\nOnce you have trained a model using the above command, you can run inference usin..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023- The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, ..."
          ],
          [
           "```\n    Args:\n        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n     ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen the script [loads the UNet](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Speed-Up Inference\nYou can make use of `torch.compile` function and gain a speed-up of about..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## Design Philosophy in Details\n\nNow, let's look a bit into the nitty-gritty details of the design p..."
          ],
          [
           "### Schedulers\n\nSchedulers are responsible to guide the denoising process for inference as well as t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Textual Inversion fine-tuning example\n\n[Textual inversion](https://arxiv.org/abs/2208.01618) is a ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Kandinsky2.2 text-to-image fine-tuning\n\nKandinsky 2.2 includes a prior pipeline that generates image..."
          ],
          [
           "```\n\nIf you want to use a fine-tuned decoder checkpoint along with your fine-tuned prior checkpoint,..."
          ],
          [
           "e don't yet support training T2I-Adapters on Stable Diffusion yet. For training T2I-Adapters on Stab..."
          ],
          [
           "Research projects\n\nThis folder contains various research projects using 🧨 Diffusers.\nThey are not re..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "[DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth) by [colossalai]..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNext, create a utility function to generate the prompts:\n\n```py\n@torch.no_grad()\ndef generate_p..."
          ],
          [
           "Community Examples\n\n> **For more information about community pipelines, please have a look at [this ..."
          ],
          [
           "| Example                                                                                           ..."
          ],
          [
           "| Long Prompt Weighting Stable Diffusion                                                            ..."
          ],
          [
           "| Text Based Inpainting Stable Diffusion                                                            ..."
          ],
          [
           "| DDIM Noise Comparative Analysis Pipeline                                                          ..."
          ],
          [
           "|   Zero1to3 Pipeline                                                                               ..."
          ],
          [
           "| AnimateDiff ControlNet Pipeline                                                                   ..."
          ],
          [
           "To load a custom pipeline you just need to pass the `custom_pipeline` argument to `DiffusionPipeline..."
          ],
          [
           "```\n\n## Example usages\n\n### LLM-grounded Diffusion\n\nLMD and LMD+ greatly improves the prompt underst..."
          ],
          [
           "```\n\nThe output of the `walk(...)` function returns a list of images saved under the folder as defin..."
          ],
          [
           "```\n\nWe can then define possible values to be sampled for `animal`, `object`, and `clothing`. These ..."
          ],
          [
           "```\n\n### Multilingual Stable Diffusion Pipeline\n\nThe following code can generate an images from text..."
          ],
          [
           "```\n\n![diffusers_euler](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/k_diffu..."
          ],
          [
           "```\nThe `mix_img` is a PIL image that can be saved locally or displayed directly in a google colab. ..."
          ],
          [
           "```\nThe original images:-\n\n![starry](https://huggingface.co/datasets/NagaSaiAbhinay/UnCLIPImageInter..."
          ],
          [
           "```\n\n### EDICT Image Editing Pipeline\n\nThis pipeline implements the text-guided image editing approa..."
          ],
          [
           "```\n\nReference Image\n\n![reference_image](https://hf.co/datasets/huggingface/documentation-images/res..."
          ],
          [
           "```\n\n### CLIP Guided Images Mixing With Stable Diffusion\n\n![clip_guided_images_mixing_examples](http..."
          ],
          [
           "```\n![mixture_tiling_results](https://huggingface.co/datasets/kadirnar/diffusers_readme_images/resol..."
          ],
          [
           "```\n\nSampling with the IADB formulation is easy, and can be done in a few lines (the pipeline alread..."
          ],
          [
           "```\n\n*With enough feedbacks you can create very similar high quality images.*\n\nThe original codebase..."
          ],
          [
           "```\n\nFor any questions or feedback, feel free to reach out to [Simian Luo](https://github.com/luosia..."
          ],
          [
           "```\n\n###  StableDiffusionUpscaleLDM3D Pipeline\n[LDM3D-VR](https://arxiv.org/pdf/2311.03226.pdf) is a..."
          ],
          [
           "```\n\n### Regional Prompting Pipeline\nThis pipeline is a port of the [Regional Prompter extension](ht..."
          ],
          [
           "```\n### Negative prompt\nNegative prompts are equally effective across all regions, but it is possibl..."
          ],
          [
           "```\n* And next, as any other diffusion models, we need the score estimator and scheduler. As we are ..."
          ],
          [
           "```\nYou can display and save the generated images as:\n```py\ndef image_grid(imgs, save_path=None):\n\n ..."
          ],
          [
           "DreamBooth training example\n\n[DreamBooth](https://arxiv.org/abs/2208.12242) is a method to personali..."
          ],
          [
           "```\n\n\n### Training on a 8 GB GPU:\n\nBy using [DeepSpeed](https://www.deepspeed.ai/) it's possible to ..."
          ],
          [
           "```\n\nFor this example we want to directly store the trained LoRA embeddings on the Hub, so \nwe need ..."
          ],
          [
           "```\n\n\n### Fine-tune text encoder with the UNet.\n\n```bash\nexport MODEL_NAME=\"duongna/stable-diffusion..."
          ],
          [
           "```\n\n### IF Stage I Full Dreambooth\n`--skip_save_text_encoder`: When training the full model, this w..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen use the [`~loaders.LoraLoaderMixin.load_lora_weights`] method to load the [ostris/super-ce..."
          ],
          [
           "```\n\nLoad the LoRA checkpoint with the [`~loaders.LoraLoaderMixin.load_lora_weights`] method, and sp..."
          ],
          [
           "```\n</hfoption>\n</hfoptions>\n\n\nIP-Adapters can also be used with [SDXL](../api/pipelines/stable_diff..."
          ],
          [
           "```\n<div class=\"flex flex-row gap-4\">\n  <div class=\"flex-1\">\n    <img class=\"rounded-xl\" src=\"https:..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThe magic behind community pipelines is contained in the following code. It allows the communit..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "RealFill\n\n[RealFill](https://arxiv.org/abs/2309.16668) is a method to personalize text2image inpaint..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nFinally, the [training loop](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f1..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n### Kandinsky 2.2 Inpainting\n\nThe Kandinsky model family is similar to SDXL because it uses two..."
          ],
          [
           "```\n\n</hfoption>\n<hfoption id=\"runwayml/stable-diffusion-inpaint\">\n\n```py\nimport torch\nfrom diffuser..."
          ],
          [
           "```\n\n<div class=\"flex flex-row gap-4\">\n  <div class=\"flex-1\">\n    <img class=\"rounded-xl\" src=\"https..."
          ],
          [
           "```\n\nLoad the mask image of the output from above:\n\n```py\nmask_image = load_image(\"https://huggingfa..."
          ],
          [
           "```\n\n### ControlNet\n\nControlNet models are used with other diffusion models like Stable Diffusion, a..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Dreambooth for the inpainting model\n\nThis script was added by @thedarkzeno .\n\nPlease note that this ..."
          ],
          [
           "Create a dataset for training\n\nThere are many datasets on the [Hub](https://huggingface.co/datasets?..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ]
         ],
         "hovertemplate": "source=diffusers<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "diffusers, circle",
         "marker": {
          "color": "#FECB52",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "diffusers, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          2.912645,
          -3.8357346,
          -1.3549389,
          -1.9340664,
          4.7025414,
          0.5929081,
          -3.927972,
          -1.1456934,
          -3.7880168,
          2.1604958,
          -0.4170496,
          -4.2499,
          3.674187,
          -2.2075012,
          0.43360546,
          0.18863851,
          3.009252,
          2.1307614,
          -3.4184332,
          -2.6158776,
          -4.399859,
          2.4353087,
          -2.9139876,
          -2.8141732,
          3.0629833,
          2.148219,
          3.0829103,
          3.0515063,
          -4.257765,
          0.54069036,
          2.8243682,
          -1.5586907,
          3.4665866,
          -0.45591754,
          2.399993,
          -2.2504663,
          -1.3712832,
          -1.0202892,
          -0.99867547,
          -0.56019753,
          4.2810016,
          4.3698545,
          -1.3212698,
          1.4714658,
          -2.906153,
          -2.6012545,
          -2.1222467,
          -0.8301096,
          3.197141,
          -1.9289201,
          4.869207,
          2.2675653,
          -1.3981822,
          4.543863,
          0.8678027,
          -2.4936004,
          4.021515,
          -2.6129444,
          -2.396207,
          -4.1726103,
          -3.6435425,
          2.1269372,
          0.25714126,
          0.19568747,
          -1.2084666,
          -3.7447248,
          -1.3733494,
          0.5010284,
          -1.3944361,
          -3.1931047,
          2.5175164,
          -3.0196419,
          2.905636,
          -1.6382233,
          5.0903974,
          -1.351138,
          3.2578526,
          4.194594,
          3.195974,
          2.7665982,
          1.0872138,
          1.4556216,
          -1.9354572,
          1.2458214,
          -2.0907764,
          1.6183889,
          -3.1628098,
          4.9542255,
          0.16322038,
          -4.1193004,
          0.6041772,
          1.6017176,
          -2.9145162,
          -0.50353587,
          -0.8918168,
          -2.7485406,
          2.666996,
          -3.1995895,
          -3.3722715,
          -2.0208437,
          -2.7084813,
          2.8311222,
          -3.6820805,
          1.7821301,
          1.4046662,
          2.8954225,
          2.2144966,
          3.887635,
          2.0762138,
          -1.0248296,
          -0.052149985,
          -3.3942344,
          4.099338,
          10.322554,
          -2.2049172,
          -4.408773,
          0.84515595,
          1.2010422,
          3.2892566,
          -1.2469541,
          2.846085,
          5.0972333,
          -3.690196,
          1.7025145,
          1.3466268,
          5.0424914,
          5.2671824,
          -0.38656136,
          0.4162811,
          -4.658656,
          -3.4981866,
          -2.9272938,
          4.00518,
          -3.8064964,
          -2.2969859,
          3.2891085,
          0.59610134,
          3.8640115,
          -2.5771978,
          -0.5955725,
          1.1236455,
          2.1638992,
          -1.2569884,
          -2.2195477,
          4.015549,
          4.3186255,
          -1.2804209,
          3.330083,
          -3.1562548,
          1.1095579,
          2.1734338,
          -1.589081,
          -0.22496414,
          4.3210335,
          2.0216007,
          4.2748837,
          0.09628286,
          -2.1703122,
          0.74444985,
          2.4692826,
          -2.7604725,
          -3.6399612,
          -0.35519692,
          3.0871942,
          -3.6325479,
          -0.7596178,
          2.6228137,
          -3.6045644,
          0.4808244,
          -1.0775834,
          -3.5582871,
          -0.2561348,
          -2.2486866,
          -0.7938729,
          1.2496657,
          3.5805068,
          4.8025804,
          -3.7941895,
          -1.0110756,
          -4.490807,
          -4.3936477,
          0.8545284,
          -0.1336626,
          5.448553,
          -0.07238492,
          2.8648126,
          1.2526387,
          4.082697,
          -2.9969487,
          1.6701244,
          -1.7530097,
          0.76809007,
          -0.06062959,
          0.305312,
          3.589968,
          0.48221412,
          -2.2518647,
          -3.4990547,
          2.9098728,
          2.7068255,
          2.3791456,
          -0.7195273,
          -3.4523404,
          -3.0658307,
          -0.56931746,
          -0.06491774,
          0.1825255,
          -2.607725,
          2.3806183,
          -3.388292,
          -1.9536722,
          -0.6449854,
          -0.27530113,
          2.7793725,
          -2.2124846,
          0.7840937,
          -2.2747414,
          1.5323672,
          2.2566812,
          1.7429227,
          5.0144176,
          1.0171545,
          -1.3963037,
          -2.8023002,
          -0.6227451,
          5.204379,
          -3.0859985,
          1.1012329,
          -3.07506,
          3.448366,
          1.9631826,
          2.6615763,
          5.2052517,
          -3.20428,
          1.1829097,
          -1.6047627,
          -1.774465,
          -0.94297576,
          2.1777468,
          -2.1796045,
          -2.6459146,
          -1.4382731,
          -1.8677236,
          4.3122354,
          -2.980363,
          2.2098107,
          0.0942169,
          -3.2759237,
          1.1025218,
          -3.197075,
          -2.160393,
          3.3325312,
          -1.663216,
          -2.4042146,
          1.2387943,
          -2.3482997,
          -3.3734958,
          5.344025,
          -0.7328781,
          -2.9714887,
          -3.3344803,
          2.82728,
          -2.6289759,
          -2.6799927,
          -3.1321995,
          0.3012057,
          3.4292257,
          -3.7563915,
          -0.8321821,
          2.2971792,
          2.536642,
          -1.6781476,
          -3.2476537,
          1.3420902,
          4.462462,
          4.8268347,
          -2.1308854,
          -0.78797,
          2.5038218,
          -0.20147327,
          1.5757126,
          -3.23823,
          0.044350497,
          1.2201948,
          -3.3137379,
          -2.4648035,
          -2.0589173,
          3.4870582,
          -0.7282824,
          -2.29513,
          -0.8516327,
          5.0991964,
          1.4656901,
          2.7398193,
          3.14775,
          3.6064844,
          1.5144048,
          -3.6009603,
          3.5513878,
          -3.4932156,
          -2.806351,
          2.7435806,
          -1.2233897,
          -0.82778484,
          1.0532271,
          -3.388107,
          0.20546684,
          0.25513995,
          0.5337467,
          0.7802257,
          -3.0033338,
          1.912741,
          2.5540535,
          3.8547962,
          -1.7279488,
          -2.9375126,
          -1.436133,
          -1.3544123,
          -2.568275,
          -2.6781662,
          -1.3834841,
          -3.031932,
          2.209543,
          0.24109934,
          1.5229387,
          1.8588034,
          2.5927022,
          4.5314884,
          -0.72179395,
          -2.4524229,
          3.5723386,
          1.6055188,
          -0.5723876,
          -1.6285096,
          3.046958,
          4.9590163,
          -2.9254565,
          1.6444004,
          1.8405476,
          -2.2883935,
          -1.9292315,
          -2.527083,
          -1.4338224,
          -1.0520656,
          -3.0300844,
          2.8969254,
          -2.319969,
          -1.6115584,
          1.0640728,
          -3.3493247,
          -2.1367188,
          0.018287174,
          -1.6718285,
          1.2653831,
          2.970858,
          2.855882,
          1.5165391,
          -4.2956915,
          3.9258404,
          -1.2179539,
          -0.80153495,
          -2.0225089,
          2.7473302,
          1.7291279,
          2.6210632,
          -2.8642392,
          -3.1737394,
          -0.04973316,
          2.2820244,
          3.327771,
          4.0265174,
          -1.0866206,
          -1.6160489,
          -1.3217953,
          -0.4478054,
          -2.589522,
          -2.5335715,
          0.6422231,
          3.79508,
          3.2802467,
          1.5660177,
          -4.188121,
          3.3523445,
          -0.17696775,
          -4.368812,
          3.627072
         ],
         "xaxis": "x",
         "y": [
          -0.5757102,
          3.4096956,
          0.2197692,
          -3.3846571,
          0.79523003,
          1.1249479,
          0.9076887,
          1.4490013,
          -1.3211837,
          3.6129236,
          1.8713865,
          -0.25519475,
          1.4654273,
          -0.66924787,
          3.96948,
          3.1162064,
          0.9041089,
          0.5299949,
          0.44589424,
          -2.4852076,
          2.4997728,
          -1.9246948,
          -4.448946,
          1.6826029,
          1.9758567,
          0.033525493,
          1.7877647,
          1.9141747,
          3.3368356,
          -3.962279,
          3.1866891,
          4.2551217,
          -0.13746645,
          -4.0336366,
          0.26140428,
          -0.97689575,
          0.20262364,
          -3.8184972,
          1.7854439,
          -1.0866225,
          1.3736899,
          -0.24696976,
          4.2048883,
          2.7523572,
          -4.111275,
          -3.6628866,
          -0.2446369,
          -2.9456248,
          0.37176028,
          -0.9636114,
          1.3109705,
          0.44662625,
          -3.1784608,
          0.5368638,
          2.3187833,
          1.3999107,
          1.8944713,
          3.5427058,
          -0.9086325,
          1.4595567,
          0.24512523,
          0.76878303,
          1.5497394,
          2.918385,
          -3.7128217,
          0.833338,
          0.104885966,
          -2.117825,
          -2.9198549,
          2.9706361,
          -0.5478157,
          -3.7120967,
          -0.8545583,
          -1.2621576,
          1.2944659,
          -5.602457,
          2.2180264,
          -1.7879571,
          2.5568042,
          3.1813433,
          3.395777,
          2.8634608,
          -2.5601456,
          -0.9096159,
          -3.7847652,
          3.7301903,
          1.8522537,
          0.95971316,
          -0.5031861,
          -0.5971948,
          -1.4253712,
          3.490259,
          -1.4379815,
          3.3988433,
          -5.365224,
          0.44937068,
          -2.584355,
          -0.22638546,
          -1.049389,
          -1.1704835,
          1.8702065,
          -2.7819567,
          -2.782464,
          -1.6346511,
          -2.572523,
          -0.8557925,
          3.1461976,
          1.4164783,
          2.9945917,
          4.0741897,
          -0.84324837,
          3.3295238,
          -2.2391407,
          19.584846,
          -2.475132,
          0.4167219,
          4.455961,
          -2.3995118,
          -0.3868067,
          -0.8766385,
          2.8680944,
          0.3249915,
          1.8053553,
          3.100874,
          2.1439967,
          0.2853241,
          1.2858772,
          -0.7242414,
          3.0048928,
          0.3044927,
          4.1770077,
          1.5427265,
          1.2669766,
          -0.90985405,
          -4.662127,
          -1.3432523,
          3.2768784,
          1.4771981,
          -3.852334,
          3.0687695,
          4.2663703,
          -1.1912943,
          1.9181484,
          2.0734956,
          1.187497,
          -1.2954906,
          -4.696047,
          1.2703657,
          0.28279376,
          -1.8279802,
          2.1222897,
          -1.6896936,
          -4.499136,
          1.6553969,
          1.2203971,
          1.8664029,
          3.4966369,
          -2.9119794,
          4.1649494,
          2.500607,
          -3.7589295,
          -2.0538034,
          2.6885583,
          -1.1803787,
          0.275777,
          -2.4022357,
          -1.0440348,
          -1.5031962,
          -1.324577,
          -0.8502212,
          3.9997108,
          3.391057,
          -0.36761886,
          0.5489465,
          1.9410397,
          2.53559,
          0.36765212,
          -1.1420424,
          -3.2202444,
          0.45358047,
          -1.8771162,
          -2.7014976,
          -2.2351935,
          0.16194953,
          3.9827864,
          3.136117,
          -2.9571252,
          -0.5528932,
          -1.1821848,
          -0.8343954,
          -0.6656131,
          1.3600417,
          1.3623946,
          -2.703463,
          1.4068536,
          -2.8347917,
          -1.8719672,
          -1.1343291,
          2.050106,
          2.1753836,
          3.3248763,
          -2.4043813,
          -0.14852417,
          3.3522553,
          -4.4004416,
          3.7672532,
          3.2311177,
          1.9639491,
          -2.20963,
          -4.9153466,
          -2.8951614,
          -4.517378,
          2.2898304,
          3.8028088,
          2.8658464,
          3.702294,
          2.1248553,
          -4.6332994,
          -0.5577085,
          1.1556197,
          0.41416514,
          -2.492189,
          2.6916351,
          2.495195,
          -1.9547673,
          0.13923448,
          3.840212,
          0.34462348,
          0.1486802,
          3.117554,
          0.1799303,
          2.670315,
          -0.07664978,
          -0.32592323,
          3.184718,
          -0.96466523,
          -3.8693135,
          -2.2935128,
          -1.2037605,
          -3.9685082,
          -1.8135135,
          -0.20083313,
          -2.7769902,
          -0.2842772,
          1.7778678,
          -1.5815064,
          -2.4467783,
          -2.4397318,
          3.3226821,
          3.9320908,
          -1.7820903,
          1.7050351,
          -0.1329573,
          -4.1689343,
          4.2974977,
          -3.2499523,
          -2.3893611,
          2.179971,
          -2.2432313,
          0.46332914,
          -3.603091,
          0.40369081,
          -0.71974903,
          0.040741697,
          0.59835625,
          -4.1223493,
          0.43542573,
          0.7593943,
          4.2499914,
          -2.2396195,
          1.4912931,
          1.1098654,
          -2.996007,
          -1.3023105,
          1.1153777,
          1.2644931,
          0.6012773,
          0.99723315,
          2.7790217,
          -2.5020397,
          1.3746486,
          -2.0213945,
          -3.2892077,
          -4.4739127,
          4.439345,
          -2.3035738,
          -3.403237,
          -0.68548846,
          -1.4903656,
          -1.00271,
          1.1500521,
          0.41490334,
          2.6666074,
          -1.8922051,
          1.7179283,
          2.8940604,
          -0.6094933,
          1.1897936,
          -2.1956382,
          0.6180292,
          -1.9208717,
          0.4109393,
          -4.554656,
          0.7679159,
          -3.4987767,
          1.760484,
          -3.3117638,
          1.3624892,
          2.56621,
          3.8300605,
          1.7912989,
          -3.2768102,
          -2.8983333,
          1.7437994,
          4.937063,
          -2.7147307,
          -4.962643,
          -5.1183844,
          0.99177194,
          0.4993277,
          -2.127061,
          1.2374486,
          -3.2508163,
          -4.533127,
          -1.0422151,
          -2.0297441,
          -1.5794036,
          1.6348548,
          0.084376164,
          5.7202196,
          -0.7661534,
          -2.8138084,
          4.873002,
          0.56925505,
          2.650429,
          0.6875035,
          -1.3190154,
          1.2578886,
          -2.5973954,
          -4.3180227,
          -2.1399322,
          0.9749746,
          -3.679201,
          -2.4333756,
          -2.0066612,
          1.7498829,
          -1.1600783,
          -2.6965747,
          3.1595812,
          -3.618361,
          -4.5471077,
          -2.7307024,
          -5.1580396,
          -0.9201657,
          0.22884108,
          -1.4833916,
          -1.3496568,
          -0.46398604,
          0.07391381,
          -3.1710217,
          3.6793566,
          -2.5696185,
          2.5621421,
          2.2107737,
          0.662334,
          4.5170736,
          -3.5722685,
          1.5836143,
          3.6494603,
          2.6336045,
          -1.093464,
          -3.821132,
          -1.9472451,
          -2.1921685,
          -1.7029021,
          0.014294837,
          -0.25959376,
          -3.5410137,
          0.09915522,
          -2.9111972,
          0.5321095,
          1.5613972,
          -2.4532216,
          -1.079095,
          -0.17231162,
          1.3620075
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Datasets server - worker\n\n> Workers that pre-compute and cache the response to /splits, /first-rows,..."
          ],
          [
           "Also, set the assets-related configuration for the first-rows worker. See [../../libs/libcommon/READ..."
          ],
          [
           "```\n</p>\n</details> \n\n##### float\n\nBin size for histogram is counted as `(max_value - min_value) / D..."
          ],
          [
           "--\ntitle: Datasets Server Admin UI\nemoji: 📊\ncolorFrom: gray\ncolorTo: purple\nsdk: gradio\nsdk_version:..."
          ],
          [
           "Filter rows in a dataset\n\nDatasets Server provides a `/filter` endpoint for filtering rows in a data..."
          ],
          [
           "List Parquet files\n\nDatasets can be published in any format (CSV, JSONL, directories of images, etc...."
          ],
          [
           "```\n</python>\n<js>\n```js\nimport fetch from \"node-fetch\";\nasync function query(data) {\n    const resp..."
          ],
          [
           "datasets-server Helm chart\n\nThe `datasets-server` Helm [chart](https://helm.sh/docs/topics/charts/) ..."
          ],
          [
           "How to contribute to the Datasets Server?\n\n[![Contributor Covenant](https://img.shields.io/badge/Con..."
          ],
          [
           "DuckDB\n\n[DuckDB](https://duckdb.org/docs/) is a database that supports reading and querying Parquet ..."
          ],
          [
           "Overview\n\nDatasets Server automatically converts and publishes public datasets less than 5GB on the ..."
          ],
          [
           "Pandas\n\n[Pandas](https://pandas.pydata.org/docs/index.html) is a popular DataFrame library for data ..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "Check dataset validity\n\nBefore you download a dataset from the Hub, it is helpful to know if a speci..."
          ],
          [
           "Security Policy\n\n## Supported Versions\n\n<!--\nUse this section to tell people about which versions of..."
          ],
          [
           "Datasets server admin machine\n\n> Admin endpoints\n\n## Configuration\n\nThe worker can be configured usi..."
          ],
          [
           "Get dataset information\n\nDatasets Server provides an `/info` endpoint for exploring the general info..."
          ],
          [
           "Datasets server\n\n> Integrate into your apps over 10,000 datasets via simple HTTP requests, with pre-..."
          ],
          [
           "Download slices of rows\n\nDatasets Server provides a `/rows` endpoint for visualizing any slice of ro..."
          ],
          [
           "```\n</curl>\n</inferencesnippet>\n\nThe endpoint response is a JSON containing two keys:\n\n- The [`featu..."
          ],
          [
           "```json\n// https://datasets-server.huggingface.co/rows?dataset=duorc&config=SelfRC&split=train&offse..."
          ],
          [
           "\"title\": \"Mortal Kombat\",\n        \"question_id\": \"40c1866a-b214-11ba-be57-8979d2cefa90\",\n        \"qu..."
          ],
          [
           "```\n\n## Image and audio samples\n\nImage and audio are represented by a URL that points to the file.\n\n..."
          ],
          [
           "Quickstart\n\n[[open-in-colab]]\n\nIn this quickstart, you'll learn how to use the Datasets Server's RES..."
          ],
          [
           "```\n</js>\n<curl>\n```curl\ncurl https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoe..."
          ],
          [
           "```\n</python>\n<js>\n```js\nimport fetch from \"node-fetch\";\nasync function query(data) {\n    const resp..."
          ],
          [
           "Datasets server SSE API\n\n> Server-sent events API for the Datasets server. It's used to update the H..."
          ],
          [
           "libapi\n\nA Python library for the API services\n\n## Configuration\n\nThe APIs can be configured using en..."
          ],
          [
           "ClickHouse\n\n[ClickHouse](https://clickhouse.com/docs/en/intro) is a fast and efficient column-orient..."
          ],
          [
           "Analyze a dataset on the Hub\n\n[[open-in-colab]]\n\nIn the Quickstart, you were introduced to various e..."
          ],
          [
           "Polars \n\n[Polars](https://pola-rs.github.io/polars-book/user-guide/) is a fast DataFrame library wri..."
          ],
          [
           "Explore statistics over split data\n\nDatasets Server provides a `/statistics` endpoint for fetching s..."
          ],
          [
           "```\n\n</p>\n</details>\n\n### bool\n\nThe following measures are returned for bool data type:\n\n* number an..."
          ],
          [
           "libcommon\n\nA Python library with common code (cache, queue, workers logic, processing steps, configu..."
          ],
          [
           "Splits and configurations\n\nMachine learning datasets are commonly organized in *splits* and they may..."
          ],
          [
           "e2e\n\nEnd to end tests, written in Python..."
          ],
          [
           "Preview a dataset\n\nDatasets Server provides a `/first-rows` endpoint for visualizing the first 100 r..."
          ],
          [
           "```\n\n## Truncated responses\n\nFor some datasets, the response size from `/first-rows` may exceed 1MB,..."
          ],
          [
           "Search text in a dataset\n\nDatasets Server provides a `/search` endpoint for searching words in a dat..."
          ],
          [
           "```\n</curl>\n</inferencesnippet>\n\nThe endpoint response is a JSON containing two keys (same format as..."
          ],
          [
           "```json\n{\n  \"features\": [\n    {\n      \"feature_idx\": 0,\n      \"name\": \"plot_id\",\n      \"type\": { \"dt..."
          ],
          [
           "\"type\": { \"dtype\": \"string\", \"_type\": \"Value\" }\n    },\n    {\n      \"feature_idx\": 2,\n      \"name\": \"..."
          ],
          [
           "\"title\": \"Three Colors: Red\",\n        \"question_id\": \"7c583513-0b7f-ddb3-be43-64befc7e90cc\",\n       ..."
          ],
          [
           "```\n\nIf the result has `partial: true` it means that the search couldn't be run on the full dataset ..."
          ],
          [
           "Developer guide\n\nThis document is intended for developers who want to install, test or contribute to..."
          ],
          [
           "```\nact -j build-and-push-image-to-docker-hub --secret-file my.secrets\n```\n\nwith `my.secrets` a file..."
          ],
          [
           "Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge..."
          ],
          [
           "Server infrastructure\n\nThe [Datasets Server](https://github.com/huggingface/datasets-server) has two..."
          ],
          [
           "Datasets server maintenance job\n\n> Job to run maintenance actions on the datasets-server\n\nAvailable ..."
          ],
          [
           "Datasets server - storage admin\n\n> A Ubuntu machine to log into and manage the storage manually..."
          ],
          [
           "🤗 Datasets Server\n\nDatasets Server is a lightweight web API for visualizing and exploring all types ..."
          ],
          [
           "Get the number of rows and the size in bytes\n\nThis guide shows you how to use Datasets Server's `/si..."
          ],
          [
           "Datasets server API - rows endpoint\n\n> /rows endpoint\n\n## Configuration\n\nThe service can be configur..."
          ],
          [
           "Datasets server - reverse proxy\n\n> Reverse-proxy in front of the API\n\nSee [docker-compose-datasets-s..."
          ],
          [
           "Data types\n\nDatasets supported by Datasets Server have a tabular format, meaning a data point is rep..."
          ],
          [
           "List splits and configurations\n\nDatasets typically have splits and may also have configurations. A _..."
          ],
          [
           "Datasets server API\n\n> API on 🤗 datasets\n\n## Configuration\n\nThe service can be configured using envi..."
          ],
          [
           "Datasets server API - search service\n\n> /search endpoint\n> /filter endpoint\n\n## Configuration\n\nThe s..."
          ],
          [
           "Datasets server databases migrations\n\n> Scripts to migrate the datasets server databases\n\n## Configu..."
          ]
         ],
         "hovertemplate": "source=datasets-server<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "datasets-server, circle",
         "marker": {
          "color": "#636efa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "datasets-server, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -1.745143,
          -2.9459918,
          1.4116434,
          2.152743,
          -1.9633592,
          -2.912448,
          -0.24590907,
          3.1663716,
          -3.4646726,
          -4.174531,
          -1.0621929,
          -1.5681976,
          -0.20616119,
          3.941683,
          -1.0809629,
          2.0891712,
          -3.8525028,
          4.0615935,
          2.5651014,
          -0.32907858,
          0.25928676,
          -3.8606782,
          -1.8769572,
          -1.2783921,
          -1.3482567,
          0.73408073,
          -2.8599627,
          0.76714337,
          -0.74841356,
          -1.9327391,
          2.3296344,
          -2.4838388,
          -0.84245753,
          0.35318446,
          4.7837553,
          1.7943203,
          2.6014578,
          -0.0877919,
          -1.3632929,
          0.8748411,
          -1.5213999,
          3.8672001,
          -3.073337,
          -3.029954,
          2.5672846,
          -0.15424502,
          1.8464888,
          -0.11186668,
          -2.9558003,
          -0.103516765,
          -3.0194218,
          -2.5787456,
          3.4983416,
          -2.2239583,
          -3.2031243,
          -3.091763,
          1.4747981,
          1.6439065,
          -3.1038532
         ],
         "xaxis": "x",
         "y": [
          -2.3004453,
          -3.8258095,
          0.80312276,
          -4.3754163,
          -2.9780724,
          3.0554106,
          -5.679115,
          1.6348789,
          1.2037776,
          3.1364324,
          -2.410628,
          -5.054594,
          -0.48943475,
          -1.5005265,
          3.8650787,
          -2.9634426,
          -1.2829889,
          1.3776903,
          -3.2643533,
          -4.5759745,
          1.0909168,
          2.9488513,
          -3.5841618,
          -4.052499,
          -3.9941902,
          -3.3136919,
          1.826115,
          -3.636447,
          2.2677906,
          -3.3938348,
          -2.2962487,
          -2.0559866,
          -5.4353004,
          -4.7331395,
          0.49459198,
          -5.1514044,
          1.1891952,
          -4.592266,
          -4.0514374,
          -3.759914,
          -6.605523,
          -1.5387707,
          3.657186,
          1.7733451,
          1.8696786,
          -5.542408,
          4.67915,
          0.19011542,
          -3.4926124,
          3.9418087,
          -0.90212625,
          -0.7031307,
          1.1696507,
          -3.291928,
          0.18536036,
          -3.115811,
          -2.5222926,
          0.80008215,
          -3.7647183
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Differences between Dataset and IterableDataset\n\nThere are two types of dataset objects, a [`Dataset..."
          ],
          [
           "```\n\n## Speed differences\n\nRegular [`Dataset`] objects are based on Arrow which provides fast random..."
          ],
          [
           "Metric Card for F1\n\n\n## Metric Description\n\nThe F1 score is the harmonic mean of the precision and r..."
          ],
          [
           "Cache management\n\nWhen you download a dataset, the processing scripts and data are stored locally on..."
          ],
          [
           "Metric Card for MSE\n\n\n## Metric Description\n\nMean Squared Error(MSE) represents the average of the s..."
          ],
          [
           "All about metrics\n\n<Tip warning={true}>\n\nMetrics is deprecated in 🤗 Datasets. To learn more about ho..."
          ],
          [
           "Metric Card for METEOR\n\n## Metric description\n\nMETEOR (Metric for Evaluation of Translation with Exp..."
          ],
          [
           "Preprocess\n\nIn addition to loading datasets, 🤗 Datasets other main goal is to offer a diverse set of..."
          ],
          [
           "```\n\n**4**. Use the [`~Dataset.map`] function to resample the entire dataset to 16kHz. This function..."
          ],
          [
           "Image classification\n\nImage classification datasets are used to train a model to classify an entire ..."
          ],
          [
           "Beam Datasets\n\nSome datasets are too large to be processed on a single machine. Instead, you can pro..."
          ],
          [
           "Load image data\n\nImage datasets have [`Image`] type columns, which contain PIL objects. \n\n<Tip>\n\nTo ..."
          ],
          [
           "Metric Card for Recall\n\n\n## Metric Description\n\nRecall is the fraction of the positive examples that..."
          ],
          [
           "Dataset features\n\n[`Features`] defines the internal structure of a dataset. It is used to specify th..."
          ],
          [
           "Metric Card for GLUE\n\n## Metric description\nThis metric is used to compute the GLUE evaluation metri..."
          ],
          [
           "Metric Card for Matthews Correlation Coefficient\n\n## Metric Description\nThe Matthews correlation coe..."
          ],
          [
           "Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge..."
          ],
          [
           "Table Classes\n\nEach `Dataset` object is backed by a PyArrow Table.\nA Table can be loaded from either..."
          ],
          [
           "Metric Card for Precision\n\n\n## Metric Description\n\nPrecision is the fraction of correctly labeled po..."
          ],
          [
           "Load tabular data\n\nA tabular dataset is a generic dataset used to describe any data stored in rows a..."
          ],
          [
           "--\nTODO: Add YAML tags here. Copy-paste the tags obtained with the online tagging app: https://huggi..."
          ],
          [
           "Use with Spark\n\nThis document is a quick introduction to using 🤗 Datasets with Spark, with a particu..."
          ],
          [
           "p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://huggi..."
          ],
          [
           "```\n\nIf your dataset is bigger than your disk or if you don't want to wait to download the data, you..."
          ],
          [
           "The cache\n\nThe cache is one of the reasons why 🤗 Datasets is so efficient. It stores previously down..."
          ],
          [
           "Metric Card for chrF(++)\n\n\n## Metric Description\nChrF and ChrF++ are two MT evaluation metrics that ..."
          ],
          [
           "Metric Card for BERT Score\n\n## Metric description\n\nBERTScore is an automatic evaluation metric for t..."
          ],
          [
           "Metric Card for ROUGE\n\n## Metric Description\nROUGE, or Recall-Oriented Understudy for Gisting Evalua..."
          ],
          [
           "Metric Card for Exact Match\n\n\n## Metric Description\nA given predicted string's exact match score is ..."
          ],
          [
           "Metric Card for COMET\n\n## Metric description\n\nCrosslingual Optimized Metric for Evaluation of Transl..."
          ],
          [
           "Metric Card for seqeval\n\n## Metric description\n\nseqeval is a Python framework for sequence labeling ..."
          ],
          [
           "Utilities\n\n## Configure logging\n\n🤗 Datasets strives to be transparent and explicit about how it work..."
          ],
          [
           "Use with PyTorch\n\nThis document is a quick introduction to using `datasets` with PyTorch, with a par..."
          ],
          [
           "```\n\nIf the dataset is split in several shards (i.e. if the dataset consists of multiple data files)..."
          ],
          [
           "Semantic segmentation\n\nSemantic segmentation datasets are used to train a model to classify every pi..."
          ],
          [
           "Metric Card for *Current Metric*\n\n***Metric Card Instructions:*** *Copy this file into the relevant ..."
          ],
          [
           "Metric Card for WikiSplit\n\n## Metric description\n\nWikiSplit is the combination of three metrics: [SA..."
          ],
          [
           "Metric Card for FrugalScore\n\n\n## Metric Description\nFrugalScore is a reference-based metric for Natu..."
          ],
          [
           "How to add one new datasets\n\nAdd datasets directly to the 🤗 Hugging Face Hub!\n\nYou can share your da..."
          ],
          [
           "Metric Card for Google BLEU (GLEU)\n\n\n## Metric Description\nThe BLEU score has some undesirable prope..."
          ],
          [
           "```\n\nExample with multiple references for the first sample, with `min_len` adjusted to `2`, instead ..."
          ],
          [
           "# Add Dummy data test\n\n**Important** In order to pass the `load_dataset_<dataset_name>` test, dummy ..."
          ],
          [
           "Main classes\n\n\n## DatasetInfo\n\n[[autodoc]] datasets.DatasetInfo\n\n## Dataset\n\nThe base class [`Datase..."
          ],
          [
           "Metric Card for COVAL\n\n## Metric description\n\nCoVal is a coreference evaluation tool for the [CoNLL]..."
          ],
          [
           "```\n\n## Limitations and bias\n\nThis wrapper of CoVal currently only works with [CoNLL line format](ht..."
          ],
          [
           "```\n\n```bibtex\n@INPROCEEDINGS{Bagga98algorithmsfor,\n    author = {Amit Bagga and Breck Baldwin},\n   ..."
          ],
          [
           "Overview\n\nThe how-to guides offer a more comprehensive overview of all the tools 🤗 Datasets offers a..."
          ],
          [
           "Metric Card for SacreBLEU\n\n\n## Metric Description\nSacreBLEU provides hassle-free computation of shar..."
          ],
          [
           "Cloud storage\n\n🤗 Datasets supports access to cloud storage providers through a `fsspec` FileSystem i..."
          ],
          [
           "```\n\n<Tip>\n\nRemember to define your credentials in your [FileSystem instance](#set-up-your-cloud-sto..."
          ],
          [
           "Metric Card for BLEU\n\n\n## Metric Description\nBLEU (Bilingual Evaluation Understudy) is an algorithm ..."
          ],
          [
           "Create an image dataset\n\nThere are two methods for creating and sharing an image dataset. This guide..."
          ],
          [
           "```\n\n## Loading script\n\nWrite a dataset loading script to share a dataset. It defines a dataset's sp..."
          ],
          [
           "```\n\n### Download and define the dataset splits\n\nNow that you've added some information about your d..."
          ],
          [
           "Create a dataset card\n\nEach dataset should have a dataset card to promote responsible usage and info..."
          ],
          [
           "Process\n\n🤗 Datasets provides many tools for modifying the structure and content of a dataset. These ..."
          ],
          [
           "```\n\n### Remove\n\nWhen you need to remove one or more columns, provide the column name to remove to t..."
          ],
          [
           "```\n\n### Multiprocessing\n\nMultiprocessing significantly speeds up processing by parallelizing proces..."
          ],
          [
           "```\n\n### Distributed usage\n\nWhen you use [`~Dataset.map`] in a distributed setting, you should also ..."
          ],
          [
           "```\n\n## Save\n\nOnce you are done processing your dataset, you can save and reuse it later with [`~Dat..."
          ],
          [
           "Metric Card for SQuAD v2\n\n## Metric description\nThis metric wraps the official scoring script for ve..."
          ],
          [
           "Metric Card for Perplexity\n\n## Metric Description\nGiven a model and an input text sequence, perplexi..."
          ],
          [
           "Overview\n\nWelcome to the 🤗 Datasets tutorials! These beginner-friendly tutorials will guide you thro..."
          ],
          [
           "Metric Card for Pearson Correlation Coefficient (pearsonr)\n\n\n## Metric Description\n\nPearson correlat..."
          ],
          [
           "Load audio data\n\nYou can load an audio dataset using the [`Audio`] feature that automatically decode..."
          ],
          [
           "Search index\n\n[FAISS](https://github.com/facebookresearch/faiss) and [Elasticsearch](https://www.ela..."
          ],
          [
           "How to contribute to Datasets?\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20C..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n**6**. Set the dataset format according to the machine learning framework you're using.\n\n<frame..."
          ],
          [
           "```\n\n**3**. Create a function to tokenize the dataset, and you should also truncate and pad the text..."
          ],
          [
           "Process text data\n\nThis guide shows specific methods for processing text datasets. Learn how to:\n\n- ..."
          ],
          [
           "Security Policy\n\n## Supported Versions\n<!--\nUse this section to tell people about which versions of ..."
          ],
          [
           "Process audio data\n\nThis guide shows specific methods for processing audio datasets. Learn how to:\n\n..."
          ],
          [
           "Task templates\n\n<Tip warning={true}>\n\nThe Task API is deprecated in favor of [`train-eval-index`](ht..."
          ],
          [
           "Object detection\n\nObject detection models identify something in an image, and object detection datas..."
          ],
          [
           "Load\n\nYour data can be stored in various places; they can be on your local machine's disk, in a Gith..."
          ],
          [
           "```\n\nTo load remote Parquet files via HTTP, pass the URLs instead:\n\n```py\n>>> base_url = \"https://st..."
          ],
          [
           "```\n\nOr select a percentage of a split with:\n\n```py\n>>> train_10pct_ds = datasets.load_dataset(\"book..."
          ],
          [
           "```\n\n<Tip>\n\nSee the [Metrics](./how_to_metrics#custom-metric-loading-script) guide for more details ..."
          ],
          [
           "Metric Card for SuperGLUE\n\n## Metric description\nThis metric is used to compute the SuperGLUE evalua..."
          ],
          [
           "Stream\n\nDataset streaming lets you work with a dataset without downloading it.\nThe data is streamed ..."
          ],
          [
           "```\n\nDefine sampling probabilities from each of the original datasets for more control over how each..."
          ],
          [
           "```\n\n<Tip>\n\nSee other examples of batch processing in the [batched map processing](./process#batch-p..."
          ],
          [
           "Depth estimation\n\nDepth estimation datasets are used to train a model to approximate the relative di..."
          ],
          [
           "```\n\nUse the [`~Dataset.set_transform`] function to apply the transformation on-the-fly to batches o..."
          ],
          [
           "Using Datasets with TensorFlow\n\nThis document is a quick introduction to using `datasets` with Tenso..."
          ],
          [
           "```\n\nThe returned `tf_ds` object here is now fully ready to train on, and can be passed directly to ..."
          ],
          [
           "Metric Card for Mahalanobis Distance\n\n## Metric Description\nMahalonobis distance is the distance bet..."
          ],
          [
           "Troubleshooting\n\nThis guide aims to provide you the tools and knowledge required to navigate some co..."
          ],
          [
           "Process image data\n\nThis guide shows specific methods for processing image datasets. Learn how to:\n\n..."
          ],
          [
           "Builder classes\n\n## Builders\n\n🤗 Datasets relies on two main classes during the dataset building proc..."
          ],
          [
           "Metrics\n\n<Tip warning={true}>\n\nMetrics is deprecated in 🤗 Datasets. To learn more about how to use m..."
          ],
          [
           "```\n\n### Compute score\n\n[`DatasetBuilder._compute`] provides the actual instructions for how to comp..."
          ],
          [
           "Metric Card for MAUVE\n\n## Metric description\n\nMAUVE is a library built on PyTorch and HuggingFace Tr..."
          ],
          [
           "Create a dataset loading script\n\n\n<Tip>\n\nThe dataset loading script is likely not needed if your dat..."
          ],
          [
           "```\n\n3. Now, users can load a specific configuration of the dataset with the configuration `name`:\n\n..."
          ],
          [
           "```\n\nUsers can also specify `num_proc=` in `load_dataset()` to specify the number of processes to us..."
          ],
          [
           "Metric Card for Competition MATH\n\n## Metric description\n\nThis metric is used to assess performance o..."
          ],
          [
           "Metric Card for SARI\n\n\n## Metric description\nSARI (***s**ystem output **a**gainst **r**eferences and..."
          ],
          [
           "Metric Card for Mean IoU \n\n\n## Metric Description\n\nIoU (Intersection over Union) is the area of over..."
          ],
          [
           "Metric Card for ROC AUC\n\n\n## Metric Description\nThis metric computes the area under the curve (AUC) ..."
          ],
          [
           "```\n\n\n## Limitations and Bias\n\n\n## Citation\n```bibtex\n@article{doi:10.1177/0272989X8900900307,\nautho..."
          ],
          [
           "Use with JAX\n\nThis document is a quick introduction to using `datasets` with JAX, with a particular ..."
          ],
          [
           "Build and load\n\nNearly every deep learning workflow begins with loading a dataset, which makes it on..."
          ],
          [
           "## Maintaining integrity\n\nTo ensure a dataset is complete, [`load_dataset`] will perform a series of..."
          ],
          [
           "Metric Card for Accuracy\n\n\n## Metric Description\n\nAccuracy is the proportion of correct predictions ..."
          ],
          [
           "Metric Card for CER\n\n## Metric description\n\nCharacter error rate (CER) is a common metric of the per..."
          ],
          [
           "Metric Card for XTREME-S\n\n\n## Metric Description\n\nThe XTREME-S metric aims to evaluate model perform..."
          ],
          [
           "Metric Card for WER\n\n## Metric description\nWord error rate (WER) is a common metric of the performan..."
          ],
          [
           "Share a dataset to the Hub\n\nThe [Hub](https://huggingface.co/datasets) is home to an extensive colle..."
          ],
          [
           "Metric Card for SQuAD\n\n## Metric description\nThis metric wraps the official scoring script for versi..."
          ],
          [
           "Loading methods\n\nMethods for listing and loading datasets and metrics:\n\n## Datasets\n\n[[autodoc]] dat..."
          ],
          [
           "Metric Card for CUAD\n\n## Metric description\n\nThis metric wraps the official scoring script for versi..."
          ],
          [
           "Datasets 🤝 Arrow\n\n## What is Arrow?\n\n[Arrow](https://arrow.apache.org/) enables large amounts of dat..."
          ],
          [
           "Metric Card for IndicGLUE\n\n## Metric description\nThis metric is used to compute the evaluation metri..."
          ],
          [
           "Structure your repository\n\nTo host and share your dataset, create a dataset repository on the Huggin..."
          ],
          [
           "Load a dataset from the Hub\n\nFinding high-quality datasets that are reproducible and accessible can ..."
          ],
          [
           "Metric Card for Code Eval\n\n## Metric description\n\nThe CodeEval metric estimates the pass@k metric fo..."
          ],
          [
           "Create a dataset\n\nSometimes, you may need to create a dataset if you're working with your own data. ..."
          ],
          [
           "Create an audio dataset\n\nYou can share a dataset with your team or with anyone in the community by c..."
          ],
          [
           "```\nmy_dataset/\n├── README.md\n├── my_dataset.py\n└── data/\n```\n\nThe `data` folder can be any name you..."
          ],
          [
           "```\n\n### Add dataset metadata\n\nAdding information about your dataset helps users to learn more about..."
          ],
          [
           "```\n\n3. Use the [`~DownloadManager.iter_archive`] method to iterate over the archive at `audio_path`..."
          ],
          [
           "Share a dataset using the CLI\n\nAt Hugging Face, we are on a mission to democratize good Machine Lear..."
          ],
          [
           "Metric Card for Spearman Correlation Coefficient Metric (spearmanr)\n\n\n## Metric Description\nThe Spea..."
          ],
          [
           "Datasets\n\n<img class=\"float-left !m-0 !border-0 !dark:border-0 !shadow-none !max-w-lg w-[150px]\" src..."
          ],
          [
           "Load text data\n\nThis guide shows you how to load text datasets. To learn how to load any type of dat..."
          ],
          [
           "Metric Card for TER\n\n## Metric Description\nTER (Translation Edit Rate, also called Translation Error..."
          ],
          [
           "Metric Card for MAE\n\n\n## Metric Description\n\nMean Absolute Error (MAE) is the mean of the magnitude ..."
          ],
          [
           "--\nYAML tags (full spec here: https://github.com/huggingface/hub-docs/blob/main/datasetcard.md?plain..."
          ],
          [
           "```\n{\n  'example_field': ...,\n  ...\n}\n```\n\nProvide any additional information that is not covered in..."
          ],
          [
           "```\n@article{article_id,\n  author    = {Author List},\n  title     = {Dataset Paper Title},\n  journal..."
          ],
          [
           "Know your dataset\n\nThere are two types of dataset objects, a regular [`Dataset`] and then an ✨ [`Ite..."
          ],
          [
           "Metric Card for XNLI\n\n## Metric description\n\nThe XNLI metric allows to evaluate a model's score on t..."
          ],
          [
           "Evaluate predictions\n\n<Tip warning={true}>\n\nMetrics is deprecated in 🤗 Datasets. To learn more about..."
          ],
          [
           "Batch mapping\n\nCombining the utility of [`Dataset.map`] with batch mode is very powerful. It allows ..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n```\n# first line of code\n# second line\n# etc\n```\n````\n\n#### Writing a return block\n\nThe return b..."
          ],
          [
           "Installation\n\nBefore you start, you'll need to setup your environment and install the appropriate pa..."
          ]
         ],
         "hovertemplate": "source=datasets<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "datasets, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "datasets, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -2.3644538,
          -1.2682292,
          3.9667547,
          -0.68932045,
          0.38454357,
          2.1210477,
          0.16423948,
          0.62473917,
          2.5763268,
          2.722683,
          -2.0167272,
          -4.2336597,
          -2.5834076,
          1.5603994,
          -0.9424755,
          4.194832,
          1.7933798,
          -2.0274732,
          3.8294547,
          2.2840607,
          -3.0227425,
          -2.4228983,
          1.3930725,
          1.9261258,
          0.84593546,
          -3.5376153,
          -3.4470952,
          -2.4523501,
          -1.1039894,
          5.1315312,
          3.5155017,
          -3.3374388,
          -1.7940481,
          0.073070146,
          -2.6783211,
          0.6647103,
          -3.2316432,
          -2.692203,
          -0.5380883,
          2.4757292,
          -0.9374619,
          -4.826393,
          1.4492646,
          0.3016738,
          -4.760579,
          0.0831709,
          2.2958095,
          -1.7048014,
          -2.5266213,
          1.8559787,
          0.48631692,
          -4.361432,
          -0.6131333,
          -3.551014,
          -4.2930593,
          2.5720801,
          1.4729766,
          4.313133,
          3.224265,
          -2.733003,
          -0.5133753,
          -2.2131,
          -1.3460597,
          1.531264,
          0.0673851,
          -1.7109116,
          1.9242948,
          -3.4579017,
          -3.423501,
          -0.43336043,
          2.7895274,
          -1.4960186,
          -1.9692423,
          -0.93266803,
          -0.105135694,
          -0.5846525,
          -0.7030694,
          -3.0190825,
          -2.2943692,
          1.3096414,
          3.0539005,
          -2.2540245,
          3.1229584,
          3.9859843,
          -2.593244,
          0.9949128,
          2.7238204,
          1.4073539,
          -1.5429491,
          1.2678716,
          -1.4296724,
          -1.911607,
          -3.6488843,
          4.1269,
          3.5549667,
          -1.4806732,
          -1.4582057,
          1.1972737,
          -0.043240115,
          -2.5473502,
          4.8613796,
          2.8757315,
          3.2021341,
          0.9827435,
          -3.2249992,
          -0.7613776,
          -0.9315868,
          4.5349307,
          2.0769591,
          -3.5495806,
          -3.3329337,
          -2.3122156,
          0.14917178,
          2.1797132,
          -0.16462441,
          1.0192698,
          -2.9245207,
          -2.8666215,
          -1.7168286,
          -3.639026,
          -2.2925622,
          -0.5064055,
          0.7829453,
          -1.2816347,
          -2.3932939,
          -4.112722,
          -1.8132007,
          3.2949343,
          -4.213836,
          1.6964166,
          0.7609254,
          -0.14347665,
          2.056296,
          2.0570407,
          3.3827658,
          1.9570587,
          0.5890154,
          -2.9834478,
          -2.856252,
          0.3097568
         ],
         "xaxis": "x",
         "y": [
          -3.9004903,
          -4.3472543,
          -1.8142245,
          -4.7902646,
          -4.2743807,
          4.032779,
          -2.722696,
          -3.1982815,
          -2.8447545,
          0.51808065,
          -3.5723042,
          0.122364886,
          -0.88550115,
          -3.80224,
          -2.0153427,
          1.371863,
          4.653772,
          -5.426463,
          -0.37750727,
          -3.6418262,
          -3.8804922,
          -2.3242018,
          -2.2433555,
          2.8334577,
          -3.4659476,
          -1.7842157,
          -0.5073129,
          -2.69251,
          -2.349681,
          0.5145152,
          1.5108498,
          -4.3833885,
          -4.5836563,
          -3.4417615,
          0.048056856,
          -2.5894454,
          0.49921542,
          -4.4183326,
          2.316683,
          1.0595698,
          4.1556673,
          1.3876755,
          -4.6874437,
          3.6362295,
          1.5966386,
          -5.0305147,
          3.430874,
          -1.7357615,
          -4.065597,
          -4.7289386,
          1.0293466,
          -0.47615075,
          -0.8015603,
          -2.7605662,
          1.2177128,
          -3.9986084,
          -3.177897,
          -0.43019265,
          -2.9126716,
          -5.0420594,
          -3.3676815,
          3.157073,
          4.189544,
          -2.0465703,
          -2.6123781,
          -5.215458,
          0.4422705,
          1.210077,
          -1.3098775,
          -0.024127109,
          -0.7114989,
          3.3335135,
          -4.200563,
          -4.036095,
          -3.6832438,
          -4.4578733,
          -4.35348,
          -0.18993008,
          -4.684912,
          -0.5543,
          -2.9869456,
          -3.8691509,
          -3.3986182,
          2.155498,
          -2.0727723,
          -2.8757467,
          -0.9028071,
          -2.8642385,
          -2.5148644,
          -3.4336782,
          -5.5358653,
          0.46412343,
          -0.3572873,
          0.91253346,
          -1.8440188,
          -3.5683577,
          -6.460984,
          -2.8565938,
          -1.6160351,
          -3.3824778,
          0.5384836,
          1.7380178,
          -2.2564256,
          -3.7229948,
          1.179197,
          0.15008007,
          -2.0318234,
          -0.61839515,
          -0.8643425,
          -1.6088799,
          -2.3959055,
          -4.509326,
          2.2025816,
          1.4011796,
          -2.4018688,
          -4.0524583,
          -3.0432575,
          0.5489978,
          -4.148455,
          0.45422035,
          -3.5418966,
          -4.093474,
          0.030543203,
          -1.4689723,
          -2.1364608,
          -0.5019281,
          -4.0760226,
          -1.8394595,
          1.6977314,
          2.7958379,
          4.4581256,
          -5.148147,
          3.2407007,
          -2.9327493,
          -2.821145,
          0.32941788,
          4.708126,
          0.553989,
          -1.7990901,
          -4.2765393
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Q-Learning Recap [[q-learning-recap]]\n\n\n*Q-Learning* **is the RL algorithm that** :\n\n- Trains a *Q-f..."
          ],
          [
           "Quiz\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lectu..."
          ],
          [
           "Additional Readings\n\nThese are **optional readings** if you want to go deeper.\n\n\n## Introduction to ..."
          ],
          [
           "Hands-on\n\nNow that you learned the basics of multi-agents, you're ready to train your first agents i..."
          ],
          [
           "```\n\nTo be able to train our agents correctly and push to the Hub, we need to install ML-Agents\n\n```..."
          ],
          [
           "```\n\nThe executable contains 8 copies of SoccerTwos.\n\n⚠️ It’s normal if you don’t see a big increase..."
          ],
          [
           "Two types of value-based methods [[two-types-value-based-methods]]\n\nIn value-based methods, **we lea..."
          ],
          [
           "The advantages and disadvantages of policy-gradient methods\n\nAt this point, you might ask, \"but Deep..."
          ],
          [
           "Glossary \n\nThis is a community-created glossary. Contributions are welcome!\n\n- **Deep Q-Learning:** ..."
          ],
          [
           "Conclusion [[conclusion]]\n\nCongrats on finishing this unit! **That was the biggest one**, and there ..."
          ],
          [
           "Introduction\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/res..."
          ],
          [
           "Introduction to Q-Learning [[introduction-q-learning]]\n\n<img src=\"https://huggingface.co/datasets/hu..."
          ],
          [
           "Conclusion\n\nCongrats on finishing this unit! You’ve just trained your first ML-Agents and shared it ..."
          ],
          [
           "Language models in RL\n## LMs encode useful knowledge for agents\n\n**Language models** (LMs) can exhib..."
          ],
          [
           "The Deep Q-Network (DQN)  [[deep-q-network]]\nThis is the architecture of our Deep Q-Learning network..."
          ],
          [
           "The certification process\n\n\nThe certification process is **completely free**:\n\n- To get a *certifica..."
          ],
          [
           "Summary [[summary]]\n\nThat was a lot of information! Let's summarize:\n\n- Reinforcement Learning is a ..."
          ],
          [
           "Glossary [[glossary]]\n\nThis is a community-created glossary. Contributions are welcomed!\n\n\n### Strat..."
          ],
          [
           "The Reinforcement Learning Framework [[the-reinforcement-learning-framework]]\n\n## The RL Process [[t..."
          ],
          [
           "As we can see in the diagram, **it’s more probable to eat the cheese near us than the cheese close t..."
          ],
          [
           "Introduction [[introduction]]\n\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course..."
          ],
          [
           "From Q-Learning to Deep Q-Learning [[from-q-to-dqn]]\n\nWe learned that **Q-Learning is an algorithm w..."
          ],
          [
           "Additional Readings [[additional-readings]]\n\nThese are **optional readings** if you want to go deepe..."
          ],
          [
           "Hands-on\n\n<CourseFloatingBanner classNames=\"absolute z-10 right-0 top-0\"\nnotebooks={[\n  {label: \"Goo..."
          ],
          [
           "```\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main..."
          ],
          [
           "```\n\nUnzip it\n\n```python\n%%capture\n!unzip -d ./training-envs-executables/linux/ ./training-envs-exec..."
          ],
          [
           "Decision Transformers\n\nThe Decision Transformer model was introduced by [\"Decision Transformer: Rein..."
          ],
          [
           "Additional Readings [[additional-readings]]\n\n##  An introduction to multi-agents\n\n- [Multi-agent rei..."
          ],
          [
           "Introducing Q-Learning [[q-learning]]\n## What is Q-Learning? [[what-is-q-learning]]\n\nQ-Learning is a..."
          ],
          [
           "How do we form the TD target?\n1. We obtain the reward \\\\(R_{t+1}\\\\) after taking the action \\\\(A_t\\\\..."
          ],
          [
           "Play with Huggy [[play]]\n\nNow that you've trained Huggy and pushed it to the Hub. **You will be able..."
          ],
          [
           "Discord 101 [[discord-101]]\n\nHey there! My name is Huggy, the dog 🐕, and I'm looking forward to trai..."
          ],
          [
           "Introduction [[introduction]]\n\nOne of the most critical tasks in Deep Reinforcement Learning is to *..."
          ],
          [
           "Designing Multi-Agents systems\n\nFor this section, you're going to watch this excellent introduction ..."
          ],
          [
           "Additional Readings [[additional-readings]]\n\nThese are **optional readings** if you want to go deepe..."
          ],
          [
           "Hands-on\n\n\n      <CourseFloatingBanner classNames=\"absolute z-10 right-0 top-0\"\n      notebooks={[\n ..."
          ],
          [
           "```\n\n- Next, we add the methods needed to push the model to the Hub\n\n- These methods will:\n  - `_eva..."
          ],
          [
           "with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n        f.write(readme)\n\n    # Save our metrics t..."
          ],
          [
           "```\n\n- Finally, we call this function at the end of the PPO training\n\n```python\n# Create the evaluat..."
          ],
          [
           "```\n\n- Here's what the final ppo.py file looks like:\n\n```python\n# docs and experiment results can be..."
          ],
          [
           "# Step 5: Generate the model card\n        generated_model_card, metadata = _generate_model_card(\n   ..."
          ],
          [
           "if __name__ == \"__main__\":\n    args = parse_args()\n    run_name = f\"{args.env_id}__{args.exp_name}__..."
          ],
          [
           "entropy_loss = entropy.mean()\n                loss = pg_loss - args.ent_coef * entropy_loss + v_loss..."
          ],
          [
           "```\n\nTo be able to share your model with the community there are three more steps to follow:\n\n1️⃣ (I..."
          ],
          [
           "The SnowballTarget Environment\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course..."
          ],
          [
           "What are the policy-based methods?\n\nThe main goal of Reinforcement learning is to **find the optimal..."
          ],
          [
           "Advantage Actor Critic (A2C) using Robotics Simulations with Panda-Gym 🤖 [[hands-on]]\n\n\n      <Cours..."
          ],
          [
           "```\n\n#### Solution\n\n```python\nenv = make_vec_env(env_id, n_envs=4)\n\nenv = VecNormalize(env, norm_obs..."
          ],
          [
           "(Optional) What is Curiosity in Deep Reinforcement Learning?\n\nThis is an (optional) introduction to ..."
          ],
          [
           "The “Deep” in Reinforcement Learning [[deep-rl]]\n\n<Tip>\nWhat we've talked about so far is Reinforcem..."
          ],
          [
           "What is RL? A short recap [[what-is-rl]]\n\nIn RL, we build an agent that can **make smart decisions**..."
          ],
          [
           "Conclusion [[Conclusion]]\n\nThat’s all for today. Congrats on finishing this unit and the tutorial!\n\n..."
          ],
          [
           "Diving deeper into policy-gradient methods\n\n## Getting the big picture\n\nWe just learned that policy-..."
          ],
          [
           "## The Reinforce algorithm (Monte Carlo Reinforce)\n\nThe Reinforce algorithm, also called Monte-Carlo..."
          ],
          [
           "Additional Readings [[additional-readings]]\n\n## Bias-variance tradeoff in Reinforcement Learning\n\nIf..."
          ],
          [
           "Let's train and play with Huggy 🐶 [[train]]\n\n\n\n\n          <CourseFloatingBanner classNames=\"absolute..."
          ],
          [
           "```\nbehaviors:\n  Huggy:\n    trainer_type: ppo\n    hyperparameters:\n      batch_size: 2048\n      buff..."
          ],
          [
           "Mid-way Quiz [[mid-way-quiz]]\n\nThe best way to learn and [to avoid the illusion of competence](https..."
          ],
          [
           "Bonus: Learn to create your own environments with Unity and MLAgents\n\n**You can create your own rein..."
          ],
          [
           "Train your first Deep Reinforcement Learning Agent 🤖 [[hands-on]]\n\n\n\n\n      <CourseFloatingBanner cl..."
          ],
          [
           "## Get a certificate 🎓\n\nTo validate this hands-on for the [certification process](https://huggingfac..."
          ],
          [
           "```\n\n```bash\npip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/noteboo..."
          ],
          [
           "```\n\n## Create the Model 🤖\n\n- We have studied our environment and we understood the problem: **being..."
          ],
          [
           "```\n\nIf you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command ins..."
          ],
          [
           "```\n\nLet's evaluate this agent:\n\n```python\n# @title\neval_env = Monitor(gym.make(\"LunarLander-v2\"))\nm..."
          ],
          [
           "Glossary \n\nThis is a community-created glossary. Contributions are welcomed!\n\n- **Tabular Method:** ..."
          ],
          [
           "Live 1: How the course work, Q&A, and playing with Huggy\n\nIn this first live stream, we explained ho..."
          ],
          [
           "Quiz [[quiz]]\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera...."
          ],
          [
           "Additional Readings [[additional-readings]]\n\nThese are **optional readings** if you want to go deepe..."
          ],
          [
           "(Optional) the Policy Gradient Theorem\n\nIn this optional section where we're **going to study how we..."
          ],
          [
           "Introduction to Deep Reinforcement Learning [[introduction-to-deep-reinforcement-learning]]\n\n<img sr..."
          ],
          [
           "Additional Readings [[additional-readings]]\n\nThese are **optional readings** if you want to go deepe..."
          ],
          [
           "Advantage Actor-Critic (A2C) [[advantage-actor-critic]]\n\n## Reducing variance with Actor-Critic meth..."
          ],
          [
           "(Automatic) Curriculum Learning for RL\n\nWhile most of the RL methods seen in this course work well i..."
          ],
          [
           "Conclusion [[conclusion]]\n\nCongrats on finishing this chapter! There was a lot of information. And c..."
          ],
          [
           "Hands-on [[hands-on]]\n\n      <CourseFloatingBanner classNames=\"absolute z-10 right-0 top-0\"\n      no..."
          ],
          [
           "For more information about the certification process, check this section 👉 https://huggingface.co/de..."
          ],
          [
           "```\n\n```bash\nsudo apt-get update\nsudo apt-get install -y python3-opengl\napt install ffmpeg xvfb\npip3..."
          ],
          [
           "```\n\n#### Solution\n\n```python\ndef greedy_policy(Qtable, state):\n    # Exploitation: take the action ..."
          ],
          [
           "```\n\n## Evaluate our Q-Learning agent 📈\n\n- Usually, you should have a mean reward of 1.0\n- The **env..."
          ],
          [
           "```\n\nIf you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command ins..."
          ],
          [
           "```\n\n### .\n\n```python\nmodel = load_from_hub(repo_id=\"ThomasSimonini/q-Taxi-v3\", filename=\"q-learning..."
          ],
          [
           "An Introduction to Unreal Learning Agents\n\n[Learning Agents](https://dev.epicgames.com/community/lea..."
          ],
          [
           "Conclusion\n\nThat’s all for today. Congrats on finishing this unit and the tutorial!\n\nThe best way to..."
          ],
          [
           "Conclusion [[conclusion]]\n\nCongrats on finishing this bonus unit!\n\nYou can now sit and enjoy playing..."
          ],
          [
           "Type of tasks [[tasks]]\n\nA task is an **instance** of a Reinforcement Learning problem. We can have ..."
          ],
          [
           "The intuition behind PPO [[the-intuition-behind-ppo]]\n\n\nThe idea with Proximal Policy Optimization (..."
          ],
          [
           "The Bellman Equation: simplify our value estimation [[bellman-equation]]\n\nThe Bellman equation **sim..."
          ],
          [
           "Conclusion\n\nThat's all for today. Congrats on finishing this Unit and the tutorial! ⭐️\n\nNow that you..."
          ],
          [
           "Brief introduction to RL documentation\n\nIn this advanced topic, we address the question: **how shoul..."
          ],
          [
           "Conclusion [[conclusion]]\n\nCongrats on finishing this unit and the tutorial. You've just trained you..."
          ],
          [
           "Monte Carlo vs Temporal Difference Learning [[mc-vs-td]]\n\nThe last thing we need to discuss before d..."
          ],
          [
           "Conclusion [[conclusion]]\n\nCongrats on finishing this chapter! There was a lot of information. And c..."
          ],
          [
           "Glossary [[glossary]]\n\nThis is a community-created glossary. Contributions are welcomed!\n\n### Agent\n..."
          ],
          [
           "Offline vs. Online Reinforcement Learning\n\nDeep Reinforcement Learning (RL) is a framework **to buil..."
          ],
          [
           "Quiz\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lectu..."
          ],
          [
           "Hands-on: advanced Deep Reinforcement Learning. Using Sample Factory to play Doom from pixels\n\n<Cour..."
          ],
          [
           "```\n\nTo validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course..."
          ],
          [
           "```\n\n## Then we can install Sample Factory and ViZDoom\n\n- This can take 7min\n\n```bash\npip install sa..."
          ],
          [
           "```\n\n```python\nmp4 = open(\"/content/train_dir/doom_health_gathering_supreme_2222/replay.mp4\", \"rb\")...."
          ],
          [
           "Introducing the Clipped Surrogate Objective Function\n## Recap: The Policy Objective Function\n\nLet’s ..."
          ],
          [
           "Quiz\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lectu..."
          ],
          [
           "The Problem of Variance in Reinforce [[the-problem-of-variance-in-reinforce]]\n\nIn Reinforce, we want..."
          ],
          [
           "An introduction to Multi-Agents Reinforcement Learning (MARL)\n\n## From single agent to multiple agen..."
          ],
          [
           "Student Works\n\nSince the launch of the Deep Reinforcement Learning Course, **many students have crea..."
          ],
          [
           "Introduction [[introduction]]\n\nIn this bonus unit, we'll reinforce what we learned in the first unit..."
          ],
          [
           "Conclusion\n\n\n**Congrats on finishing this unit**! There was a lot of information.\nAnd congrats on fi..."
          ],
          [
           "Visualize the Clipped Surrogate Objective Function\n\nDon't worry. **It's normal if this seems complex..."
          ],
          [
           "Welcome to the 🤗 Deep Reinforcement Learning Course [[introduction]]\n\n<img src=\"https://huggingface...."
          ],
          [
           "About the team:\n\n- <a href=\"https://twitter.com/osanseviero\">Omar Sanseviero</a> is a Machine Learni..."
          ],
          [
           "Hands on\n\n\n\n      <CourseFloatingBanner classNames=\"absolute z-10 right-0 top-0\"\n      notebooks={[\n..."
          ],
          [
           "```\n\n## Check if we have a GPU\n\n- Let's check if we have a GPU\n- If it's the case you should see `de..."
          ],
          [
           "```\n\nBy using CartPole, it was easier to debug since **we know that the bug comes from our integrati..."
          ],
          [
           "```\n\n#### Solution\n\n```python\ndef reinforce(policy, optimizer, n_training_episodes, max_t, gamma, pr..."
          ],
          [
           "```\n\n```python\ndef push_to_hub(repo_id,\n                model,\n                hyperparameters,\n    ..."
          ],
          [
           "```\n\n#### Solution\n\n```python\nclass Policy(nn.Module):\n    def __init__(self, s_size, a_size, h_size..."
          ],
          [
           "Setup [[setup]]\n\nAfter all this information, it's time to get started. We're going to do two things:..."
          ],
          [
           "Second Quiz [[quiz2]]\n\nThe best way to learn and [to avoid the illusion of competence](https://www.c..."
          ],
          [
           "Two main approaches for solving RL problems [[two-methods]]\n\n<Tip>\nNow that we learned the RL framew..."
          ],
          [
           "The Exploration/Exploitation trade-off [[exp-exp-tradeoff]]\n\nFinally, before looking at the differen..."
          ],
          [
           "Generalization in Reinforcement Learning\n\nGeneralization plays a pivotal role in the realm of Reinfo..."
          ],
          [
           "Godot RL Agents\n\n[Godot RL Agents](https://github.com/edbeeching/godot_rl_agents) is an Open Source ..."
          ],
          [
           "```\n\nIn order to implement these methods, we will need to create a class that inherits from AIContro..."
          ],
          [
           "An Introduction to Unity ML-Agents [[introduction-to-ml-agents]]\n\n<img src=\"https://huggingface.co/d..."
          ],
          [
           "Introduction [[introduction]]\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/..."
          ],
          [
           "Quiz\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lectu..."
          ],
          [
           "Model Based Reinforcement Learning (MBRL)\n\nModel-based reinforcement learning only differs from its ..."
          ],
          [
           "Hands-on [[hands-on]]\n\nNow that you've learned to use Optuna, here are some ideas to apply what you'..."
          ],
          [
           "[The Hugging Face Deep Reinforcement Learning Course 🤗 (v2.0)](https://huggingface.co/deep-rl-course..."
          ],
          [
           "How do Unity ML-Agents work? [[how-mlagents-works]]\n\nBefore training our agent, we need to understan..."
          ],
          [
           "The Pyramid environment\n\nThe goal in this environment is to train our agent to **get the gold brick ..."
          ],
          [
           "How Huggy works [[how-huggy-works]]\n\nHuggy is a Deep Reinforcement Learning environment made by Hugg..."
          ],
          [
           "Interesting Environments to try\n\nHere we provide a list of interesting environments you can try to t..."
          ],
          [
           "Self-Play: a classic technique to train competitive agents in adversarial games\n\nNow that we've stud..."
          ],
          [
           "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/u..."
          ],
          [
           "Quiz [[quiz]]\n\nThe best way to learn and [to avoid the illusion of competence](https://www.coursera...."
          ],
          [
           "Deep Q-Learning [[deep-q-learning]]\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-c..."
          ],
          [
           "Apache License\n                           Version 2.0, January 2004\n                        http://w..."
          ],
          [
           "5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intent..."
          ],
          [
           "Optuna Tutorial [[optuna]]\n\nThe content below comes from [Antonin's Raffin ICRA 2022 presentations](..."
          ],
          [
           "Hands-on [[hands-on]]\n\n\n\n      <CourseFloatingBanner classNames=\"absolute z-10 right-0 top-0\"\n      ..."
          ],
          [
           "```\n\n## Train our Deep Q-Learning Agent to Play Space Invaders 👾\n\nTo train an agent with RL-Baseline..."
          ],
          [
           "```\n\n2. Let's evaluate if for 5000 timesteps\n\n```bash\npython -m rl_zoo3.enjoy --algo dqn --env BeamR..."
          ],
          [
           "Introduction to PPO with Sample-Factory\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-..."
          ],
          [
           "The Deep Q-Learning Algorithm [[deep-q-algorithm]]\n\nWe learned that Deep Q-Learning **uses a deep ne..."
          ],
          [
           "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/u..."
          ],
          [
           "A Q-Learning example [[q-learning-example]]\n\nTo better understand Q-Learning, let's take a simple ex..."
          ],
          [
           "Congratulations\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/..."
          ],
          [
           "What is Reinforcement Learning? [[what-is-reinforcement-learning]]\n\nTo understand Reinforcement Lear..."
          ],
          [
           "Introduction [[introduction]]\n\n  <img src=\"https://huggingface.co/datasets/huggingface-deep-rl-cours..."
          ],
          [
           "Mid-way Recap [[mid-way-recap]]\n\nBefore diving into Q-Learning, let's summarize what we've just lear..."
          ],
          [
           "Introduction [[introduction]]\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/..."
          ],
          [
           "RLHF\n\nReinforcement learning from human feedback (RLHF) is a **methodology for integrating human dat..."
          ]
         ],
         "hovertemplate": "source=deep-rl-class<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "deep-rl-class, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "deep-rl-class, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -3.016617,
          1.5362555,
          -3.0742848,
          0.49400523,
          1.051427,
          -4.172398,
          2.6368985,
          4.390027,
          -0.13486351,
          5.500423,
          2.2741947,
          2.1755037,
          3.1735525,
          -0.58150876,
          1.4633095,
          5.3653445,
          -2.0066555,
          2.6803963,
          -0.048808686,
          1.9471668,
          2.4874609,
          3.265189,
          -2.1500053,
          1.3299001,
          -3.6345057,
          2.4206426,
          -3.6054308,
          1.2278854,
          -3.8166323,
          0.95939606,
          -1.1486076,
          2.2777207,
          1.8492254,
          5.1449018,
          -1.7185863,
          -1.3258294,
          -0.83751893,
          -1.088211,
          2.4973505,
          -1.7835642,
          -3.2064922,
          0.23538132,
          -2.5784578,
          -2.1604612,
          4.9723773,
          4.496634,
          2.4158647,
          1.1652583,
          2.4979692,
          -0.6887416,
          1.0580018,
          1.5373759,
          0.44909275,
          -0.5334651,
          -0.30618182,
          0.74486345,
          -3.9056797,
          -3.2010496,
          1.369044,
          3.8835893,
          1.7181422,
          3.4015868,
          -1.2721814,
          -3.5253944,
          0.9109496,
          2.3669245,
          2.1775455,
          -0.14849451,
          -0.6550211,
          2.751554,
          3.0972362,
          -3.872085,
          -0.15963309,
          4.260966,
          -1.6754762,
          0.092941195,
          1.0315382,
          -2.0957742,
          0.8823248,
          -2.5181124,
          -2.1092114,
          2.1876435,
          -2.1078982,
          -2.8014693,
          -4.140814,
          -0.3728736,
          2.1272237,
          1.5322297,
          -3.1510007,
          2.4201043,
          1.373275,
          -4.0850425,
          2.2404687,
          -3.778058,
          2.9218948,
          -1.056051,
          -0.017785367,
          -2.0268939,
          1.2770052,
          2.5053105,
          1.8276644,
          1.8389033,
          3.4133124,
          1.6603484,
          3.3257415,
          -2.5593069,
          0.05735984,
          0.60540247,
          1.835574,
          0.05536377,
          4.458027,
          -2.6572614,
          -1.3445585,
          -2.3222132,
          -1.3736938,
          -3.428561,
          2.102961,
          -4.79535,
          -2.5108519,
          3.4522157,
          -2.1267593,
          1.8541164,
          0.7216386,
          2.00227,
          2.3831728,
          -3.796321,
          -1.8871619,
          2.273703,
          -2.7790673,
          -0.54864734,
          3.9506876,
          -4.4618187,
          0.9025297,
          -0.5604599,
          2.7287521,
          2.9152286,
          -2.2253067,
          -0.667588,
          4.790705,
          -3.8694272,
          4.4843254,
          -2.191727,
          4.714952,
          -0.038622316,
          4.2752132,
          3.6678185,
          3.5809364,
          1.5187918,
          4.895396,
          -2.7371087,
          0.05295852,
          -2.45413,
          3.5228322
         ],
         "xaxis": "x",
         "y": [
          0.80124426,
          2.5734777,
          3.965623,
          3.3008523,
          -1.3159082,
          0.82340115,
          1.1843387,
          1.1409414,
          -1.7024255,
          0.45049208,
          2.8896773,
          -1.2432885,
          3.0070977,
          1.4763937,
          3.4099548,
          1.3766383,
          4.8445396,
          3.354894,
          -0.6567488,
          4.265029,
          2.7636638,
          -0.96929145,
          3.8383462,
          -3.2360249,
          -0.014547371,
          -0.004418579,
          2.657819,
          -1.984276,
          -1.0467168,
          -3.4420035,
          4.687824,
          -1.5338352,
          3.4510872,
          1.5335962,
          4.3359795,
          0.3165797,
          0.94945085,
          -5.128844,
          -3.4825597,
          4.1274076,
          2.8132865,
          3.575129,
          2.1973073,
          3.9998155,
          0.9009133,
          -0.15015398,
          -2.024399,
          -3.1662154,
          2.4885232,
          -0.16743422,
          3.8759997,
          2.5065386,
          -1.7103621,
          -1.0087068,
          3.062266,
          -1.6668942,
          3.1908283,
          -1.0935535,
          3.462865,
          -1.26253,
          -1.6636913,
          0.3610757,
          -1.7885996,
          -1.4678966,
          4.5209436,
          1.7619101,
          2.7566187,
          -1.1260258,
          3.662975,
          -0.6278469,
          1.3116696,
          0.44537112,
          -1.2851948,
          0.5674964,
          1.4983288,
          -1.1181885,
          2.4368544,
          -3.3518531,
          -0.081684016,
          -4.7661366,
          -0.63767797,
          3.9178128,
          4.12876,
          1.1635652,
          -1.2579005,
          4.4422674,
          1.6604925,
          0.64358467,
          0.92491484,
          3.037587,
          3.7114782,
          2.4932833,
          3.9519424,
          -0.29123852,
          2.925255,
          2.3426518,
          -1.6139693,
          3.176586,
          1.7312665,
          -0.92611325,
          1.6634964,
          -0.35616326,
          3.025632,
          4.26079,
          1.3916624,
          3.6112225,
          4.012302,
          3.6179612,
          1.91521,
          -0.298897,
          -0.6979369,
          1.198319,
          -1.7082038,
          -1.5468453,
          -1.870507,
          1.1772636,
          -3.4854062,
          1.6307403,
          -1.0948962,
          -0.3086142,
          2.8453162,
          2.6060522,
          1.6819736,
          2.784005,
          3.450399,
          2.1365967,
          0.19465514,
          3.3389225,
          4.446334,
          3.5813932,
          -0.35928047,
          0.81769496,
          3.875852,
          -1.0152875,
          -2.4583337,
          -0.420213,
          3.3708336,
          3.1170635,
          0.65480703,
          -1.1717024,
          1.6960992,
          0.20971203,
          -0.048643477,
          4.4823284,
          1.4795407,
          -0.46695217,
          1.4427254,
          2.7343981,
          0.6645112,
          4.4117136,
          2.980352,
          -1.502054,
          -1.2152032
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "Inference pipelines with the ONNX Runtime accelerator\n\nThe [`~pipelines.pipeline`] function makes it..."
          ],
          [
           "```\n\n### Optimizing with `ORTOptimizer`\n\n```python\n>>> from transformers import AutoTokenizer\n>>> fr..."
          ],
          [
           "Quantization\n\n## AutoGPTQ Integration\n\n🤗 Optimum collaborated with [AutoGPTQ library](https://github..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### Neural Compressor\n\n| Notebook                                                                   ..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/onnxrunti..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Ve..."
          ],
          [
           "Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Register commands in the Optimum CLI from a subpackage\n\nIt is possible to register a command in the ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Quantize Seq2Seq models\n\nThe [`~optimum.onnxruntime.ORTQuantizer`] class currently doesn't s..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Stable Diffusion Text-to-Image Fine-Tuning\n\nThis example shows how to leverage ONNX Runtime Training..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "### Neural Compressor\n\n| Notebook                                                                   ..."
          ],
          [
           "Overview\n\n🤗 Optimum provides an integration with Torch FX, a library for PyTorch that allows develop..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "Accelerated inference on NVIDIA GPUs\n\nBy default, ONNX Runtime runs inference on CPU devices. Howeve..."
          ],
          [
           "```\n\nFor the time being, IOBinding is supported for task-defined ORT models, if you want us to add s..."
          ],
          [
           "```\n\nTensorRT builds its engine depending on specified input shapes. Unfortunately, in the [current ..."
          ],
          [
           "```\n\nThe model can then be used with the common 🤗 Transformers API for inference and evaluation, suc..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Optimum Inference with ONNX Runtime\n\nOptimum is a utility package for building and running inference..."
          ],
          [
           "```\n\n\n## Stable Diffusion XL\n\nBefore using `ORTStableDiffusionXLPipeline` make sure to have `diffuse..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Optimizing a model with Optimum CLI\n\nThe Optimum ONNX Runtime optimization tools can be used..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\nAt the last layer, it is important to \"un-nest\" the hidden_states so that it can be processed by..."
          ],
          [
           "Symbolic tracer\n\nIn Torch FX, the symbolic tracer feeds dummy values through the code to record the ..."
          ],
          [
           "Accelerated inference on AMD GPUs supported by ROCm\n\nBy default, ONNX Runtime runs inference on CPU ..."
          ],
          [
           "BetterTransformer benchmark\n\nPlease refer to https://medium.com/pytorch/bettertransformer-out-of-the..."
          ],
          [
           "```\n\nThe benchmark below is for a prompt length of 512, measuring only the prefill step on a single ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\nYou can leave `keep_original_model=False` in case you want to overwrite the current model with i..."
          ],
          [
           "ONNX 🤝 ONNX Runtime\n\nONNX is an open standard that defines a common set of operators and a common fi..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# How to contribute to Optimum?\n\nOptimum is an open source project, so all contributions and suggest..."
          ],
          [
           "Overview\n\n🤗 Optimum provides an integration with ONNX Runtime, a cross-platform, high performance en..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nCheck out more detailed [example scripts](https://github.com/huggingface/optimum/tree/main/exam..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n```\n# first line of code\n# second line\n# etc\n```\n````\n\nWe follow the [doctest](https://docs.pyth..."
          ],
          [
           "```\n\nOnce you've added the `doc` target to the Makefile, you can generate the\ndocumentation by runni..."
          ],
          [
           "![ONNX Runtime](https://github.com/huggingface/optimum/actions/workflows/test_onnxruntime.yml/badge...."
          ],
          [
           "```\n\nIt is possible to export 🤗 Transformers and Diffusers models to the [ONNX](https://onnx.ai/) fo..."
          ],
          [
           "Quantization\n\nQuantization is a technique to reduce the computational and memory costs of running in..."
          ],
          [
           "```\n\n<Tip>\n\nUsually `round(a/S + Z)` corresponds to the smallest representable value in the consider..."
          ],
          [
           "</Tip>\n\nThe most fundamental unit of representation for computers is the bit. Everything in computer..."
          ],
          [
           "```\n19 = 0 x 2^7 + 0 x 2^6 + 0 x 2^5 + 1 x 2^4 + 0 x 2^3 + 0 x 2^2 + 1 x 2^1 + 1 x 2^0\n```\n\n2. Signe..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nYou should see the following logs (along with potential logs from PyTorch / TensorFlow that wer..."
          ],
          [
           "```\n\nYou can then pass one of these tasks to the `--task` argument in the `optimum-cli export onnx` ..."
          ],
          [
           "```\n\nFor tasks that require only a single ONNX file (e.g. encoder-only), an exported model with cust..."
          ],
          [
           "Helpful tips for testing & debugging optimum\n\n## VSCODE\n\nIf you are using vscode you might have hard..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Exporting the model\n\nOnce you have implemented the ONNX configuration, the next step is to e..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ]
         ],
         "hovertemplate": "source=optimum<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "optimum, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "optimum, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0.9863762,
          -3.6191893,
          1.4098876,
          3.4237146,
          -3.2212534,
          -3.2587097,
          0.9150049,
          1.7035004,
          -1.7600513,
          -1.2150288,
          -3.3414898,
          1.3710718,
          -3.3165543,
          -2.8639014,
          2.1518118,
          -2.2312772,
          1.8417037,
          -2.202984,
          -3.9941928,
          0.647337,
          1.9460188,
          -2.319722,
          5.1171207,
          -2.5080793,
          1.6710085,
          1.6489881,
          2.2722132,
          2.1260445,
          -0.21732302,
          -3.0618734,
          -1.6778381,
          -1.4888107,
          -2.0977652,
          4.473452,
          -0.17646417,
          -0.14920585,
          -3.8425307,
          -0.60648,
          4.1589518,
          -3.377222,
          0.65146863,
          -4.41471,
          -4.528745,
          -3.074047,
          -2.4655218,
          -4.556617,
          -4.640603,
          -1.7780861,
          -0.33639446,
          -2.3713152,
          -1.3683337,
          0.9036407,
          -1.0697507,
          -0.45181847,
          -0.9804278,
          2.0206044,
          1.3838133,
          1.4160882,
          -3.784569,
          2.1554065,
          -3.436458,
          -3.490205,
          -1.4453942,
          1.0176023,
          2.521272,
          0.715078,
          4.6290936,
          -4.683771,
          -4.57413,
          -0.09791915,
          -2.96564,
          -2.01392,
          -2.4568865,
          -0.7631903,
          -1.3115608,
          -0.9578726,
          -1.4911429,
          2.0101726,
          -2.5617635,
          -1.5107164,
          0.6918639,
          0.01530762,
          -2.6156082,
          -1.7774874,
          -2.2735775,
          -2.3715427,
          -2.7445118,
          -1.9439728,
          -0.33516872,
          0.46003807,
          3.714076
         ],
         "xaxis": "x",
         "y": [
          -1.241557,
          2.9148602,
          0.13898233,
          1.8756655,
          -2.7577124,
          -3.5507286,
          -2.1814427,
          -3.7696712,
          4.865627,
          5.02682,
          2.1089103,
          -2.2240846,
          -2.4418004,
          4.1157956,
          2.3982265,
          -2.2468863,
          2.9412844,
          0.07097714,
          -1.229155,
          2.7461226,
          4.8248887,
          -1.7840937,
          1.4520547,
          -1.8900937,
          -5.256135,
          -2.2115352,
          -3.7964041,
          -2.0239813,
          3.363656,
          -3.460425,
          4.8677573,
          5.164601,
          -2.4762864,
          0.7979715,
          -1.6047852,
          -2.2292285,
          -2.702264,
          -1.2013518,
          -0.23304306,
          1.065171,
          2.9573438,
          2.8438566,
          1.7997396,
          -1.5705407,
          -4.074164,
          0.15679339,
          -0.7491499,
          -3.430748,
          3.3625624,
          1.1728574,
          1.1205034,
          5.1786,
          -2.1397038,
          5.0037766,
          2.524401,
          0.7758671,
          2.607111,
          -0.40939415,
          -3.4904175,
          -2.3400235,
          -1.6771457,
          -4.34046,
          -2.4705184,
          -1.5371922,
          1.6408098,
          -3.5731406,
          -1.0447671,
          0.8422451,
          -0.21796232,
          0.9323569,
          -0.31244627,
          -3.6834378,
          4.0647674,
          -3.4748116,
          -2.6865163,
          0.36901844,
          -2.4959016,
          0.9018817,
          1.719534,
          -2.0311558,
          -2.7687588,
          -2.9687202,
          -3.7663548,
          -4.01394,
          -3.5535996,
          2.7519267,
          -0.40642393,
          -2.0748076,
          -4.2862086,
          4.1497912,
          1.6761452
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "Fine-tuning for image classification using LoRA and 🤗 PEFT\n\n## Vision Transformer model from transfo..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nNote that we always omit the \"defaults to \\`None\\`\" when None is the default for any argument. ..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nLet's see how well the model performs on the validation set:\n\n```py\ncorrect = 0\ntotal = 0\nfor p..."
          ],
          [
           "Fine-tuning a multilayer perceptron using LoRA and 🤗 PEFT\n\n[![Open In Colab](https://colab.research...."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Using PEFT with timm\n\n`peft` allows us to train any model with LoRA as long as the layer type is sup..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\nimport os\n\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    default_data_coll..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n## Train\n\nNow that the dataset is ready, you can turn your attention to the model. Start by loa..."
          ],
          [
           "```\n\n## Share model\n\nOnce you're happy with your results, you can upload your model to the Hub with ..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\n## Load a base model \n\nBefore loading a base model, let's define a helper function to check the..."
          ],
          [
           "```\n\nGet an image:\n\n```python\nimport requests\n\nurl = \"https://huggingface.co/datasets/huggingface/do..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Training PEFT models with new tokens being added to the embedding layers and tokenizer\n\nIn this exam..."
          ],
          [
           "```\n\n# Check the model output on a sample from evaluation dataset\n\n\n```python\nimport random\n\ni = ran..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nNow you can use the function above to create a Stable Diffusion pipeline using the LoRA weights..."
          ],
          [
           "``python\nfrom transformers import AutoModelForSeq2SeqLM\nfrom peft import get_peft_config, get_peft_m..."
          ],
          [
           "``python\nfrom transformers import AutoModelForSeq2SeqLM\nfrom peft import get_peft_config, get_peft_m..."
          ],
          [
           "``python\nfrom transformers import AutoModelForCausalLM\nfrom peft import get_peft_config, get_peft_mo..."
          ],
          [
           "```\n\nYou can push model to hub or save model locally. \n\n- Option1: Pushing the model to Hugging Face..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "LoftQ: LoRA-fine-tuning-aware Quantization\n\n## Introduction\n\nLoftQ finds quantized LoRA initializati..."
          ],
          [
           "Finetuning Whisper-large-V2 on Colab using PEFT-Lora + BNB INT8 training\n\nIn this Colab, we present ..."
          ],
          [
           "```\n\n### Load a Pre-Trained Checkpoint\n\nNow let's load the pre-trained Whisper `small` checkpoint. A..."
          ],
          [
           "```\n\n\n```python\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimp..."
          ],
          [
           "``python\nimport argparse\nimport gc\nimport hashlib\nimport itertools\nimport logging\nimport math\nimport..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nThat is all! The rest of the script handles the training loop, evaluation, and even pushes it t..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\nfrom transformers import AutoModelForSeq2SeqLM\nimport peft\nfrom peft import get_peft_config..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "``python\nfrom datasets import load_dataset\nfrom transformers import set_seed, AutoModelForSeq2SeqLM,..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\n!pip install -q git+https://github.com/huggingface/transformers.git\n!pip install -q git+htt..."
          ],
          [
           "``python\nfrom transformers import AutoModelForSeq2SeqLM\nfrom peft import PeftModel, PeftConfig\nimpor..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "Fine-tune FLAN-T5 using `bitsandbytes`, `peft` & `transformers` 🤗 \n\nIn this notebook we will see how..."
          ],
          [
           "``python\nimport argparse\nimport os\n\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nThe `get_cosine_embeddings` function computes the cosine similarity and the `get_loss` function..."
          ],
          [
           "``python\nimport argparse\nimport os\n\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n## Share model\n\nYou can store and share your model on the Hub if you'd like. Log in to your Hug..."
          ],
          [
           "Dreambooth with OFT\nThis Notebook assumes that you already ran the train_dreambooth.py script to cre..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nCreate a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) ..."
          ],
          [
           "``python\nfrom transformers import AutoModelForCausalLM\nfrom peft import get_peft_config, get_peft_mo..."
          ],
          [
           "```\n\nYou can push model to hub or save model locally. \n\n- Option1: Pushing the model to Hugging Face..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nBefore creating a `PeftModel`, you can check the number of trainable parameters in the original..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "## Llama-Adapter\n\n[Llama-Adapter](https://hf.co/papers/2303.16199) is a method for adapting Llama in..."
          ],
          [
           "``python\nimport argparse\nimport os\n\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\nimport argparse\nimport os\n\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nDefine the [`LoraConfig`] with:\n\n- `task_type`, token classification (`TaskType.TOKEN_CLS`)\n- `..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\nimport os\n\nimport torch\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, defa..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "``python\nimport argparse\nimport json\nimport logging\nimport math\nimport os\nimport random\nfrom pathlib..."
          ],
          [
           "``python\nfrom transformers import AutoModelForCausalLM\nfrom peft import PeftModel, PeftConfig\nimport..."
          ],
          [
           "Fine-tuning for semantic segmentation using LoRA and 🤗 PEFT\n\n[![Open In Colab](https://colab.researc..."
          ],
          [
           "Using PEFT with custom models\n\n`peft` allows us to fine-tune models efficiently with LoRA. In this s..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "```\n\nThen we only need to create the PEFT model by passing our base model and the config to `get_pef..."
          ],
          [
           "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\nTry out the 🤗 Gradio Space which should run seamlessly on a T4 instance:\n[smangrul/peft-lora-sd..."
          ],
          [
           "```\n\n### Example of PEFT model inference using 🤗 Accelerate's Big Model Inferencing capabilities\nAn ..."
          ],
          [
           "```\n\nLearn more about the [low level API in the docs](https://huggingface.co/docs/peft/developer_gui..."
          ],
          [
           "``python\nimport argparse\nimport os\n\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data..."
          ]
         ],
         "hovertemplate": "source=peft<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "peft, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "peft, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -1.4022698,
          3.1738298,
          3.6741793,
          0.9059616,
          -2.647731,
          -0.6480189,
          -2.5865695,
          0.01298893,
          -1.6463449,
          -2.4458942,
          -3.656986,
          -0.16798656,
          -3.1494124,
          3.53899,
          -3.698404,
          1.2807645,
          1.5917091,
          -3.9359808,
          2.9836957,
          -2.712832,
          -1.1481986,
          -2.554706,
          -3.0465465,
          -1.6166562,
          -3.408357,
          -1.2620875,
          -1.4774361,
          -2.642544,
          -4.734244,
          -2.2338028,
          3.146556,
          -2.591241,
          3.5426078,
          -2.2548244,
          0.1213214,
          -2.7050822,
          0.13225693,
          -1.4625324,
          0.071695685,
          4.856364,
          4.3522286,
          0.88496506,
          0.9436628,
          -3.428055,
          -0.9427177,
          -3.1002042,
          2.5880535,
          1.2765538,
          1.2403728,
          0.11917813,
          -3.9104419,
          0.783617,
          -2.9105115,
          0.3127335,
          -0.86695504,
          -3.713953,
          1.4493407,
          -3.1836958,
          -0.2199228,
          2.0595596,
          1.3011754,
          2.346217,
          -2.9675066,
          -4.014127,
          3.5791576,
          1.6316698,
          -2.9102004,
          -2.837297,
          2.7546108,
          -0.47357267,
          0.17823872,
          4.5548286,
          0.15444715,
          0.9103106,
          2.9500537,
          -2.5162878,
          2.1510348,
          -0.45151284,
          2.4608407,
          -1.9367372,
          -4.417231,
          2.5477898,
          -3.9457157,
          -2.9627542,
          2.4850771,
          2.5756938,
          1.6059735,
          0.8144513,
          -1.4063189,
          1.184584,
          -3.2951853,
          3.335535,
          4.2405496,
          -3.6164503,
          0.4903028,
          1.514737
         ],
         "xaxis": "x",
         "y": [
          2.0940027,
          1.8948663,
          1.3899494,
          4.7447996,
          -0.515139,
          -2.0664837,
          -3.29457,
          -4.3550506,
          3.6200802,
          -0.6065016,
          1.575176,
          -2.0475886,
          2.5627117,
          -1.9750228,
          0.2766814,
          -4.0322323,
          -2.0539117,
          1.6568553,
          0.29634288,
          -0.7684572,
          2.199112,
          1.1855063,
          -4.363912,
          -4.557954,
          3.5689409,
          -2.4434927,
          -0.046206363,
          -2.7964478,
          0.9845746,
          -3.8532789,
          -0.51783866,
          -5.182872,
          2.0377405,
          -3.7425096,
          -3.4749684,
          0.28681841,
          -3.2314432,
          -4.4643755,
          -3.3104014,
          -0.7414545,
          0.21001586,
          4.1551366,
          -0.4240441,
          2.5383053,
          -5.2674155,
          2.7440147,
          2.8641884,
          -2.200494,
          -4.4858413,
          -1.5905327,
          3.0384398,
          -5.532135,
          -1.1270767,
          3.79952,
          -4.805675,
          0.23103738,
          1.8902317,
          -2.7526958,
          3.121433,
          1.6731478,
          -2.7880416,
          0.10226022,
          -3.82524,
          2.9962401,
          -1.5898426,
          -3.6579697,
          -4.031997,
          -5.1362658,
          1.1786889,
          -4.345582,
          -3.4228647,
          0.4619804,
          -0.010974438,
          3.771556,
          0.514118,
          3.3185403,
          -1.0808605,
          4.691891,
          -2.2085867,
          -1.8256471,
          0.24211873,
          3.8921053,
          2.37215,
          2.1110175,
          -1.1736089,
          -2.5220625,
          0.21804926,
          -0.54222584,
          4.0078044,
          -1.3139207,
          -1.7255023,
          0.49136224,
          0.63782346,
          0.088856444,
          -4.3114276,
          -0.23953602
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "p align=\"center\">\n  <br/>\n    <img alt=\"huggingface_hub library logo\" src=\"https://huggingface.co/da..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nOn the other hand, `ignore_patterns` can exclude certain files from being downloaded. The\nfollo..."
          ],
          [
           "--\n# For reference on dataset card metadata, see the spec: https://github.com/huggingface/hub-docs/b..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n### Upload a folder by chunks\n\n[`upload_folder`] makes it easy to upload an entire folder to th..."
          ],
          [
           "```\n\nAnd that's it! User input/outputs and feedback will be available as a dataset on the Hub. By us..."
          ],
          [
           "```\n\n2. Pass your operations to [`create_commit`]:\n\n```py\n>>> api.create_commit(\n...     repo_id=\"ly..."
          ],
          [
           "```\n\nHere is another example of how to use the `commit` context manager to save and upload a file to..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n\n   Compared to `make style`, `make quality` will never update your code. In addition to the pre..."
          ],
          [
           "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pled..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nThe command will always print on the last line the path to the file on your local machine.\n\n###..."
          ],
          [
           "```\n\n### Upload to a dataset or Space\n\nTo upload to a dataset or a Space, use the `--repo-type` opti..."
          ],
          [
           "Running Tests\n\nTo run the test suite, please perform the following from the root directory of this r..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nIf an item already exists in a collection (same `item_id`/`item_type` pair), an HTTP 409 error ..."
          ],
          [
           "--\nlanguage:\n- en\nlicense: mit\nlibrary_name: pytorch-lightning\ntags:\n- pytorch\n- image-classificatio..."
          ],
          [
           "--\n[]\n---\n\n# invalid-card-data\n\nThis card should fail when trying to load it in because the card dat..."
          ],
          [
           "his document covers all steps that need to be done in order to do a release of the `huggingface_hub`..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nYou can also delete your storage, losing all the data permanently.\n```py\n>>> api.delete_space_s..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "Inference Endpoints\n\nInference Endpoints provides a secure production solution to easily deploy mode..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "p align=\"center\">\n  <br/>\n    <img alt=\"huggingface_hub library logo\" src=\"https://huggingface.co/da..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "--\n# For reference on model card metadata, see the spec: https://github.com/huggingface/hub-docs/blo..."
          ],
          [
           "MyCoolModel\n\nIn this example, we don't have any metadata at the top of the file. In cases like these..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nWhich will create two endpoints:\n\n```text\n(...)\nWebhooks are correctly setup and ready to use:\n..."
          ],
          [
           "!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n    Args:\n        x (`str`, *optional*):\n            This argument controls ...\n        a (`floa..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n### Rename your repository\n\nYou can rename your repository on the Hub using [`move_repo`]. Usin..."
          ],
          [
           "p align=\"center\">\n  <br/>\n    <img alt=\"huggingface_hub library logo\" src=\"https://huggingface.co/da..."
          ],
          [
           "p align=\"center\">\n  <br/>\n    <img alt=\"huggingface_hub library logo\" src=\"https://huggingface.co/da..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "Contrib test suite\n\nThe contrib folder contains simple end-to-end scripts to test integration of `hu..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "--\nlanguage: en\nlicense: mit\nlibrary_name: timm\ntags:\n- pytorch\n- image-classification\ndatasets:\n- b..."
          ],
          [
           "p align=\"center\">\n  <br/>\n    <img alt=\"huggingface_hub library logo\" src=\"https://huggingface.co/da..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "## Translating the `huggingface_hub` documentation into your language\n\nAs part of our mission to dem..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n[[autodoc]] huggingface_hub.utils.hf_raise_for_status\n\n### HTTP errors\n\nHere is a list of HTTP ..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "Hugging Face Hub Client library\n\n## Download files from the Hub\n\nThe `hf_hub_download()` function is..."
          ],
          [
           "```\n\nThe `clone_from` method can also take any Hugging Face model ID as input, and\nwill clone that r..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nThis is of course only an example. If you are interested in more complex manipulations (delete ..."
          ],
          [
           "```\n\nAnd that's it! Your library now enables users to upload and download files to and from the Hub...."
          ],
          [
           "Inference Endpoints\n\nInference Endpoints provides a secure production solution to easily deploy any ..."
          ],
          [
           "```\n\nIf `timeout` is set and the Inference Endpoint takes too much time to load, a [`InferenceEndpoi..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "--\nlanguage: en\nlicense: mit\nlibrary_name: timm\ntags:\n- pytorch\n- image-classification\ndatasets:\n- b..."
          ],
          [
           "--\nlicense: mit\nlanguage: eo\nthumbnail: https://huggingface.co/blog/assets/01_how-to-train/EsperBERT..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\nWith these two lines of code you will update the metadata to set a new `pipeline_tag`.\n\nBy defa..."
          ],
          [
           "--\nlanguage:\n- en\nlicense:\n- bsd-3-clause\nannotations_creators:\n- crowdsourced\n- expert-generated\nla..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "### HF_HUB_ENABLE_HF_TRANSFER\n\nSet to `True` for faster uploads and downloads from the Hub using `hf..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n### Limitations\n\nIn order to have an efficient cache-system, `huggingface-hub` uses symlinks. H..."
          ],
          [
           "```\n\nTo get a more detailed report, use the `--verbose` option. For each repo, you get a\nlist of all..."
          ],
          [
           "```\n\n## Clean your cache\n\nScanning your cache is interesting but what you really want to do next is ..."
          ],
          [
           "--\n{{card_data}}\n---\n\n# {{ model_name | default(\"MyModelName\", true)}}\n\n{{ some_data }}..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "```\n\n### Authentication\n\nCalls made with the [`InferenceClient`] can be authenticated using a [User ..."
          ],
          [
           "```\n\n### Binary inputs\n\nSome tasks require binary inputs, for example, when dealing with images or a..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ],
          [
           "--\n{card_data}\n---\n\n# {{ pretty_name | default(\"Dataset Name\", true)}}\n\n{{ some_data }}..."
          ],
          [
           "!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to..."
          ]
         ],
         "hovertemplate": "source=huggingface_hub<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "huggingface_hub, circle",
         "marker": {
          "color": "#19d3f3",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "huggingface_hub, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          3.5199625,
          0.3679079,
          -3.0479596,
          -1.60217,
          -1.3680891,
          1.2393651,
          -3.3072572,
          -2.6785107,
          -1.210686,
          1.9013544,
          -2.9207034,
          2.865479,
          -3.0486891,
          4.275018,
          -3.843065,
          1.8224114,
          -1.6257524,
          -3.9993687,
          0.13439639,
          2.1420743,
          -2.0068223,
          -2.9786923,
          -1.6089034,
          -1.8941014,
          1.6304793,
          0.25771132,
          -1.828979,
          2.5873582,
          2.859917,
          -3.2479172,
          0.8236838,
          -1.7062415,
          -0.0048434255,
          -3.2337883,
          2.0341697,
          -4.278493,
          3.6675122,
          1.5290412,
          0.8533137,
          -0.21331279,
          -3.7634053,
          -1.1752614,
          -4.2204504,
          0.69709045,
          -1.7976295,
          -2.2022166,
          2.451342,
          0.49407873,
          -0.37796754,
          -1.3590811,
          -2.7175333,
          -3.4967127,
          -1.6523805,
          0.6594608,
          -0.058233984,
          3.7779534,
          -2.3096104,
          -3.7685764,
          -1.1376828,
          2.8835478,
          1.0890619,
          -3.008633,
          -3.0536838,
          -2.0673394,
          -0.48952752,
          -0.7644383,
          -1.3557719,
          -0.22814289,
          -2.913417,
          1.3521408,
          -0.054752562,
          0.716446,
          -2.0089376,
          1.1666833,
          -2.711723,
          -0.96572745,
          1.4381447,
          -0.7777096,
          -2.118689,
          4.0545244,
          -3.3549595,
          0.87416744,
          5.4517407,
          -2.685131,
          -1.3109969,
          -1.062519,
          -4.3671155,
          -3.7530186,
          1.3026364,
          2.571052,
          5.9795914,
          -4.074261
         ],
         "xaxis": "x",
         "y": [
          -3.383516,
          -1.6022935,
          -0.18061137,
          -1.6482025,
          3.3467102,
          -1.1153754,
          0.97492856,
          -0.04912113,
          -4.9560776,
          -0.9505197,
          -2.0866306,
          2.590854,
          -2.1584768,
          -0.8274952,
          1.5961021,
          4.1582355,
          -3.4249094,
          1.9079574,
          0.39490816,
          -4.328097,
          -3.5833259,
          -3.196316,
          -0.054451507,
          4.5029407,
          0.49490234,
          -0.6825452,
          2.8470144,
          -3.7390928,
          0.4399628,
          -4.607089,
          -2.9424376,
          -0.2819791,
          1.5461507,
          1.8514669,
          -2.608892,
          2.4102733,
          2.0304332,
          -3.578848,
          -3.3707788,
          1.1240412,
          0.4470261,
          -3.067161,
          2.326927,
          -4.2087216,
          -4.5782533,
          -5.566737,
          -3.8393426,
          1.3626001,
          2.5065749,
          -6.094845,
          -5.018528,
          2.0126605,
          -3.6148663,
          -2.7835948,
          -5.397184,
          -2.9571183,
          -0.28737366,
          1.0028347,
          -2.0837207,
          -1.6018103,
          -1.9034578,
          -0.7291447,
          2.6324034,
          -4.6076384,
          -3.5281808,
          -4.0357103,
          -4.2993107,
          2.2784882,
          0.22308554,
          -3.8997953,
          -5.313281,
          2.7153502,
          -3.8908958,
          2.386211,
          -2.2966738,
          -5.7717633,
          -0.984393,
          -0.18725808,
          -0.05380129,
          2.28167,
          0.94904894,
          2.6074011,
          1.120177,
          -0.5230441,
          -5.6954823,
          1.1196287,
          0.19276994,
          2.6495428,
          -4.7722907,
          -4.29475,
          0.8866215,
          -2.0577533
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "The tokenization pipeline\n\nWhen calling `Tokenizer.encode` or\n`Tokenizer.encode_batch`, the input\nte..."
          ],
          [
           "As we saw in the `quicktour`, you can\ncustomize the pre-tokenizer of a `Tokenizer` by just changing ..."
          ],
          [
           "## Decoding\n\nOn top of encoding the input texts, a `Tokenizer` also has an API for decoding, that is..."
          ],
          [
           "Quicktour\n\nLet's have a quick look at the 🤗 Tokenizers library features. The\nlibrary provides an imp..."
          ],
          [
           "```\n\n### Training the tokenizer\n\nIn this tour, we will build and train a Byte-Pair Encoding (BPE)\nto..."
          ],
          [
           "This applied the full pipeline of the tokenizer on the text, returning\nan `Encoding` object. To lear..."
          ],
          [
           "To check the results on a pair of sentences, we just pass the two\nsentences to `Tokenizer.encode`:\n\n..."
          ],
          [
           "```\n\n### Importing a pretrained tokenizer from legacy vocabulary files\n\nYou can also import a pretra..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/landing/assets/tokenizers/tokenizers..."
          ],
          [
           "`tokenizers-linux-arm64-musl`\n\nThis is the **aarch64-unknown-linux-musl** binary for `tokenizers`..."
          ],
          [
           "div align=\"center\">\n\n  <h1><code>wasm-pack-template</code></h1>\n\n  <strong>A template for kick start..."
          ],
          [
           "Post-processors\n\n<tokenizerslangcontent>\n<python>\n## BertProcessing\n\n[[autodoc]] tokenizers.processo..."
          ],
          [
           "Training from memory\n\nIn the [Quicktour](quicktour), we saw how to build and train a\ntokenizer using..."
          ],
          [
           "Models\n\n<tokenizerslangcontent>\n<python>\n## BPE\n\n[[autodoc]] tokenizers.models.BPE\n\n## Model\n\n[[auto..."
          ],
          [
           "Added Tokens\n\n<tokenizerslangcontent>\n<python>\n## AddedToken\n\n[[autodoc]] tokenizers.AddedToken\n    ..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/landing/assets/tokenizers/tokenizers..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/landing/assets/tokenizers/tokenizers..."
          ],
          [
           "`tokenizers-win32-x64-msvc`\n\nThis is the **x86_64-pc-windows-msvc** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-freebsd-x64`\n\nThis is the **x86_64-unknown-freebsd** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-win32-ia32-msvc`\n\nThis is the **i686-pc-windows-msvc** binary for `tokenizers`..."
          ],
          [
           "Visualizer\n\n<tokenizerslangcontent>\n<python>\n## Annotation\n\n[[autodoc]] tokenizers.tools.Annotation\n..."
          ],
          [
           "Components\n\nWhen building a Tokenizer, you can attach various types of components to\nthis Tokenizer ..."
          ],
          [
           "## Pre-tokenizers\n\nThe `PreTokenizer` takes care of splitting the input according to a set\nof rules...."
          ],
          [
           "## Models\n\nModels are the core algorithms used to actually tokenize, and therefore,\nthey are the onl..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n# Tokenizers\n\nFast State-of-the-art tokenizers, optimized for ..."
          ],
          [
           "Decoders\n\n<tokenizerslangcontent>\n<python>\n## BPEDecoder\n\n[[autodoc]] tokenizers.decoders.BPEDecoder..."
          ],
          [
           "`tokenizers-darwin-arm64`\n\nThis is the **aarch64-apple-darwin** binary for `tokenizers`..."
          ],
          [
           "Input Sequences\n\n<tokenizerslangcontent>\n<python>\nThese types represent all the different kinds of s..."
          ],
          [
           "Encoding\n\n<tokenizerslangcontent>\n<python>\n## Encoding\n\n[[autodoc]] tokenizers.Encoding\n    - all\n  ..."
          ],
          [
           "Pre-tokenizers\n\n<tokenizerslangcontent>\n<python>\n## BertPreTokenizer\n\n[[autodoc]] tokenizers.pre_tok..."
          ],
          [
           "Normalizers\n\n<tokenizerslangcontent>\n<python>\n## BertNormalizer\n\n[[autodoc]] tokenizers.normalizers...."
          ],
          [
           "Trainers\n\n<tokenizerslangcontent>\n<python>\n## BpeTrainer\n\n[[autodoc]] tokenizers.trainers.BpeTrainer..."
          ],
          [
           "p align=\"center\">\n  <br>\n  <img src=\"https://huggingface.co/landing/assets/tokenizers/tokenizers-log..."
          ],
          [
           "# Requirements\n\nIn order to generate the documentation, it is necessary to have a Python environment..."
          ],
          [
           "`tokenizers-linux-x64-gnu`\n\nThis is the **x86_64-unknown-linux-gnu** binary for `tokenizers`..."
          ],
          [
           "Changelog\nAll notable changes to this project will be documented in this file.\n\nThe format is based ..."
          ],
          [
           "### How to migrate\n- Add the `ByteLevel` `PostProcessor` to your byte-level BPE tokenizers if releva..."
          ],
          [
           "`tokenizers-win32-arm64-msvc`\n\nThis is the **aarch64-pc-windows-msvc** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-android-arm-eabi`\n\nThis is the **armv7-linux-androideabi** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-linux-arm-gnueabihf`\n\nThis is the **armv7-unknown-linux-gnueabihf** binary for `tokenize..."
          ],
          [
           "`tokenizers-linux-arm64-gnu`\n\nThis is the **aarch64-unknown-linux-gnu** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-linux-x64-musl`\n\nThis is the **x86_64-unknown-linux-musl** binary for `tokenizers`..."
          ],
          [
           "`tokenizers-android-arm64`\n\nThis is the **aarch64-linux-android** binary for `tokenizers`..."
          ],
          [
           "Changelog\nAll notable changes to this project will be documented in this file.\n\nThe format is based ..."
          ],
          [
           "### Fixed\n- [#286]: Fix various crash when training a BPE model\n- [#309]: Fixed a few bugs related t..."
          ],
          [
           "```\noutput = tokenizer.encode(...)\nprint(output.original_str.offsets(output.offsets[3]))\n```\n- [#99]..."
          ],
          [
           "div align=\"center\">\n\n  <h1><code>create-wasm-app</code></h1>\n\n  <strong>An <code>npm init</code> tem..."
          ],
          [
           "Encode Inputs\n\n<tokenizerslangcontent>\n<python>\nThese types represent all the different kinds of inp..."
          ],
          [
           "Tokenizer\n\n<tokenizerslangcontent>\n<python>\n## Tokenizer\n\n[[autodoc]] tokenizers.Tokenizer\n    - all..."
          ],
          [
           "Installation\n\n<tokenizerslangcontent>\n<python>\n🤗 Tokenizers is tested on Python 3.5+.\n\nYou should in..."
          ],
          [
           "`tokenizers-darwin-x64`\n\nThis is the **x86_64-apple-darwin** binary for `tokenizers`..."
          ],
          [
           "# How to release\n\n# Before the release\n\nSimple checklist on how to make releases for `tokenizers`.\n\n..."
          ]
         ],
         "hovertemplate": "source=tokenizers<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "tokenizers, circle",
         "marker": {
          "color": "#FF6692",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "tokenizers, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -2.3951337,
          -1.9711928,
          -0.9027749,
          5.756737,
          -0.19508825,
          -1.3619735,
          0.45322093,
          -0.7860106,
          -4.211228,
          1.4311204,
          -3.8459885,
          -2.2631454,
          1.7449255,
          -0.6365239,
          -2.256573,
          0.97163177,
          3.997662,
          1.5797192,
          1.238867,
          0.90826744,
          -2.3650823,
          -2.9933531,
          -2.665398,
          -1.942563,
          3.4511278,
          1.905879,
          1.5731759,
          -1.5185769,
          -1.7543058,
          0.43418717,
          -0.43314794,
          -0.2885191,
          -1.1435859,
          -1.3137314,
          0.60931146,
          -0.5525474,
          -0.7673741,
          1.4005111,
          1.7483801,
          3.8070614,
          4.344859,
          1.4863733,
          1.4707303,
          -1.8895586,
          -0.1461033,
          3.250455,
          -0.33505508,
          -1.6871983,
          -1.4701251,
          -0.97832423,
          2.6275747,
          3.3676267
         ],
         "xaxis": "x",
         "y": [
          -4.333265,
          -4.246191,
          -5.0829144,
          1.5905504,
          -3.3644903,
          -2.001273,
          -4.6061287,
          -5.244314,
          0.15994655,
          -5.7199774,
          1.5620803,
          -5.718119,
          -0.9527299,
          -3.3652117,
          -4.5723395,
          -1.8114768,
          -0.117147595,
          -5.5720487,
          -5.507062,
          -5.715252,
          -0.80984205,
          -4.0335746,
          -3.232598,
          4.177358,
          2.2754216,
          -3.5628905,
          -5.2702446,
          -5.0761566,
          -5.4058404,
          -3.3318737,
          -5.053113,
          -4.354401,
          0.42779595,
          -6.2140617,
          -4.319985,
          0.4565968,
          0.073542036,
          -5.6138306,
          -5.5343227,
          2.8961241,
          1.7277755,
          -5.671157,
          -5.5003886,
          -2.7849598,
          -3.0294662,
          -3.4719694,
          -4.6032195,
          -3.9369783,
          -3.16509,
          -5.5489874,
          -3.7909348,
          0.79996896
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "How to contribute to simulate?\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20C..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Simulate with Godot\n\n### Install in Godot 4\nThis integration has been developed for Godot 4.x. You..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "p align=\"center\">\n    <br>\n    <img src=\"docs/source/assets/simulate_library.png\" width=\"400\"/>\n    ..."
          ],
          [
           "```\n\n### Editing and moving objects\n\nObjects can be easily translated, rotated, scaled\n\nHere are a c..."
          ],
          [
           "# Unity Integration\n\n### Install with the Unity editor\nCurrently we use Unity version `2021.3.2f1` a..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, V..."
          ],
          [
           "```\n    Args:\n        n_layers (`int`): The number of layers of the model.\n```\n\nIf the description i..."
          ],
          [
           "Security Policy\n\n## Supported Versions\n<!--\nUse this section to tell people about which versions of ..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "his package provides core backend functionality for the Hugging Face Simulate project: (https://gith..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Blender Integration\n\n### Install addon in Blender\nThis integration has been developed for Blender ..."
          ],
          [
           "Tests examples taken from the original great gltflib\n\nFind the great gltflib by Lukas Shawford here:..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "# Examples for Simulate\n\nThe examples are organized by level of complexity or application. \nCurrentl..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ],
          [
           "!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Ver..."
          ]
         ],
         "hovertemplate": "source=simulate<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "simulate, circle",
         "marker": {
          "color": "#B6E880",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "simulate, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          4.2099123,
          -1.9411553,
          3.5436063,
          4.173699,
          0.9613538,
          -3.0146613,
          3.7381473,
          0.59974027,
          -1.392762,
          -2.857508,
          -1.1039478,
          -2.8862207,
          -0.8904181,
          -2.6932418,
          -1.0340457,
          -2.2619724,
          4.703577,
          -0.6691697,
          -0.40885502,
          -0.10439303,
          1.0149854,
          -1.9647293,
          1.0587814,
          1.5451586,
          -2.5780873,
          -2.5705757,
          -0.762785,
          3.053637,
          4.1590495,
          -0.6770138,
          -1.6165823,
          1.8750478,
          -1.6568513,
          3.760066,
          2.9982464,
          0.6192604,
          -1.2966044
         ],
         "xaxis": "x",
         "y": [
          1.3683491,
          3.9119904,
          2.2098556,
          2.5951738,
          3.8005106,
          -2.852231,
          1.8709335,
          -3.3807955,
          -0.74634975,
          -0.7301517,
          -4.496643,
          -3.23411,
          3.9481118,
          0.4250713,
          2.1568434,
          3.2224443,
          0.5279883,
          4.0160418,
          4.920849,
          -3.1983745,
          0.128284,
          0.20021735,
          1.0160403,
          3.648609,
          2.4889116,
          1.5302963,
          -6.124434,
          2.4630713,
          1.9317448,
          0.8691938,
          -2.2775078,
          4.5479074,
          2.7618248,
          -2.3013518,
          0.9277692,
          4.3276024,
          2.1495109
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "# How to release\n\n# Before the release\n\nSimple checklist on how to make releases for `safetensors`.\n..."
          ],
          [
           "Flax API\n\n[[autodoc]] safetensors.flax.load_file\n[[autodoc]] safetensors.flax.load\n[[autodoc]] safet..."
          ],
          [
           "Convert weights to safetensors\n\nPyTorch model weights are commonly saved and stored as `.bin` files ..."
          ],
          [
           "Numpy API\n\n[[autodoc]] safetensors.numpy.load_file\n[[autodoc]] safetensors.numpy.load\n[[autodoc]] sa..."
          ],
          [
           "Speed Comparison\n\n<a href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/..."
          ],
          [
           "# Installation\n\n```\npip install safetensors\n```\n\n\n## Usage\n\n### Numpy\n\n```python\nfrom safetensors.nu..."
          ],
          [
           "PaddlePaddle API\n\n[[autodoc]] safetensors.paddle.load_file\n[[autodoc]] safetensors.paddle.load\n[[aut..."
          ],
          [
           "he purpose of this directory is to showcase various attacks (and creating your own).\n\n\n# Torch Arbit..."
          ],
          [
           "p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://huggi..."
          ],
          [
           "```\n\n[Python documentation](https://huggingface.co/docs/safetensors/index)\n\n\n### Format\n\n- 8 bytes: ..."
          ],
          [
           "Metadata Parsing\n\nGiven the simplicity of the format, it's very simple and efficient to fetch and pa..."
          ],
          [
           "Torch API\n\n[[autodoc]] safetensors.torch.load_file\n[[autodoc]] safetensors.torch.load\n[[autodoc]] sa..."
          ],
          [
           "Tensorflow API\n\n[[autodoc]] safetensors.tensorflow.load_file\n[[autodoc]] safetensors.tensorflow.load..."
          ],
          [
           "!-- DISABLE-FRONTMATTER-SECTIONS -->\n\n<div class=\"flex justify-center\">\n    <img class=\"block dark:h..."
          ],
          [
           "Torch shared tensors\n\n\n## TL;DR\n\nUsing specific functions, which should work in most cases for you.\n..."
          ],
          [
           "p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://huggi..."
          ],
          [
           "```\n\n[Python documentation](https://huggingface.co/docs/safetensors/index)\n\n\n### Format\n\n- 8 bytes: ..."
          ]
         ],
         "hovertemplate": "source=safetensors<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "safetensors, circle",
         "marker": {
          "color": "#FF97FF",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "safetensors, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0.4056919,
          1.8296807,
          2.0426245,
          -2.4724503,
          2.217734,
          0.0054198643,
          -0.17747396,
          2.1309702,
          -3.2477164,
          -3.5891333,
          -2.7932165,
          -4.4668937,
          -0.89198273,
          3.523426,
          -3.278005,
          -3.1413317,
          -3.6039898
         ],
         "xaxis": "x",
         "y": [
          -2.4803078,
          -4.5532303,
          2.4295788,
          4.6936846,
          -3.574898,
          -4.911917,
          4.4085946,
          1.8700035,
          -3.3712978,
          -0.71632636,
          -3.6253526,
          1.9178855,
          -3.4900122,
          -0.8127404,
          0.31158134,
          -3.3711226,
          -0.6183817
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "How to create a pipeline object?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0.04692421
         ],
         "xaxis": "x",
         "y": [
          0.67820305
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[i, 0],\n",
    "            \"y\": documents_projected[i, 1],\n",
    "            \"source\": docs_processed[i].metadata[\"source\"].split(\"/\")[1],\n",
    "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for i in range(len(docs_processed))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting retrieval for user_query='How to create a pipeline object?'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2b3dd3181d45628e72de7a2febe9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================Top document==================================\n",
      "Gradio Demo: filter_records\n",
      "\n",
      "\n",
      "```\n",
      "!pip install -q gradio \n",
      "```\n",
      "\n",
      "\n",
      "```\n",
      "import gradio as gr\n",
      "\n",
      "\n",
      "def filter_records(records, gender):\n",
      "    return records[records[\"gender\"] == gender]\n",
      "\n",
      "\n",
      "demo = gr.Interface(\n",
      "    filter_records,\n",
      "    [\n",
      "        gr.Dataframe(\n",
      "            headers=[\"name\", \"age\", \"gender\"],\n",
      "            datatype=[\"str\", \"number\", \"str\"],\n",
      "            row_count=5,\n",
      "            col_count=(3, \"fixed\"),\n",
      "        ),\n",
      "        gr.Dropdown([\"M\", \"F\", \"O\"]),\n",
      "    ],\n",
      "    \"dataframe\",\n",
      "    description=\"Enter gender as 'M', 'F', or 'O' for other.\",\n",
      ")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    demo.launch()\n",
      "\n",
      "```\n",
      "==================================Metadata==================================\n",
      "{'source': 'gradio-app/gradio/blob/main/demo/filter_records/run.ipynb', 'start_index': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(\"==================================Metadata==================================\")\n",
    "print(retrieved_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting retrieval for user_query='Access HF Hub?'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9959b19c6c3a4ef498e46b4accdfdbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================Top document==================================\n",
      "Security Policy\n",
      "\n",
      "## Reporting a Vulnerability\n",
      "\n",
      "If you discover a security vulnerability, we would be very grateful if you could email us at team@gradio.app. This is the preferred approach instead of opening a public issue. We take all vulnerability reports seriously, and will work to patch the vulnerability immediately. Whenever possible, we will credit the person or people who report the security vulnerabilities after it has been patched.\n",
      "==================================Metadata==================================\n",
      "{'source': 'gradio-app/gradio/blob/main/SECURITY.md', 'start_index': 1}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Access HF Hub?\"\n",
    "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(\"==================================Metadata==================================\")\n",
    "print(retrieved_docs[0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
